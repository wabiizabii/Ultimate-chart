# ===================== SEC 0: IMPORT & CONFIG =======================
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import plotly.express as px
import google.generativeai as genai
import gspread
import plotly.graph_objects as go
import yfinance as yf
import random
import csv
import io # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° import io module ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ io.StringIO ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô CSV String

st.set_page_config(page_title="Ultimate-Chart", layout="wide")
acc_balance = 10000 # ‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡πÄ‡∏ó‡∏£‡∏î

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ Google Sheet ‡πÅ‡∏•‡∏∞ Worksheet ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
GOOGLE_SHEET_NAME = "TradeLog"
WORKSHEET_PORTFOLIOS = "Portfolios"
WORKSHEET_PLANNED_LOGS = "PlannedTradeLogs"
WORKSHEET_ACTUAL_TRADES = "ActualTrades"
WORKSHEET_ACTUAL_ORDERS = "ActualOrders"
WORKSHEET_ACTUAL_POSITIONS = "ActualPositions"
WORKSHEET_STATEMENT_SUMMARIES = "StatementSummaries" 

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ gspread
# ‡πÉ‡∏ä‡πâ st.cache_resource ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ GSpread client object ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
@st.cache_resource
def get_gspread_client():
    try:
        if "gcp_service_account" not in st.secrets:
            st.warning("‚ö†Ô∏è ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ 'gcp_service_account' ‡πÉ‡∏ô `.streamlit/secrets.toml` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets.")
            return None
        return gspread.service_account_from_dict(st.secrets["gcp_service_account"])
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets: {e}")
        st.info("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ 'gcp_service_account' ‡πÉ‡∏ô secrets.toml ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡πÅ‡∏ä‡∏£‡πå Sheet ‡∏Å‡∏±‡∏ö Service Account ‡πÅ‡∏•‡πâ‡∏ß")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Portfolios
# ‡πÉ‡∏ä‡πâ st.cache_data ‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î ttl (Time-To-Live) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
@st.cache_data(ttl=300) # Cache ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ß‡πâ 5 ‡∏ô‡∏≤‡∏ó‡∏µ
def load_portfolios_from_gsheets():
    gc = get_gspread_client()
    if gc is None:
        return pd.DataFrame()

    try:
        sh = gc.open(GOOGLE_SHEET_NAME)
        worksheet = sh.worksheet(WORKSHEET_PORTFOLIOS)
        records = worksheet.get_all_records()
        
        if not records:
            return pd.DataFrame()
        
        df_portfolios = pd.DataFrame(records)
        
        cols_to_numeric = ['InitialBalance', 'ProfitTargetPercent', 'DailyLossLimitPercent', 'TotalStopoutPercent', 'ScalingProfitTargetPercent']
        for col in cols_to_numeric:
            if col in df_portfolios.columns:
                df_portfolios[col] = pd.to_numeric(df_portfolios[col], errors='coerce').fillna(0)

        return df_portfolios
    except gspread.exceptions.WorksheetNotFound:
        st.sidebar.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet ‡∏ä‡∏∑‡πà‡∏≠ '{WORKSHEET_PORTFOLIOS}' ‡πÉ‡∏ô Google Sheet '{GOOGLE_SHEET_NAME}'.")
        st.sidebar.info(f"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á Worksheet ‡∏ä‡∏∑‡πà‡∏≠ '{WORKSHEET_PORTFOLIOS}' ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡∏´‡∏±‡∏ß‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
        return pd.DataFrame()
    except Exception as e:
        st.sidebar.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Portfolios: {e}")
        return pd.DataFrame()

# ===================== SEC 1: PORTFOLIO MANAGEMENT =======================
df_portfolios_gs = load_portfolios_from_gsheets()

st.sidebar.markdown("---")
st.sidebar.subheader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Active Portfolio)")

if 'active_portfolio_name_gs' not in st.session_state:
    st.session_state.active_portfolio_name_gs = ""
if 'active_portfolio_id_gs' not in st.session_state:
    st.session_state.active_portfolio_id_gs = None

portfolio_names_list_gs = [""]
if not df_portfolios_gs.empty and 'PortfolioName' in df_portfolios_gs.columns:
    portfolio_names_list_gs.extend(sorted(df_portfolios_gs['PortfolioName'].dropna().unique().tolist()))

if st.session_state.active_portfolio_name_gs not in portfolio_names_list_gs:
    st.session_state.active_portfolio_name_gs = portfolio_names_list_gs[0]

selected_portfolio_name_gs = st.sidebar.selectbox(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏û‡∏≠‡∏£‡πå‡∏ï:",
    options=portfolio_names_list_gs,
    index=portfolio_names_list_gs.index(st.session_state.active_portfolio_name_gs),
    key='sb_active_portfolio_selector_gs'
)

if selected_portfolio_name_gs != "":
    st.session_state.active_portfolio_name_gs = selected_portfolio_name_gs
    selected_portfolio_row = df_portfolios_gs[df_portfolios_gs['PortfolioName'] == selected_portfolio_name_gs]
    if not selected_portfolio_row.empty and 'PortfolioID' in selected_portfolio_row.columns:
        st.session_state.active_portfolio_id_gs = selected_portfolio_row['PortfolioID'].iloc[0]
    else:
        st.session_state.active_portfolio_id_gs = None
        st.sidebar.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö PortfolioID ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡∏µ‡∏ï 'Portfolios'.")
else:
    st.session_state.active_portfolio_name_gs = ""
    st.session_state.active_portfolio_id_gs = None

if st.session_state.active_portfolio_name_gs and not df_portfolios_gs.empty:
    current_portfolio_rules = df_portfolios_gs[df_portfolios_gs['PortfolioName'] == st.session_state.active_portfolio_name_gs]
    if not current_portfolio_rules.empty:
        st.sidebar.markdown(f"**üí° ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏≠‡∏£‡πå‡∏ï '{st.session_state.active_portfolio_name_gs}'**")
        if 'InitialBalance' in current_portfolio_rules.columns:
            st.sidebar.write(f"- **Initial Balance:** {current_portfolio_rules['InitialBalance'].iloc[0]:,.2f} USD")
        if 'ProfitTargetPercent' in current_portfolio_rules.columns:
            st.sidebar.write(f"- **Profit Target:** {current_portfolio_rules['ProfitTargetPercent'].iloc[0]:.1f}%")
        if 'DailyLossLimitPercent' in current_portfolio_rules.columns:
            st.sidebar.write(f"- **Daily Loss Limit:** {current_portfolio_rules['DailyLossLimitPercent'].iloc[0]:.1f}%")
        if 'TotalStopoutPercent' in current_portfolio_rules.columns:
            st.sidebar.write(f"- **Total Stopout:** {current_portfolio_rules['TotalStopoutPercent'].iloc[0]:.1f}%")
        if 'Status' in current_portfolio_rules.columns:
            st.sidebar.write(f"- **Status:** {current_portfolio_rules['Status'].iloc[0]}")
    else:
        st.sidebar.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å.")
elif df_portfolios_gs.empty:
    st.sidebar.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Portfolio ‡πÉ‡∏ô Google Sheets ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î.")
    st.sidebar.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡∏µ‡∏ï 'Portfolios' ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Sheets.")

# ========== Function Utility ==========
def get_today_drawdown(log_source_df, acc_balance):
    if log_source_df.empty:
        return 0
    today_str = datetime.now().strftime("%Y-%m-%d")
    try:
        log_source_df['Timestamp'] = pd.to_datetime(log_source_df['Timestamp'], errors='coerce')
        log_source_df['Risk $'] = pd.to_numeric(log_source_df['Risk $'], errors='coerce').fillna(0)

        df_today = log_source_df[log_source_df["Timestamp"].dt.strftime("%Y-%m-%d") == today_str]
        drawdown = df_today["Risk $"].sum()
        return drawdown
    except KeyError as e:
        return 0
    except Exception as e:
        return 0

def get_performance(log_source_df, mode="week"):
    if log_source_df.empty:
        return 0, 0, 0
    
    try:
        log_source_df['Timestamp'] = pd.to_datetime(log_source_df['Timestamp'], errors='coerce')
        log_source_df['Risk $'] = pd.to_numeric(log_source_df['Risk $'], errors='coerce').fillna(0)
        now = datetime.now()

        if mode == "week":
            week_start_date = now - pd.Timedelta(days=now.weekday())
            df_period = log_source_df[log_source_df["Timestamp"] >= week_start_date]
        else:  # month
            month_start_date = now.replace(day=1)
            df_period = log_source_df[log_source_df["Timestamp"] >= month_start_date]
        
        win = df_period[df_period["Risk $"] > 0].shape[0]
        loss = df_period[df_period["Risk $"] <= 0].shape[0]
        total_trades = win + loss
        winrate = (100 * win / total_trades) if total_trades > 0 else 0
        gain = df_period["Risk $"].sum()
        return winrate, gain, total_trades
    except KeyError as e:
        return 0,0,0
    except Exception as e:
        return 0,0,0

# ===================== SEC 2: SIDEBAR - TRADE SETUP & INPUTS =======================
st.sidebar.header("üéõÔ∏è Trade Setup")

# ===================== SEC 2.1: COMMON INPUTS & MODE SELECTION =======================
drawdown_limit_pct = st.sidebar.number_input(
    "Drawdown Limit ‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô (%)",
    min_value=0.1, max_value=20.0,
    value=st.session_state.get("drawdown_limit_pct", 2.0),
    step=0.1, format="%.1f",
    key="drawdown_limit_pct"
)

mode = st.sidebar.radio("Trade Mode", ["FIBO", "CUSTOM"], horizontal=True, key="mode")

if st.sidebar.button("üîÑ Reset Form"):
    risk_keep = st.session_state.get("risk_pct", 1.0)
    asset_keep = st.session_state.get("asset", "XAUUSD")
    drawdown_limit_keep = st.session_state.get("drawdown_limit_pct", 2.0)
    
    keys_to_keep = {"risk_pct", "asset", "drawdown_limit_pct", "mode", 
                    "active_portfolio_name_gs", "active_portfolio_id_gs",
                    "gcp_service_account"}

    for k in list(st.session_state.keys()):
        if k not in keys_to_keep:
            del st.session_state[k]

    st.session_state["risk_pct"] = risk_keep
    st.session_state["asset"] = asset_keep
    st.session_state["drawdown_limit_pct"] = drawdown_limit_keep
    st.session_state["fibo_flags"] = [False] * 5
    st.rerun()

# ===================== SEC 2.2: FIBO TRADE DETAILS =======================
if mode == "FIBO":
    col1, col2, col3 = st.sidebar.columns([2, 2, 2])
    with col1:
        asset = st.text_input("Asset", value=st.session_state.get("asset", "XAUUSD"), key="asset")
    with col2:
        risk_pct = st.number_input(
            "Risk %",
            min_value=0.01,
            max_value=100.0,
            value=st.session_state.get("risk_pct", 1.0),
            step=0.01,
            format="%.2f",
            key="risk_pct"
        )
    with col3:
        direction = st.radio("Direction", ["Long", "Short"], horizontal=True, key="fibo_direction")

    col4, col5 = st.sidebar.columns(2)
    with col4:
        swing_high = st.text_input("High", key="swing_high")
    with col5:
        swing_low = st.text_input("Low", key="swing_low")

    st.sidebar.markdown("**üìê Entry Fibo Levels**")
    fibos = [0.114, 0.25, 0.382, 0.5, 0.618]
    labels = [f"{l:.3f}" for l in fibos]
    cols = st.sidebar.columns(len(fibos))

    if "fibo_flags" not in st.session_state:
        st.session_state.fibo_flags = [True] * len(fibos)

    fibo_selected_flags = []
    for i, col in enumerate(cols):
        checked = col.checkbox(labels[i], value=st.session_state.fibo_flags[i], key=f"fibo_cb_{i}")
        fibo_selected_flags.append(checked)

    st.session_state.fibo_flags = fibo_selected_flags

    try:
        high_val = float(swing_high) if swing_high else 0
        low_val = float(swing_low) if swing_low else 0
        if swing_high and swing_low and high_val <= low_val:
            st.sidebar.warning("High ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Low!")
    except ValueError:
        if swing_high or swing_low:
            st.sidebar.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà High/Low ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    except Exception:
        pass

    if 'risk_pct' in st.session_state and st.session_state.risk_pct <= 0:
        st.sidebar.warning("Risk% ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0")

    st.sidebar.markdown("---")
    try:
        high_preview = float(swing_high)
        low_preview = float(swing_low)
        if high_preview > low_preview and any(st.session_state.fibo_flags):
            st.sidebar.markdown("**Preview (‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô):**")
            first_selected_fibo_index = st.session_state.fibo_flags.index(True)
            if direction == "Long":
                preview_entry = low_preview + (high_preview - low_preview) * fibos[first_selected_fibo_index]
            else:
                preview_entry = high_preview - (high_preview - low_preview) * fibos[first_selected_fibo_index]
            st.sidebar.markdown(f"Entry ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‚âà **{preview_entry:.2f}**")
            st.sidebar.caption("Lot/TP/‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ï‡πá‡∏°‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á (‡πÉ‡∏ô Strategy Summary)")
    except Exception:
        pass

    save_fibo = st.sidebar.button("üíæ Save Plan (FIBO)", key="save_fibo")

# ===================== SEC 2.3: CUSTOM TRADE DETAILS =======================
elif mode == "CUSTOM":
    col1, col2, col3 = st.sidebar.columns([2, 2, 2])
    with col1:
        asset = st.text_input("Asset", value=st.session_state.get("asset", "XAUUSD"), key="asset_custom")
    with col2:
        risk_pct = st.number_input(
            "Risk %",
            min_value=0.01,
            max_value=100.0,
            value=st.session_state.get("risk_pct_custom", 1.00),
            step=0.01,
            format="%.2f",
            key="risk_pct_custom"
        )
    with col3:
        n_entry = st.number_input(
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏°‡πâ",
            min_value=1,
            max_value=10,
            value=st.session_state.get("n_entry_custom", 2),
            step=1,
            key="n_entry_custom"
        )

    st.sidebar.markdown("**‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏°‡πâ**")
    custom_inputs = []
    current_custom_risk_pct = st.session_state.get("risk_pct_custom", 1.0)
    risk_per_trade = current_custom_risk_pct / 100
    risk_dollar_total = acc_balance * risk_per_trade
    num_entries_val = st.session_state.get("n_entry_custom", 1)
    risk_dollar_per_entry = risk_dollar_total / num_entries_val if num_entries_val > 0 else 0

    for i in range(int(num_entries_val)):
        st.sidebar.markdown(f"--- ‡πÑ‡∏°‡πâ‡∏ó‡∏µ‡πà {i+1} ---")
        col_e, col_s, col_t = st.sidebar.columns(3)
        with col_e:
            entry = st.text_input(f"Entry {i+1}", value=st.session_state.get(f"custom_entry_{i}", "0.00"), key=f"custom_entry_{i}")
        with col_s:
            sl = st.text_input(f"SL {i+1}", value=st.session_state.get(f"custom_sl_{i}", "0.00"), key=f"custom_sl_{i}")
        with col_t:
            tp = st.text_input(f"TP {i+1}", value=st.session_state.get(f"custom_tp_{i}", "0.00"), key=f"custom_tp_{i}")
        
        try:
            entry_val = float(entry)
            sl_val = float(sl)
            stop = abs(entry_val - sl_val)
            lot = risk_dollar_per_entry / stop if stop > 0 else 0
            lot_display = f"Lot: {lot:.2f}" if stop > 0 else "Lot: - (Invalid SL)"
            risk_per_entry_display = f"Risk$ ‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πâ: {risk_dollar_per_entry:.2f}"
        except ValueError:
            lot_display = "Lot: - (Error)"
            risk_per_entry_display = "Risk$ ‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πâ: - (Error)"
            stop = None
        except Exception:
            lot_display = "Lot: -"
            risk_per_entry_display = "Risk$ ‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πâ: -"
            stop = None

        try:
            if stop is not None and stop > 0:
                tp_rr3_info = f"Stop: {stop:.2f}"
            else:
                tp_rr3_info = "TP (RR=3): - (SL Error)"
        except Exception:
            tp_rr3_info = "TP (RR=3): -"
        
        st.sidebar.caption(f"{lot_display} | {risk_per_entry_display} | {tp_rr3_info}")
        custom_inputs.append({"entry": entry, "sl": sl, "tp": tp})

    if current_custom_risk_pct <= 0:
        st.sidebar.warning("Risk% ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0")
    save_custom = st.sidebar.button("üíæ Save Plan (CUSTOM)", key="save_custom")

# ===================== SEC 3: SIDEBAR - CALCULATIONS, SUMMARY & ACTIONS =======================
st.sidebar.markdown("---")
st.sidebar.markdown("### üßæ Strategy Summary")

entry_data = []
custom_entries_summary = []

if mode == "FIBO":
    try:
        current_fibo_risk_pct = st.session_state.get("risk_pct", 1.0)
        current_fibo_direction = st.session_state.get("fibo_direction", "Long")
        current_swing_high = st.session_state.get("swing_high", "")
        current_swing_low = st.session_state.get("swing_low", "")
        current_fibo_flags = st.session_state.get("fibo_flags", [False]*5)

        high = float(current_swing_high)
        low = float(current_swing_low)
        selected_fibo_levels = [fibos[i] for i, sel in enumerate(current_fibo_flags) if sel]
        n = len(selected_fibo_levels)
        risk_per_trade = current_fibo_risk_pct / 100
        risk_dollar_total = acc_balance * risk_per_trade
        risk_dollar_per_entry = risk_dollar_total / n if n > 0 else 0
        
        for idx, fibo_level_val in enumerate(selected_fibo_levels):
            if current_fibo_direction == "Long":
                entry = low + (high - low) * fibo_level_val
                sl = low
            else:
                entry = high - (high - low) * fibo_level_val
                sl = high
            
            stop = abs(entry - sl)
            lot = risk_dollar_per_entry / stop if stop > 0 else 0
            risk_val = stop * lot if stop > 0 else 0

            if stop > 0:
                if current_fibo_direction == "Long":
                    tp1 = entry + (stop * 1.618)
                else:
                    tp1 = entry - (stop * 1.618)
                tp_display = f"{tp1:.2f}"
            else:
                tp_display = "-"

            entry_data.append({
                "Fibo Level": f"{fibo_level_val:.3f}",
                "Entry": f"{entry:.2f}",
                "SL": f"{sl:.2f}",
                "TP": tp_display, 
                "Lot": f"{lot:.2f}" if stop > 0 else "0.00",
                "Risk $": f"{risk_val:.2f}" if stop > 0 else "0.00",
            })
        if entry_data:
            entry_df_summary = pd.DataFrame(entry_data)
            st.sidebar.write(f"**Total Lots:** {entry_df_summary['Lot'].astype(float).sum():.2f}")
            st.sidebar.write(f"**Total Risk $:** {entry_df_summary['Risk $'].astype(float).sum():.2f}")
    except ValueError:
        if current_swing_high or current_swing_low:
             st.sidebar.warning("‡∏Å‡∏£‡∏≠‡∏Å High/Low ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Summary")
    except Exception as e:
        pass 
elif mode == "CUSTOM":
    try:
        num_entries_val_summary = st.session_state.get("n_entry_custom", 1)
        current_custom_risk_pct_summary = st.session_state.get("risk_pct_custom", 1.0)

        risk_per_trade_summary = current_custom_risk_pct_summary / 100
        risk_dollar_total_summary = acc_balance * risk_per_trade_summary
        risk_dollar_per_entry_summary = risk_dollar_total_summary / num_entries_val_summary if num_entries_val_summary > 0 else 0
        
        rr_list = []
        for i in range(int(num_entries_val_summary)):
            entry_val_str = st.session_state.get(f"custom_entry_{i}", "0.00")
            sl_val_str = st.session_state.get(f"custom_sl_{i}", "0.00")
            tp_val_str = st.session_state.get(f"custom_tp_{i}", "0.00")

            entry_val = float(entry_val_str)
            sl_val = float(sl_val_str)
            tp_val = float(tp_val_str)

            stop = abs(entry_val - sl_val)
            target = abs(tp_val - entry_val)
            lot = risk_dollar_per_entry_summary / stop if stop > 0 else 0
            rr = (target / stop) if stop > 0 else 0
            rr_list.append(rr)
            custom_entries_summary.append({
                "Entry": f"{entry_val:.2f}",
                "SL": f"{sl_val:.2f}",
                "TP": f"{tp_val:.2f}",
                "Lot": f"{lot:.2f}" if stop > 0 else "0.00",
                "Risk $": f"{risk_dollar_per_entry_summary:.2f}" if stop > 0 else "0.00",
                "RR": f"{rr:.2f}" if stop > 0 else "0.00"
            })
        if custom_entries_summary:
            custom_df_summary = pd.DataFrame(custom_entries_summary)
            st.sidebar.write(f"**Total Lots:** {custom_df_summary['Lot'].astype(float).sum():.2f}")
            st.sidebar.write(f"**Total Risk $:** {custom_df_summary['Risk $'].astype(float).sum():.2f}")
            avg_rr = np.mean([r for r in rr_list if r > 0]) if any(r > 0 for r in rr_list) else 0
            if avg_rr > 0 :
                st.sidebar.write(f"**Average RR:** {avg_rr:.2f}")
    except ValueError:
        st.sidebar.warning("‡∏Å‡∏£‡∏≠‡∏Å Entry/SL/TP ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Summary")
    except Exception as e:
        pass

# ===================== SEC 3.1: SCALING MANAGER =======================
with st.sidebar.expander("‚öôÔ∏è Scaling Manager Settings", expanded=False):
    scaling_step = st.number_input(
        "Scaling Step (%)", min_value=0.01, max_value=1.0, 
        value=st.session_state.get('scaling_step', 0.25), 
        step=0.01, format="%.2f", key='scaling_step'
    )
    min_risk_pct = st.number_input(
        "Minimum Risk %", min_value=0.01, max_value=100.0, 
        value=st.session_state.get('min_risk_pct', 0.5), 
        step=0.01, format="%.2f", key='min_risk_pct'
    )
    max_risk_pct = st.number_input(
        "Maximum Risk %", min_value=0.01, max_value=100.0, 
        value=st.session_state.get('max_risk_pct', 5.0), 
        step=0.01, format="%.2f", key='max_risk_pct'
    )
    scaling_mode = st.radio(
        "Scaling Mode", ["Manual", "Auto"], 
        index=0 if st.session_state.get('scaling_mode', 'Manual') == 'Manual' else 1,
        horizontal=True, key='scaling_mode'
    )

# ===================== SEC 3.1.1: SCALING SUGGESTION LOGIC =======================
df_planned_logs_for_scaling = pd.DataFrame()
gc_scaling = get_gspread_client()
if gc_scaling:
    try:
        sh_scaling = gc_scaling.open(GOOGLE_SHEET_NAME)
        ws_planned_logs = sh_scaling.worksheet(WORKSHEET_PLANNED_LOGS)
        records_scaling = ws_planned_logs.get_all_records()
        if records_scaling:
            df_planned_logs_for_scaling = pd.DataFrame(records_scaling)
    except Exception as e:
        pass

winrate_perf, gain_perf, total_trades_perf = get_performance(df_planned_logs_for_scaling.copy(), mode="week")

current_risk_for_scaling = 1.0
if mode == "FIBO":
    current_risk_for_scaling = st.session_state.get("risk_pct", 1.0)
elif mode == "CUSTOM":
    current_risk_for_scaling = st.session_state.get("risk_pct_custom", 1.0)

scaling_step_val = st.session_state.get('scaling_step', 0.25)
max_risk_pct_val = st.session_state.get('max_risk_pct', 5.0)
min_risk_pct_val = st.session_state.get('min_risk_pct', 0.5)
current_scaling_mode = st.session_state.get('scaling_mode', 'Manual')

suggest_risk = current_risk_for_scaling
scaling_msg = "Risk% ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Performance ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠ Performance ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå)"

if total_trades_perf > 0:
    if winrate_perf > 55 and gain_perf > 0.02 * acc_balance:
        suggest_risk = min(current_risk_for_scaling + scaling_step_val, max_risk_pct_val)
        scaling_msg = f"üéâ ‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏î‡∏µ! Winrate {winrate_perf:.1f}%, ‡∏Å‡∏≥‡πÑ‡∏£ {gain_perf:.2f}. ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏° Risk% ‡πÄ‡∏õ‡πá‡∏ô {suggest_risk:.2f}%"
    elif winrate_perf < 45 or gain_perf < 0:
        suggest_risk = max(current_risk_for_scaling - scaling_step_val, min_risk_pct_val)
        scaling_msg = f"‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏£‡∏•‡∏î Risk%! Winrate {winrate_perf:.1f}%, ‡∏Å‡∏≥‡πÑ‡∏£ {gain_perf:.2f}. ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏•‡∏î Risk% ‡πÄ‡∏õ‡πá‡∏ô {suggest_risk:.2f}%"
    else:
        scaling_msg = f"Risk% ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (Winrate {winrate_perf:.1f}%, ‡∏Å‡∏≥‡πÑ‡∏£ {gain_perf:.2f})"

st.sidebar.info(scaling_msg)

if current_scaling_mode == "Manual" and abs(suggest_risk - current_risk_for_scaling) > 0.001:
    if st.sidebar.button(f"‡∏õ‡∏£‡∏±‡∏ö Risk% ‡πÄ‡∏õ‡πá‡∏ô {suggest_risk:.2f}%"):
        if mode == "FIBO":
            st.session_state.risk_pct = suggest_risk
        elif mode == "CUSTOM":
            st.session_state.risk_pct_custom = suggest_risk
        st.rerun()
elif current_scaling_mode == "Auto":
    if abs(suggest_risk - current_risk_for_scaling) > 0.001:
        if mode == "FIBO":
            st.session_state.risk_pct = suggest_risk
        elif mode == "CUSTOM":
            st.session_state.risk_pct_custom = suggest_risk

# ===================== SEC 3.2: SAVE PLAN ACTION & DRAWDOWN LOCK =======================
def save_plan_to_gsheets(plan_data_list, trade_mode_arg, asset_name, risk_percentage, trade_direction, portfolio_id, portfolio_name):
    gc = get_gspread_client()
    if not gc:
        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets Client ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ú‡∏ô‡πÑ‡∏î‡πâ")
        return False
    try:
        sh = gc.open(GOOGLE_SHEET_NAME)
        ws = sh.worksheet(WORKSHEET_PLANNED_LOGS)
        timestamp_now = datetime.now()
        rows_to_append = []
        expected_headers = [
            "LogID", "PortfolioID", "PortfolioName", "Timestamp", "Asset", "Mode", "Direction",
            "Risk %", "Fibo Level", "Entry", "SL", "TP", "Lot", "Risk $", "RR"
        ]
        current_headers = []
        if ws.row_count > 0:
            try:
                current_headers = ws.row_values(1)
            except Exception:
                current_headers = []
        
        if not current_headers or all(h == "" for h in current_headers) :
            ws.append_row(expected_headers, value_input_option='USER_ENTERED')
        elif set(current_headers) != set(expected_headers) and any(h!="" for h in current_headers):
            st.warning(f"Worksheet '{WORKSHEET_PLANNED_LOGS}' has incorrect headers. Please ensure headers match: {', '.join(expected_headers)}")

        for idx, plan_entry in enumerate(plan_data_list):
            log_id = f"{timestamp_now.strftime('%Y%m%d%H%M%S')}-{random.randint(1000, 9999)}-{idx}"
            row_data = {
                "LogID": log_id,
                "PortfolioID": portfolio_id,
                "PortfolioName": portfolio_name,
                "Timestamp": timestamp_now.strftime("%Y-%m-%d %H:%M:%S"),
                "Asset": asset_name,
                "Mode": trade_mode_arg,
                "Direction": trade_direction,
                "Risk %": risk_percentage,
                "Fibo Level": plan_entry.get("Fibo Level", ""),
                "Entry": plan_entry.get("Entry", "0.00"),
                "SL": plan_entry.get("SL", "0.00"),
                "TP": plan_entry.get("TP", "0.00"),
                "Lot": plan_entry.get("Lot", "0.00"),
                "Risk $": plan_entry.get("Risk $", "0.00"),
                "RR": plan_entry.get("RR", "")
            }
            rows_to_append.append([str(row_data.get(h, "")) for h in expected_headers])

        if rows_to_append:
            ws.append_rows(rows_to_append, value_input_option='USER_ENTERED')
            return True
        return False
    except gspread.exceptions.WorksheetNotFound:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet ‡∏ä‡∏∑‡πà‡∏≠ '{WORKSHEET_PLANNED_LOGS}'. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Headers: {', '.join(expected_headers)}")
        return False
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ú‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets: {e}")
        return False

df_drawdown_check = pd.DataFrame()
gc_drawdown = get_gspread_client()
if gc_drawdown:
    try:
        sh_drawdown = gc_drawdown.open(GOOGLE_SHEET_NAME)
        ws_planned_logs_drawdown = sh_drawdown.worksheet(WORKSHEET_PLANNED_LOGS)
        records_drawdown = ws_planned_logs_drawdown.get_all_records()
        if records_drawdown:
            df_drawdown_check = pd.DataFrame(records_drawdown)
    except Exception as e:
        pass

drawdown_today = get_today_drawdown(df_drawdown_check.copy(), acc_balance)
drawdown_limit_pct_val = st.session_state.get('drawdown_limit_pct', 2.0)
drawdown_limit_abs = -acc_balance * (drawdown_limit_pct_val / 100)

if drawdown_today < 0:
    st.sidebar.markdown(f"**‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏ú‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ:** <font color='red'>{drawdown_today:,.2f} USD</font>", unsafe_allow_html=True)
else:
    st.sidebar.markdown(f"**‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏ú‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ:** {drawdown_today:,.2f} USD")

active_portfolio_id = st.session_state.get('active_portfolio_id_gs', None)
active_portfolio_name = st.session_state.get('active_portfolio_name_gs', None)

asset_to_save = ""
risk_pct_to_save = 0.0
direction_to_save = "N/A"
data_to_save = []

if mode == "FIBO":
    asset_to_save = st.session_state.get("asset", "XAUUSD")
    risk_pct_to_save = st.session_state.get("risk_pct", 1.0)
    direction_to_save = st.session_state.get("fibo_direction", "Long")
    data_to_save = entry_data
    save_button_pressed = save_fibo
elif mode == "CUSTOM":
    asset_to_save = st.session_state.get("asset_custom", "XAUUSD")
    risk_pct_to_save = st.session_state.get("risk_pct_custom", 1.0)
    direction_to_save = st.session_state.get("custom_direction_for_log", "N/A")
    data_to_save = custom_entries_summary
    save_button_pressed = save_custom

if save_button_pressed and data_to_save:
    if drawdown_today <= drawdown_limit_abs and drawdown_limit_abs < 0 :
        st.sidebar.error(
            f"‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏î! ‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏ú‡∏ô‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ {abs(drawdown_today):,.2f} ‡πÄ‡∏Å‡∏¥‡∏ô‡∏•‡∏¥‡∏°‡∏¥‡∏ï {abs(drawdown_limit_abs):,.2f} ({drawdown_limit_pct_val:.1f}%)"
        )
    elif not active_portfolio_id:
        st.sidebar.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ú‡∏ô")
    else:
        try:
            if save_plan_to_gsheets(data_to_save, mode, asset_to_save, risk_pct_to_save, direction_to_save, active_portfolio_id, active_portfolio_name):
                st.sidebar.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ú‡∏ô ({mode}) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏≠‡∏£‡πå‡∏ï '{active_portfolio_name}' ‡∏•‡∏á Google Sheets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                st.balloons()
            else:
                st.sidebar.error(f"Save ({mode}) ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
        except Exception as e:
            st.sidebar.error(f"Save ({mode}) ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

# ===================== SEC 4: MAIN AREA - ENTRY PLAN DETAILS TABLE =======================
with st.expander("üìã Entry Table (FIBO/CUSTOM)", expanded=True):
    if mode == "FIBO":
        col1_main, col2_main = st.columns(2)
        with col1_main:
            st.markdown("### üéØ Entry Levels (FIBO)")
            if entry_data:
                entry_df_main = pd.DataFrame(entry_data)
                st.dataframe(entry_df_main, hide_index=True, use_container_width=True)
            else:
                st.info("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• High/Low ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Fibo Level ‡πÉ‡∏ô Sidebar ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Entry Levels.")
        with col2_main:
            st.markdown("### üéØ Take Profit Zones (FIBO)")
            try:
                current_swing_high_tp = st.session_state.get("swing_high", "")
                current_swing_low_tp = st.session_state.get("swing_low", "")
                current_fibo_direction_tp = st.session_state.get("fibo_direction", "Long")

                high_tp = float(current_swing_high_tp)
                low_tp = float(current_swing_low_tp)

                if high_tp > low_tp:
                    if current_fibo_direction_tp == "Long":
                        tp1_main = low_tp + (high_tp - low_tp) * 1.618
                        tp2_main = low_tp + (high_tp - low_tp) * 2.618
                        tp3_main = low_tp + (high_tp - low_tp) * 4.236
                    else:
                        tp1_main = high_tp - (high_tp - low_tp) * 1.618
                        tp2_main = high_tp - (high_tp - low_tp) * 2.618
                        tp3_main = high_tp - (high_tp - low_tp) * 4.236
                    tp_df_main = pd.DataFrame({
                        "TP Zone": ["TP1 (1.618)", "TP2 (2.618)", "TP3 (4.236)"],
                        "Price": [f"{tp1_main:.2f}", f"{tp2_main:.2f}", f"{tp3_main:.2f}"]
                    })
                    st.dataframe(tp_df_main, hide_index=True, use_container_width=True)
                else:
                    if current_swing_high_tp or current_swing_low_tp :
                        st.warning("üìå High ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Low ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì TP.")
                    else:
                        st.info("üìå ‡∏Å‡∏£‡∏≠‡∏Å High/Low ‡πÉ‡∏ô Sidebar ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π TP.")
            except ValueError:
                 if current_swing_high_tp or current_swing_low_tp :
                    st.warning("üìå ‡∏Å‡∏£‡∏≠‡∏Å High/Low ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì TP.")
                 else:
                    st.info("üìå ‡∏Å‡∏£‡∏≠‡∏Å High/Low ‡πÉ‡∏ô Sidebar ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π TP.")
            except Exception:
                st.info("üìå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì TP.")

    elif mode == "CUSTOM":
        st.markdown("### üéØ Entry & Take Profit Zones (CUSTOM)")
        if custom_entries_summary:
            custom_df_main = pd.DataFrame(custom_entries_summary)
            st.dataframe(custom_df_main, hide_index=True, use_container_width=True)
            for i, row_data_dict in enumerate(custom_entries_summary):
                try:
                    rr_val_str = row_data_dict.get("RR", "0")
                    rr_val = float(rr_val_str)
                    if rr_val < 2 and rr_val > 0:
                        st.warning(f"üéØ Entry {i+1} ‡∏°‡∏µ RR ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πà‡∏≥ ({rr_val:.2f}) ‚Äî ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö TP/SL ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Risk:Reward ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô")
                except ValueError:
                    pass
                except Exception:
                    pass
        else:
            st.info("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Custom ‡πÉ‡∏ô Sidebar ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Entry & TP Zones.")

# ===================== SEC 5: MAIN AREA - CHART VISUALIZER =======================
with st.expander("üìà Chart Visualizer", expanded=True):
    asset_to_display = "OANDA:XAUUSD"
    current_asset_input = ""
    if mode == "FIBO":
        current_asset_input = st.session_state.get("asset", "XAUUSD")
    elif mode == "CUSTOM":
        current_asset_input = st.session_state.get("asset_custom", "XAUUSD")
    
    if current_asset_input.upper() == "XAUUSD":
        asset_to_display = "OANDA:XAUUSD"
    elif current_asset_input.upper() == "EURUSD":
        asset_to_display = "OANDA:EURUSD"
    elif current_asset_input:
        asset_to_display = current_asset_input.upper()

    if 'plot_data' in st.session_state and st.session_state['plot_data']:
        asset_from_log = st.session_state['plot_data'].get('Asset', asset_to_display)
        if asset_from_log.upper() == "XAUUSD":
            asset_to_display = "OANDA:XAUUSD"
        elif asset_from_log.upper() == "EURUSD":
            asset_to_display = "OANDA:EURUSD"
        elif asset_from_log:
            asset_to_display = asset_from_log.upper()
        st.info(f"‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü TradingView ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: {asset_to_display} (‡∏à‡∏≤‡∏Å Log Viewer)")
    else:
        st.info(f"‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü TradingView ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: {asset_to_display} (‡∏à‡∏≤‡∏Å Input ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)")

    tradingview_html = f"""
    <div class="tradingview-widget-container">
      <div id="tradingview_legendary"></div>
      <script type="text/javascript" src="https://s3.tradingview.com/tv.js"></script>
      <script type="text/javascript">
      new TradingView.widget({{
        "width": "100%",
        "height": 600,
        "symbol": "{asset_to_display}",
        "interval": "15",
        "timezone": "Asia/Bangkok",
        "theme": "dark",
        "style": "1",
        "locale": "th",
        "toolbar_bg": "#f1f3f6",
        "enable_publishing": false,
        "withdateranges": true,
        "allow_symbol_change": true,
        "hide_side_toolbar": false,
        "details": true,
        "hotlist": true,
        "calendar": true,
        "container_id": "tradingview_legendary"
      }});
      </script>
    </div>
    """
    st.components.v1.html(tradingview_html, height=620)

# ===================== SEC 6: MAIN AREA - AI ASSISTANT =======================
with st.expander("ü§ñ AI Assistant", expanded=True):
    df_ai_logs = pd.DataFrame()
    gc_ai = get_gspread_client()
    if gc_ai:
        try:
            sh_ai = gc_ai.open(GOOGLE_SHEET_NAME)
            ws_ai_logs = sh_ai.worksheet(WORKSHEET_PLANNED_LOGS)
            records_ai = ws_ai_logs.get_all_records()
            if records_ai:
                df_ai_logs = pd.DataFrame(records_ai)
                if 'Risk $' in df_ai_logs.columns:
                    df_ai_logs['Risk $'] = pd.to_numeric(df_ai_logs['Risk $'], errors='coerce').fillna(0)
                if 'RR' in df_ai_logs.columns:
                    df_ai_logs['RR'] = pd.to_numeric(df_ai_logs['RR'], errors='coerce')
                if 'Timestamp' in df_ai_logs.columns:
                    df_ai_logs['Timestamp'] = pd.to_datetime(df_ai_logs['Timestamp'], errors='coerce')
        except Exception as e:
            pass
            
    if df_ai_logs.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡πÄ‡∏ó‡∏£‡∏î‡πÉ‡∏ô Log (Google Sheets) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Assistant")
    else:
        total_trades_ai = df_ai_logs.shape[0]
        win_trades_ai = df_ai_logs[df_ai_logs["Risk $"] > 0].shape[0] if "Risk $" in df_ai_logs.columns else 0
        winrate_ai = (100 * win_trades_ai / total_trades_ai) if total_trades_ai > 0 else 0
        gross_profit_ai = df_ai_logs["Risk $"].sum() if "Risk $" in df_ai_logs.columns else 0
        
        avg_rr_ai = df_ai_logs["RR"].mean() if "RR" in df_ai_logs.columns and not df_ai_logs["RR"].dropna().empty else None

        max_drawdown_ai = 0
        if "Risk $" in df_ai_logs.columns:
            df_ai_logs_sorted = df_ai_logs.sort_values(by="Timestamp") if "Timestamp" in df_ai_logs.columns else df_ai_logs
            current_balance_sim = acc_balance
            peak_balance_sim = acc_balance
            for pnl_val in df_ai_logs_sorted["Risk $"]:
                current_balance_sim += pnl_val
                if current_balance_sim > peak_balance_sim:
                    peak_balance_sim = current_balance_sim
                drawdown_val = peak_balance_sim - current_balance_sim
                if drawdown_val > max_drawdown_ai:
                    max_drawdown_ai = drawdown_val
        
        win_day_ai = "-"
        loss_day_ai = "-"
        if "Timestamp" in df_ai_logs.columns and "Risk $" in df_ai_logs.columns and not df_ai_logs["Timestamp"].isnull().all():
            df_ai_logs["Weekday"] = df_ai_logs["Timestamp"].dt.day_name()
            daily_pnl = df_ai_logs.groupby("Weekday")["Risk $"].sum()
            if not daily_pnl.empty:
                win_day_ai = daily_pnl.idxmax() if daily_pnl.max() > 0 else "-"
                loss_day_ai = daily_pnl.idxmin() if daily_pnl.min() < 0 else "-"

        st.markdown("### üß† AI Intelligence Report (‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡πÄ‡∏ó‡∏£‡∏î)")
        st.write(f"- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ú‡∏ô‡πÄ‡∏ó‡∏£‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:** {total_trades_ai:,}")
        st.write(f"- **Winrate (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô):** {winrate_ai:.2f}% (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å Risk $ > 0)")
        st.write(f"- **‡∏Å‡∏≥‡πÑ‡∏£/‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏™‡∏∏‡∏ó‡∏ò‡∏¥ (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô):** {gross_profit_ai:,.2f} USD")
        if avg_rr_ai is not None:
            st.write(f"- **RR ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô):** {avg_rr_ai:.2f}")
        st.write(f"- **Max Drawdown (‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ú‡∏ô):** {max_drawdown_ai:,.2f} USD")
        st.write(f"- **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≥‡πÑ‡∏£‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô):** {win_day_ai}")
        st.write(f"- **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô):** {loss_day_ai}")

        st.markdown("### ü§ñ AI Insight (‡∏à‡∏≤‡∏Å‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á)")
        insight_messages = []
        if winrate_ai >= 60:
            insight_messages.append("‚úÖ Winrate (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô) ‡∏™‡∏π‡∏á: ‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ó‡∏µ‡πà‡∏î‡∏µ")
        elif winrate_ai < 40 and total_trades_ai > 10 :
            insight_messages.append("‚ö†Ô∏è Winrate (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô) ‡∏ï‡πà‡∏≥: ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô")
        
        if avg_rr_ai is not None and avg_rr_ai < 1.5 and total_trades_ai > 5:
            insight_messages.append("üìâ RR ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô) ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 1.5: ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á TP/SL ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Risk:Reward ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏∂‡πâ‡∏ô")
        
        if max_drawdown_ai > acc_balance * 0.10:
            insight_messages.append("üö® Max Drawdown (‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ú‡∏ô) ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á: ‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
        
        if not insight_messages:
            insight_messages = ["‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡πÄ‡∏ó‡∏£‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ"]
        
        for msg in insight_messages:
            if "‚úÖ" in msg: st.success(msg)
            elif "‚ö†Ô∏è" in msg or "üìâ" in msg: st.warning(msg)
            elif "üö®" in msg: st.error(msg)
            else: st.info(msg)

# ===================== SEC 7: MAIN AREA - STATEMENT IMPORT & PROCESSING =======================
with st.expander("üìÇ SEC 7: Ultimate Chart Dashboard Import & Processing", expanded=True):
    st.markdown("### üìä ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Statement ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö")

    # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Statement (CSV) ---
    def extract_data_from_report_content(file_content):
        extracted_data = {}

        # Define raw headers from the CSV report for identification
        # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Header Template ‡∏≠‡∏≠‡∏Å
        section_raw_headers = {
            "Positions": "Time,Position,Symbol,Type,Volume,Price,S / L,T / P,Time,Price,Commission,Swap,Profit",
            "Orders": "Open Time,Order,Symbol,Type,Volume,Price,S / L,T / P,Time,State,,Comment", # ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏°‡∏≤
            "Deals": "Time,Deal,Symbol,Type,Direction,Volume,Price,Order,Commission,Fee,Swap,Profit,Balance,Comment",
        }
        
        # Define expected clean column names for each section (Hardcoded for robust parsing)
        expected_cleaned_columns = {
            "Positions": ["Time", "Position", "Symbol", "Type", "Volume", "Price", "S_L", "T_P", "Close_Time", "Close_Price", "Commission", "Swap", "Profit"],
            "Orders": ["Open_Time", "Order", "Symbol", "Type", "Volume", "Price", "S_L", "T_P", "Close_Time", "State", "Comment"], # ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÅ‡∏Ñ‡πà Comment
            "Deals": ["Time", "Deal", "Symbol", "Type", "Direction", "Volume", "Price", "Order", "Commission", "Fee", "Swap", "Profit", "Balance", "Comment"],
        }

        lines = file_content.strip().split('\n')
        
        section_order = ["Positions", "Orders", "Deals"]
        
        # Find the start line indices for each section's header
        section_start_indices = {}
        for section_name, header_template in section_raw_headers.items():
            for i, line in enumerate(lines):
                line_stripped = line.strip()
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ match ‡∏Ç‡∏≠‡∏á header ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ `startswith` ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
                if line_stripped.startswith(header_template.split(',')[0]) and \
                   len(line_stripped.split(',')) >= (len(header_template.split(',')) - 2) and \
                   len(line_stripped.split(',')) <= (len(header_template.split(',')) + 2):
                    section_start_indices[section_name] = i
                    break
        
        dfs_output = {}
        for i, section_name in enumerate(section_order):
            section_key_lower = section_name.lower() # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î section_key_lower ‡πÑ‡∏ß‡πâ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô
            
            if section_name in section_start_indices:
                header_idx = section_start_indices[section_name]
                
                end_idx = len(lines)
                for j in range(i + 1, len(section_order)):
                    next_section_name = section_order[j]
                    if next_section_name in section_start_indices:
                        end_idx = section_start_indices[next_section_name]
                        break
                
                raw_section_lines_block = lines[header_idx : end_idx]
                
                table_data_lines = []
                if raw_section_lines_block:
                    first_line_of_block = raw_section_lines_block[0]
                    
                    # Split ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ ‡πÅ‡∏ó‡∏ô csv.reader ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á 'lo' error
                    current_line_parts_raw = first_line_of_block.split(',')
                    header_template_parts_count = len(section_raw_headers[section_name].split(','))

                    # Logic ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å Header ‡πÅ‡∏•‡∏∞ Data Row ‡πÅ‡∏£‡∏Å
                    if len(current_line_parts_raw) >= header_template_parts_count:
                        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤ header template ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏°‡∏µ data ‡∏ï‡∏¥‡∏î‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢
                        first_data_row_extracted = current_line_parts_raw[header_template_parts_count:]
                        # ‡∏ô‡∏≥ data ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤ join ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô CSV line
                        if any(p.strip() for p in first_data_row_extracted): # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡πÜ
                            table_data_lines.append(','.join(first_data_row_extracted))
                    
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ (‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà 2 ‡∏Ç‡∏≠‡∏á block)
                    for line_val in raw_section_lines_block[1:]:
                        line_val_stripped = line_val.strip()
                        if not line_val_stripped: continue # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á

                        # Heuristic ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡∏™‡∏£‡∏∏‡∏õ
                        if line_val_stripped.startswith(("Name:", "Account:", "Company:", "Date:", "Results", "Balance:", "Total Net Profit:", "Average consecutive losses")):
                            break
                        
                        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Orders ‡∏ó‡∏µ‡πà Comment ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô ‡πÉ‡∏´‡πâ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏°‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Comment ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                        if section_name == "Orders":
                            parts = list(csv.reader(io.StringIO(line_val_stripped)))[0] # ‡πÉ‡∏ä‡πâ csv.reader ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
                            if len(parts) > len(expected_cleaned_columns[section_name]):
                                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà expected_cleaned_columns ‡∏Å‡∏≥‡∏´‡∏ô‡∏î
                                # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏°‡∏≤‡∏Ñ‡∏∑‡∏≠ Comment ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô
                                comment_parts = parts[len(expected_cleaned_columns[section_name])-1:]
                                cleaned_line = ','.join(parts[:len(expected_cleaned_columns[section_name])-1]) + ',' + ' '.join(comment_parts)
                                table_data_lines.append(cleaned_line)
                            else:
                                table_data_lines.append(line_val_stripped)
                        else:
                            table_data_lines.append(line_val_stripped)

                csv_string_data_to_parse = "\n".join(table_data_lines)
                
                # DEBUG: Add this to see the CSV string being passed to pandas
                if st.session_state.get("debug_statement_processing", False):
                    st.write(f"DEBUG: CSV string for {section_name} (before pandas):")
                    st.code(csv_string_data_to_parse)

                if csv_string_data_to_parse.strip():
                    try:
                        df = pd.read_csv(io.StringIO(csv_string_data_to_parse),
                                         sep=',',
                                         names=expected_cleaned_columns[section_name],
                                         header=None,
                                         skipinitialspace=True,
                                         on_bad_lines='warn',
                                         engine='python')
                        
                        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 'Unnamed: X')
                        df = df.dropna(axis=1, how='all')
                        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

                        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Orders: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Comment ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà Comment ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                        if section_name == "Orders":
                            # ‡∏£‡∏ß‡∏° CommentX (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Comment ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                            comment_cols = [col for col in df.columns if col.startswith('Comment')]
                            if comment_cols:
                                df['Comment'] = df[comment_cols].fillna('').agg(' '.join, axis=1).str.strip()
                                df.drop(columns=comment_cols, inplace=True, errors='ignore')
                            if 'Comment' not in df.columns: # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Comment ‡∏Å‡πá‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡πà‡∏≤‡∏á
                                df['Comment'] = ''

                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö expected_cleaned_columns
                        # ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° NaN
                        for col_name in expected_cleaned_columns[section_name]:
                            if col_name not in df.columns:
                                df[col_name] = np.nan
                        
                        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà expected_cleaned_columns ‡∏Å‡∏≥‡∏´‡∏ô‡∏î
                        df = df[expected_cleaned_columns[section_name]]
                        
                        df.dropna(how='all', inplace=True) # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏≠‡∏≠‡∏Å

                        dfs_output[section_key_lower] = df
                    except ValueError as ve:
                        st.error(f"‚ùå Column mismatch or data type error in {section_name}: {ve}. Expected {len(expected_cleaned_columns[section_name])} columns.")
                        dfs_output[section_key_lower] = pd.DataFrame()
                    except Exception as e:
                        st.error(f"‚ùå Error creating DataFrame for {section_name}: {e}")
                        dfs_output[section_key_lower] = pd.DataFrame()
                else:
                    st.warning(f"No valid data rows collected for {section_name} table in the uploaded file.")
                    dfs_output[section_key_lower] = pd.DataFrame()
            else:
                dfs_output[section_key_lower] = pd.DataFrame() # ‡∏Ñ‡∏∑‡∏ô DataFrame ‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö Section

        # --- Extract Balance Summary and Results Summary (non-table sections) ---
        balance_summary_dict = {}
        results_summary_dict = {}
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á Balance Summary
        balance_start_line_idx = -1
        for i, line in enumerate(lines):
            if line.strip().startswith("Balance:"):
                balance_start_line_idx = i
                break

        if balance_start_line_idx != -1:
            for i in range(balance_start_line_idx, len(lines)):
                line_stripped = lines[i].strip()
                if not line_stripped or line_stripped.startswith(("Results", "Total Net Profit:")):
                    break
                
                parts = [p.strip() for p in line_stripped.split(',')]
                
                def safe_float_convert(value_str):
                    try:
                        return float(value_str.replace(" ", "").replace(",", "").replace("%", ""))
                    except ValueError:
                        return None

                for part in parts:
                    key = ""
                    value_str = ""
                    if ':' in part: # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Key: Value
                        key_val = part.split(':', 1)
                        key = key_val[0].strip()
                        value_str = key_val[1].strip()
                    else: # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Key Value (‡πÑ‡∏°‡πà‡∏°‡∏µ colon)
                        last_space_idx = part.rfind(' ')
                        if last_space_idx != -1:
                            key = part[:last_space_idx].strip()
                            value_str = part[last_space_idx+1:].strip()
                    
                    if key:
                        cleaned_key = key.replace(" ", "_").replace(".", "").strip()
                        if cleaned_key: # Ensure cleaned key is not empty
                            balance_summary_dict[cleaned_key] = safe_float_convert(value_str)

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á Results Summary
        results_start_line_idx = -1
        for i, line in enumerate(lines):
            if line.strip().startswith("Results") or line.strip().startswith("Total Net Profit:"):
                results_start_line_idx = i
                break
        
        if results_start_line_idx != -1:
            for i in range(results_start_line_idx, len(lines)): # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠ Results ‡πÄ‡∏•‡∏¢
                line_stripped = lines[i].strip()
                if not line_stripped or line_stripped.startswith("Average consecutive losses"):
                    break
                
                parts = [p.strip() for p in line_stripped.split(',')]
                for part in parts:
                    key = ""
                    value_str = ""
                    
                    if ':' in part:
                        key_val = part.split(':', 1)
                        key = key_val[0].strip()
                        value_str = key_val[1].strip()
                    elif ' ' in part and len(part.split()) > 1:
                        last_space_idx = part.rfind(' ')
                        if last_space_idx != -1:
                            key = part[:last_space_idx].strip()
                            value_str = part[last_space_idx+1:].strip()
                    
                    if key:
                        cleaned_key = key.replace("(", "").replace(")", "").replace("/", "_").replace("-", "_").replace(" ", "_").replace("__", "_").strip()
                        if "won %" in cleaned_key: # Specific handle "won %" in key names
                            cleaned_key = cleaned_key.replace("won %", "won_Percent")
                        
                        try:
                            results_summary_dict[cleaned_key] = safe_float_convert(value_str)
                        except Exception:
                            results_summary_dict[cleaned_key] = value_str # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô string ‡∏ñ‡πâ‡∏≤ convert ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

        dfs_output['balance_summary'] = balance_summary_dict
        dfs_output['results_summary'] = results_summary_dict

        return dfs_output

    # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Deals ‡∏•‡∏á‡πÉ‡∏ô‡∏ä‡∏µ‡∏ó ActualTrades ---
    def save_deals_to_actual_trades(df_deals, portfolio_id, portfolio_name, source_file_name="N/A"):
        gc = get_gspread_client()
        if not gc: return False
        try:
            sh = gc.open(GOOGLE_SHEET_NAME)
            ws = sh.worksheet(WORKSHEET_ACTUAL_TRADES)
            expected_headers = [
                "Time", "Deal", "Symbol", "Type", "Direction", "Volume", "Price", "Order",
                "Commission", "Fee", "Swap", "Profit", "Balance", "Comment",
                "PortfolioID", "PortfolioName", "SourceFile"
            ]
            
            current_headers = []
            if ws.row_count > 0: current_headers = ws.row_values(1)
            if not current_headers or all(h == "" for h in current_headers): ws.append_row(expected_headers)

            rows_to_append = []
            for index, row in df_deals.iterrows():
                row_data = {
                    "Time": row.get("Time", ""),
                    "Deal": row.get("Deal", ""),
                    "Symbol": row.get("Symbol", ""),
                    "Type": row.get("Type", ""),
                    "Direction": row.get("Direction", ""),
                    "Volume": row.get("Volume", ""),
                    "Price": row.get("Price", ""),
                    "Order": row.get("Order", ""),
                    "Commission": row.get("Commission", ""),
                    "Fee": row.get("Fee", ""),
                    "Swap": row.get("Swap", ""),
                    "Profit": row.get("Profit", ""),
                    "Balance": row.get("Balance", ""),
                    "Comment": row.get("Comment", ""),
                    "PortfolioID": portfolio_id,
                    "PortfolioName": portfolio_name,
                    "SourceFile": source_file_name
                }
                rows_to_append.append([str(row_data.get(h, "")) for h in expected_headers])
            if rows_to_append: ws.append_rows(rows_to_append, value_input_option='USER_ENTERED'); return True
            return False
        except gspread.exceptions.WorksheetNotFound:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet '{WORKSHEET_ACTUAL_TRADES}'. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Headers: {', '.join(expected_headers)}")
            return False
        except Exception as e: st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Deals: {e}"); return False

    # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Positions ‡∏•‡∏á‡πÉ‡∏ô‡∏ä‡∏µ‡∏ó ActualPositions ---
    def save_positions_to_gsheets(df_positions, portfolio_id, portfolio_name, source_file_name="N/A"):
        gc = get_gspread_client()
        if not gc: return False
        try:
            sh = gc.open(GOOGLE_SHEET_NAME)
            ws = sh.worksheet(WORKSHEET_ACTUAL_POSITIONS)
            expected_headers = [
                "Time", "Position", "Symbol", "Type", "Volume", "Price", "S_L", "T_P",
                "Close_Time", "Close_Price", "Commission", "Swap", "Profit",
                "PortfolioID", "PortfolioName", "SourceFile"
            ]
            
            current_headers = []
            if ws.row_count > 0: current_headers = ws.row_values(1)
            if not current_headers or all(h == "" for h in current_headers): ws.append_row(expected_headers)

            rows_to_append = []
            for index, row in df_positions.iterrows():
                row_data = {
                    "Time": row.get("Time", ""),
                    "Position": row.get("Position", ""),
                    "Symbol": row.get("Symbol", ""),
                    "Type": row.get("Type", ""),
                    "Volume": row.get("Volume", ""),
                    "Price": row.get("Price", ""),
                    "S_L": row.get("S_L", ""),
                    "T_P": row.get("T_P", ""),
                    "Close_Time": row.get("Close_Time", ""),
                    "Close_Price": row.get("Close_Price", ""),
                    "Commission": row.get("Commission", ""),
                    "Swap": row.get("Swap", ""),
                    "Profit": row.get("Profit", ""),
                    "PortfolioID": portfolio_id,
                    "PortfolioName": portfolio_name,
                    "SourceFile": source_file_name
                }
                rows_to_append.append([str(row_data.get(h, "")) for h in expected_headers])
            if rows_to_append: ws.append_rows(rows_to_append, value_input_option='USER_ENTERED'); return True
            return False
        except gspread.exceptions.WorksheetNotFound:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet '{WORKSHEET_ACTUAL_POSITIONS}'. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Headers: {', '.join(expected_headers)}")
            return False
        except Exception as e: st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Positions: {e}"); return False

    # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Orders ‡∏•‡∏á‡πÉ‡∏ô‡∏ä‡∏µ‡∏ó ActualOrders ---
    def save_orders_to_gsheets(df_orders, portfolio_id, portfolio_name, source_file_name="N/A"):
        gc = get_gspread_client()
        if not gc: return False
        try:
            sh = gc.open(GOOGLE_SHEET_NAME)
            ws = sh.worksheet(WORKSHEET_ACTUAL_ORDERS)
            expected_headers = [
                "Open_Time", "Order", "Symbol", "Type", "Volume", "Price", "S_L", "T_P",
                "Close_Time", "State", "Comment",
                "PortfolioID", "PortfolioName", "SourceFile"
            ]
            
            current_headers = []
            if ws.row_count > 0: current_headers = ws.row_values(1)
            if not current_headers or all(h == "" for h in current_headers): ws.append_row(expected_headers)

            rows_to_append = []
            for index, row in df_orders.iterrows():
                row_data = {
                    "Open_Time": row.get("Open_Time", ""),
                    "Order": row.get("Order", ""),
                    "Symbol": row.get("Symbol", ""),
                    "Type": row.get("Type", ""),
                    "Volume": row.get("Volume", ""),
                    "Price": row.get("Price", ""),
                    "S_L": row.get("S_L", ""),
                    "T_P": row.get("T_P", ""),
                    "Close_Time": row.get("Close_Time", ""),
                    "State": row.get("State", ""),
                    "Comment": row.get("Comment", ""),
                    "PortfolioID": portfolio_id,
                    "PortfolioName": portfolio_name,
                    "SourceFile": source_file_name
                }
                rows_to_append.append([str(row_data.get(h, "")) for h in expected_headers])
            if rows_to_append: ws.append_rows(rows_to_append, value_input_option='USER_ENTERED'); return True
            return False
        except gspread.exceptions.WorksheetNotFound:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet '{WORKSHEET_ACTUAL_ORDERS}'. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Headers: {', '.join(expected_headers)}")
            return False
        except Exception as e: st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Orders: {e}"); return False

    # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Results Summary ‡∏•‡∏á‡πÉ‡∏ô‡∏ä‡∏µ‡∏ó StatementSummaries ---
    def save_results_summary_to_gsheets(summary_dict, portfolio_id, portfolio_name, source_file_name="N/A"):
        gc = get_gspread_client()
        if not gc: return False
        try:
            sh = gc.open(GOOGLE_SHEET_NAME)
            ws = sh.worksheet(WORKSHEET_STATEMENT_SUMMARIES)
            
            expected_headers = [
                "Timestamp", "PortfolioID", "PortfolioName", "SourceFile", 
                "Total_Net_Profit", "Gross_Profit", "Gross_Loss", "Profit_Factor", 
                "Expected_Payoff", "Recovery_Factor", "Sharpe_Ratio", 
                "Balance_Drawdown_Absolute", "Balance_Drawdown_Maximal", 
                "Balance_Drawdown_Maximal_Percent", "Balance_Drawdown_Relative", 
                "Balance_Drawdown_Relative_Percent", "Total_Trades", 
                "Short_Trades", "Short_Trades_won_Percent", "Long_Trades", 
                "Long_Trades_won_Percent", "Profit_Trades", "Profit_Trades_Percent_of_total", 
                "Loss_Trades", "Loss_Trades_Percent_of_total", "Largest_profit_trade", 
                "Largest_loss_trade", "Average_profit_trade", "Average_loss_trade", 
                "Maximum_consecutive_wins_Count", "Maximum_consecutive_wins_Profit", 
                "Maximum_consecutive_losses_Count", "Maximum_consecutive_losses_Profit",
                "Maximal_consecutive_profit_Count", "Maximal_consecutive_profit_Amount",
                "Maximal_consecutive_loss_Count", "Maximal_consecutive_loss_Amount",
                "Average_consecutive_wins", "Average_consecutive_losses"
            ]
            
            current_headers = []
            if ws.row_count > 0: current_headers = ws.row_values(1)
            if not current_headers or all(h == "" for h in current_headers): ws.append_row(expected_headers)

            rows_to_append = []
            row_data = {
                "Timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "PortfolioID": portfolio_id,
                "PortfolioName": portfolio_name,
                "SourceFile": source_file_name
            }
            for key, value in summary_dict.items():
                cleaned_key = key.replace(" ", "_").replace("%", "Percent").replace("(won_%)", "won_Percent").replace("__", "_").strip()
                if "TotalNetProfit" in cleaned_key: cleaned_key = "Total_Net_Profit"

                if cleaned_key in expected_headers:
                    row_data[cleaned_key] = value
            
            final_row_data = [str(row_data.get(h, "")) for h in expected_headers]

            rows_to_append.append(final_row_data)
            
            if rows_to_append: ws.append_rows(rows_to_append, value_input_option='USER_ENTERED'); return True
            return False
        except gspread.exceptions.WorksheetNotFound:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet '{WORKSHEET_STATEMENT_SUMMARIES}'. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà Headers: {', '.join(expected_headers)}")
            return False
        except Exception as e: st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Statement Summaries: {e}"); return False


    st.markdown("---")
    st.subheader("üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Statement Report (CSV) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
    
    uploaded_file_statement = st.file_uploader( 
        "‡∏•‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Statement Report (CSV) ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå",
        type=["csv"],
        key="full_stmt_uploader"
    )

    st.checkbox("‚öôÔ∏è ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏´‡∏°‡∏î Debug (‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ)", key="debug_statement_processing")
    
    active_portfolio_id_for_actual = st.session_state.get('active_portfolio_id_gs', None)
    active_portfolio_name_for_actual = st.session_state.get('active_portfolio_name_gs', None)

    if uploaded_file_statement:
        file_name_for_saving = uploaded_file_statement.name
        
        file_content_str = uploaded_file_statement.getvalue().decode("utf-8")
        
        st.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå: {uploaded_file_statement.name}")
        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {uploaded_file_statement.name}..."):
            extracted_sections = extract_data_from_report_content(file_content_str)
            
            if st.session_state.get("debug_statement_processing", False):
                st.subheader("üìÑ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ (Debug)")
                for section_name, data_item in extracted_sections.items():
                    st.write(f"#### {section_name.replace('_',' ').title()}")
                    if isinstance(data_item, pd.DataFrame):
                        if not data_item.empty:
                            st.dataframe(data_item)
                        else:
                            st.info(f"DataFrame for {section_name.replace('_',' ').title()} is empty.")
                    else:
                        st.json(data_item)

            if not active_portfolio_id_for_actual:
                st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏û‡∏≠‡∏£‡πå‡∏ï‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Active Portfolio) ‡πÉ‡∏ô Sidebar ‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Statement.")
            else:
                st.markdown("---")
                st.subheader("üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets...")
                
                if not extracted_sections.get('deals', pd.DataFrame()).empty:
                    if save_deals_to_actual_trades(extracted_sections['deals'], active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving):
                        st.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Deals ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(extracted_sections['deals'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ä‡∏µ‡∏ï 'ActualTrades' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                        st.session_state.df_stmt_deals = extracted_sections['deals'].copy()
                    else: st.error("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Deals ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
                else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Deals ‡πÉ‡∏ô Statement.")

                if not extracted_sections.get('orders', pd.DataFrame()).empty:
                    if save_orders_to_gsheets(extracted_sections['orders'], active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving):
                        st.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Orders ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(extracted_sections['orders'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ä‡∏µ‡∏ï 'ActualOrders' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                    else: st.error("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Orders ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
                else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Orders ‡πÉ‡∏ô Statement.")
                
                if not extracted_sections.get('positions', pd.DataFrame()).empty:
                    if save_positions_to_gsheets(extracted_sections['positions'], active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving):
                        st.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Positions ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(extracted_sections['positions'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ä‡∏µ‡∏ï 'ActualPositions' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                    else: st.error("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Positions ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
                else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Positions ‡πÉ‡∏ô Statement.")

                if extracted_sections.get('results_summary'):
                    if save_results_summary_to_gsheets(extracted_sections['results_summary'], active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving):
                        st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Results Summary ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ä‡∏µ‡∏ó 'StatementSummaries' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                    else: st.error("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Results Summary ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à.")
                else: st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Results Summary ‡πÉ‡∏ô Statement.")

    else:
        st.info("‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Statement Report (CSV) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•.")

    st.markdown("---")

# ===================== SEC 8: MAIN AREA - PERFORMANCE DASHBOARD =======================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î ‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö source_option ‡∏à‡∏≤‡∏Å selectbox ‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å
def load_data_for_dashboard(source_option_param):
    df_dashboard_data = pd.DataFrame()
    if source_option_param == "Planned Trades (Google Sheets)":
        gc_dash = get_gspread_client()
        if gc_dash:
            try:
                sh_dash = gc_dash.open(GOOGLE_SHEET_NAME)
                ws_dash_logs = sh_dash.worksheet(WORKSHEET_PLANNED_LOGS)
                records_dash = ws_dash_logs.get_all_records()
                if records_dash:
                    df_dashboard_data = pd.DataFrame(records_dash)
                    if 'Risk $' in df_dashboard_data.columns:
                        df_dashboard_data['Profit'] = pd.to_numeric(df_dashboard_data['Risk $'], errors='coerce').fillna(0)
                    if 'Timestamp' in df_dashboard_data.columns:
                        df_dashboard_data['Time'] = pd.to_datetime(df_dashboard_data['Timestamp'], errors='coerce')
                    if 'RR' in df_dashboard_data.columns:
                         df_dashboard_data['RR'] = pd.to_numeric(df_dashboard_data['RR'], errors='coerce')
                    if 'Lot' in df_dashboard_data.columns:
                         df_dashboard_data['Lot'] = pd.to_numeric(df_dashboard_data['Lot'], errors='coerce')
                    if 'Asset' in df_dashboard_data.columns:
                        df_dashboard_data.rename(columns={'Asset': 'Symbol'}, inplace=True)

            except Exception as e:
                st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î Planned Trades ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dashboard: {e}")
        st.caption("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ä‡∏µ‡∏ï 'PlannedTradeLogs'")

    else: # Actual Trades (Statement Import)
        df_dashboard_data = st.session_state.get('df_stmt_deals', pd.DataFrame()).copy()
        if not df_dashboard_data.empty:
            rename_map = {} 
            for col in df_dashboard_data.columns:
                col_lower = col.lower()
                if 'profit' in col_lower and 'Profit' not in rename_map.values(): rename_map[col] = 'Profit'
                if 'time' in col_lower and 'open time' not in col_lower and 'Time' not in rename_map.values(): rename_map[col] = 'Time'
                if 'open time' in col_lower and 'Open Time' not in rename_map.values(): rename_map[col] = 'Open Time'
                if 'symbol' in col_lower and 'Symbol' not in rename_map.values(): rename_map[col] = 'Symbol'
                if 'volume' in col_lower or 'lots' in col_lower and 'Lot' not in rename_map.values(): rename_map[col] = 'Lot'

            df_dashboard_data.rename(columns=rename_map, inplace=True)

            if 'Profit' in df_dashboard_data.columns:
                df_dashboard_data['Profit'] = pd.to_numeric(df_dashboard_data['Profit'], errors='coerce').fillna(0)
            if 'Time' in df_dashboard_data.columns:
                df_dashboard_data['Time'] = pd.to_datetime(df_dashboard_data['Time'], errors='coerce')
            elif 'Open Time' in df_dashboard_data.columns:
                 df_dashboard_data['Time'] = pd.to_datetime(df_dashboard_data['Open Time'], errors='coerce')
            if 'Lot' in df_dashboard_data.columns:
                df_dashboard_data['Lot'] = pd.to_numeric(df_dashboard_data['Lot'], errors='coerce').fillna(0)

        st.caption("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Statement ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (Deals)")
        
    return df_dashboard_data


with st.expander("üìä Performance Dashboard", expanded=True):
    # ‡∏¢‡πâ‡∏≤‡∏¢ st.selectbox ‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡∏ô‡∏≠‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô load_data_for_dashboard)
    source_option = st.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î:",
        ["Planned Trades (Google Sheets)", "Actual Trades (Statement Import)"],
        index=0,
        key="dashboard_source_selector" # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ key ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥
    )
    
    df_data_dash = load_data_for_dashboard(source_option) # ‡∏™‡πà‡∏á source_option ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ

    if df_data_dash.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dashboard ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
    else:
        required_cols_present = True
        if 'Profit' not in df_data_dash.columns:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Profit' ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dashboard")
            required_cols_present = False
        if 'Time' not in df_data_dash.columns:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Time' (‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤) ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dashboard")
            required_cols_present = False
        
        if not required_cols_present:
            st.stop()

        st.markdown("#### ‚öôÔ∏è Filters")
        col_filter1, col_filter2 = st.columns(2)

        with col_filter1:
            portfolio_col_name = None
            if "Portfolio" in df_data_dash.columns and df_data_dash["Portfolio"].notna().any():
                portfolio_col_name = "Portfolio"
            elif "PortfolioName" in df_data_dash.columns and df_data_dash["PortfolioName"].notna().any():
                portfolio_col_name = "PortfolioName"
            
            if portfolio_col_name:
                portfolio_list_dash = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df_data_dash[portfolio_col_name].dropna().unique().tolist())
                selected_portfolio_dash = st.selectbox(
                    "üìÇ Filter by Portfolio", portfolio_list_dash, key="dash_portfolio_filter"
                )
                if selected_portfolio_dash != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                    df_data_dash = df_data_dash[df_data_dash[portfolio_col_name] == selected_portfolio_dash]
            else:
                st.selectbox("üìÇ Filter by Portfolio", ["- (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏≠‡∏£‡πå‡∏ï)"], disabled=True, key="dash_portfolio_filter_disabled")
        
        with col_filter2:
            symbol_col_name = None
            if "Symbol" in df_data_dash.columns and df_data_dash["Symbol"].notna().any():
                symbol_col_name = "Symbol"
            
            if symbol_col_name:
                asset_list_dash = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df_data_dash[symbol_col_name].dropna().unique().tolist())
                selected_asset_dash = st.selectbox(
                    f"üéØ Filter by {symbol_col_name}", asset_list_dash, key="dash_asset_filter"
                )
                if selected_asset_dash != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
                    df_data_dash = df_data_dash[df_data_dash[symbol_col_name] == selected_asset_dash]
            else:
                st.selectbox("üéØ Filter by Asset/Symbol", ["- (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Symbol)"], disabled=True, key="dash_asset_filter_disabled")
        
        st.markdown("---")

        tab_names = ["üìä Dashboard", "üìà RR Analysis", "üìâ Lot Size", "üïí Time Analysis", "ü§ñ AI Insight", "‚¨áÔ∏è Export"]
        # Conditionally remove RR tab if RR column not present or not relevant for 'Actual Trades'
        if 'RR' not in df_data_dash.columns and source_option == "Actual Trades (Statement Import)":
            if "üìà RR Analysis" in tab_names: tab_names.remove("üìà RR Analysis")
        
        tabs = st.tabs(tab_names)
        
        with tabs[0]:
            st.markdown("### ‚öñÔ∏è Win/Loss Ratio")
            win_count_dash = df_data_dash[df_data_dash['Profit'] > 0].shape[0]
            loss_count_dash = df_data_dash[df_data_dash['Profit'] <= 0].shape[0]
            if win_count_dash + loss_count_dash > 0:
                pie_df_dash = pd.DataFrame({"Result": ["Win", "Loss"], "Count": [win_count_dash, loss_count_dash]})
                pie_chart_dash = px.pie(pie_df_dash, names="Result", values="Count", color="Result",
                                        color_discrete_map={"Win": "mediumseagreen", "Loss": "indianred"}, title="Win vs Loss Trades")
                st.plotly_chart(pie_chart_dash, use_container_width=True)
            else:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Win/Loss ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Pie Chart")

            st.markdown("### üóìÔ∏è Daily Profit/Loss")
            df_data_dash['TradeDate'] = df_data_dash['Time'].dt.date
            daily_pnl_df = df_data_dash.groupby("TradeDate")['Profit'].sum().reset_index(name="Daily P/L")
            daily_bar_chart = px.bar(daily_pnl_df, x="TradeDate", y="Daily P/L", 
                                     color="Daily P/L", title="‡∏Å‡∏≥‡πÑ‡∏£/‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô",
                                     color_continuous_scale=["indianred", "lightgrey", "mediumseagreen"])
            st.plotly_chart(daily_bar_chart, use_container_width=True)

            st.markdown("### üìâ Balance Curve (Equity Timeline)")
            df_data_dash_sorted = df_data_dash.sort_values(by="Time")
            df_data_dash_sorted["Balance"] = acc_balance + df_data_dash_sorted['Profit'].cumsum()
            balance_curve_chart = px.line(df_data_dash_sorted, x="Time", y="Balance", markers=True, title="Balance Curve")
            balance_curve_chart.update_traces(line_color='deepskyblue')
            st.plotly_chart(balance_curve_chart, use_container_width=True)

        rr_tab_index = -1
        if "üìà RR Analysis" in tab_names:
            rr_tab_index = tab_names.index("üìà RR Analysis")
        
        if rr_tab_index != -1:
            with tabs[rr_tab_index]:
                if 'RR' in df_data_dash.columns and not df_data_dash['RR'].dropna().empty:
                    rr_data_dash = df_data_dash['RR'].dropna()
                    st.markdown("#### Risk:Reward Ratio (RR) Histogram")
                    rr_hist = px.histogram(rr_data_dash, nbins=20, title="RR Distribution", labels={'value': 'RR Ratio'}, opacity=0.8)
                    rr_hist.update_layout(bargap=0.1, xaxis_title='Risk:Reward Ratio', yaxis_title='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡∏£‡∏î')
                    rr_hist.update_traces(marker_color='cornflowerblue')
                    st.plotly_chart(rr_hist, use_container_width=True)
                    st.caption("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á RR. RR ‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ 1.5 ‡∏´‡∏£‡∏∑‡∏≠ 2 ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏î‡∏µ.")
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• RR ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Histogram ‡∏ô‡∏µ‡πâ.")
        
        lot_tab_index = tab_names.index("üìâ Lot Size")
        with tabs[lot_tab_index]:
            if 'Lot' in df_data_dash.columns and not df_data_dash['Lot'].dropna().empty:
                st.markdown("#### Lot Size Over Time")
                lot_df_sorted = df_data_dash.dropna(subset=['Lot', 'Time']).sort_values(by="Time")
                lot_line_chart = px.line(lot_df_sorted, x="Time", y="Lot", markers=True, title="Lot Size Evolution")
                lot_line_chart.update_traces(line_color='goldenrod')
                st.plotly_chart(lot_line_chart, use_container_width=True)
                st.caption("‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡∏≠‡∏á Lot Size ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Money Management ‡πÅ‡∏•‡∏∞ Scaling.")
            else:
                st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Lot Size ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠.")

        time_analysis_tab_index = tab_names.index("üïí Time Analysis")
        with tabs[time_analysis_tab_index]:
            st.markdown("#### Performance by Day of Week")
            df_data_dash['Weekday'] = df_data_dash['Time'].dt.day_name()
            weekday_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
            weekday_pnl = df_data_dash.groupby("Weekday")['Profit'].sum().reindex(weekday_order).reset_index()
            weekday_chart = px.bar(weekday_pnl, x="Weekday", y="Profit", title="Total P/L by Day of Week", color="Profit",
                                   color_continuous_scale=["tomato", "lightgoldenrodyellow", "lightgreen"])
            st.plotly_chart(weekday_chart, use_container_width=True)
            st.caption("‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô‡πÉ‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏ó‡∏≥‡∏Å‡∏≥‡πÑ‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô.")

        ai_insight_tab_index = tab_names.index("ü§ñ AI Insight")
        with tabs[ai_insight_tab_index]:
            st.markdown("### AI Insight & Recommendation (Dashboard Data)")
            total_trades_dash_ai = df_data_dash.shape[0]
            winrate_dash_ai = (win_count_dash / total_trades_dash_ai * 100) if total_trades_dash_ai > 0 else 0
            gross_profit_dash_ai = df_data_dash['Profit'].sum()
            
            st.write(f"Trades in current view: {total_trades_dash_ai}")
            st.write(f"Winrate: {winrate_dash_ai:.2f}%")
            st.write(f"Net Profit: {gross_profit_dash_ai:,.2f} USD")
            
            try:
                if "google_api" in st.secrets and "GOOGLE_API_KEY" in st.secrets.google_api:
                    genai.configure(api_key=st.secrets.google_api.GOOGLE_API_KEY)
                    model_gemini = genai.GenerativeModel('gemini-pro')
                    prompt_text_dash = (
                        f"Analyze this trading performance: Total trades: {total_trades_dash_ai}, "
                        f"Winrate: {winrate_dash_ai:.2f}%, Net Profit/Loss: {gross_profit_dash_ai:,.2f} USD. "
                        f"Provide concise trading insights and recommendations for improvement. "
                        f"What are potential strengths and weaknesses? Focus on practical advice. Respond in Thai."
                    )
                    with st.spinner("ü§ñ Gemini AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Dashboard..."):
                        response_gemini = model_gemini.generate_content(prompt_text_dash)
                    st.markdown("---")
                    st.markdown("**‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏à‡∏≤‡∏Å Gemini AI:**")
                    st.write(response_gemini.text)
                else:
                    st.info("‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google API Key ‡πÉ‡∏ô `secrets.toml` (‡πÉ‡∏ï‡πâ `[google_api]`) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI Assistant ‡∏à‡∏≤‡∏Å Gemini.")
            except Exception as e_gemini:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Gemini AI: {e_gemini}")

        export_tab_index = tab_names.index("‚¨áÔ∏è Export")
        with tabs[export_tab_index]:
            st.markdown("### üìÑ Export Filtered Data")
            if not df_data_dash.empty:
                csv_export = df_data_dash.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• Download Data as CSV",
                    data=csv_export,
                    file_name=f"dashboard_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                )
            else:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Export.")

# ===================== SEC 9: MAIN AREA - TRADE LOG VIEWER =======================
@st.cache_data(ttl=120)
def load_planned_trades_from_gsheets_for_viewer():
    gc = get_gspread_client()
    if gc is None: return pd.DataFrame()
    try:
        sh = gc.open(GOOGLE_SHEET_NAME)
        worksheet = sh.worksheet(WORKSHEET_PLANNED_LOGS)
        records = worksheet.get_all_records()
        if not records: return pd.DataFrame()
        
        df_logs_viewer = pd.DataFrame(records)
        if 'Timestamp' in df_logs_viewer.columns:
            df_logs_viewer['Timestamp'] = pd.to_datetime(df_logs_viewer['Timestamp'], errors='coerce')
        
        cols_to_numeric_log_viewer = ['Risk %', 'Entry', 'SL', 'TP', 'Lot', 'Risk $', 'RR']
        for col_viewer in cols_to_numeric_log_viewer:
            if col_viewer in df_logs_viewer.columns:
                # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞ replace '' ‡πÄ‡∏õ‡πá‡∏ô 'NaN' ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                # ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÅ‡∏•‡πâ‡∏ß nan() ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤ default ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
                df_logs_viewer[col_viewer] = pd.to_numeric(df_logs_viewer[col_viewer], errors='coerce')
        
        return df_logs_viewer.sort_values(by="Timestamp", ascending=False) if 'Timestamp' in df_logs_viewer.columns else df_logs_viewer
    except gspread.exceptions.WorksheetNotFound:
        st.error(f"‚ùå Log Viewer: ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet '{WORKSHEET_PLANNED_LOGS}'.")
        return pd.DataFrame()
    except Exception as e_log_viewer:
        st.error(f"‚ùå Log Viewer: ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Log - {e_log_viewer}")
        return pd.DataFrame()

with st.expander("üìö Trade Log Viewer (‡πÅ‡∏ú‡∏ô‡πÄ‡∏ó‡∏£‡∏î‡∏à‡∏≤‡∏Å Google Sheets)", expanded=False):
    df_log_viewer_gs = load_planned_trades_from_gsheets_for_viewer()

    if df_log_viewer_gs.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Google Sheets ‡∏´‡∏£‡∏∑‡∏≠ Worksheet 'PlannedTradeLogs' ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤.")
    else:
        df_show_log_viewer = df_log_viewer_gs.copy()

        log_filter_cols = st.columns(4)
        with log_filter_cols[0]:
            portfolios_in_log = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df_show_log_viewer["PortfolioName"].dropna().unique().tolist()) if "PortfolioName" in df_show_log_viewer else ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"]
            portfolio_filter_log = st.selectbox("Portfolio", portfolios_in_log, key="log_viewer_portfolio_filter")
        with log_filter_cols[1]:
            modes_in_log = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df_show_log_viewer["Mode"].dropna().unique().tolist()) if "Mode" in df_show_log_viewer else ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"]
            mode_filter_log = st.selectbox("Mode", modes_in_log, key="log_viewer_mode_filter")
        with log_filter_cols[2]:
            assets_in_log = ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(df_show_log_viewer["Asset"].dropna().unique().tolist()) if "Asset" in df_show_log_viewer else ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"]
            asset_filter_log = st.selectbox("Asset", assets_in_log, key="log_viewer_asset_filter")
        with log_filter_cols[3]:
            date_filter_log = None
            if 'Timestamp' in df_show_log_viewer.columns and not df_show_log_viewer['Timestamp'].isnull().all():
                 date_filter_log = st.date_input("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (Log)", value=None, key="log_viewer_date_filter", help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≠‡∏á Log")


        if portfolio_filter_log != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" and "PortfolioName" in df_show_log_viewer:
            df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["PortfolioName"] == portfolio_filter_log]
        if mode_filter_log != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" and "Mode" in df_show_log_viewer:
            df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["Mode"] == mode_filter_log]
        if asset_filter_log != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î" and "Asset" in df_show_log_viewer:
            df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["Asset"] == asset_filter_log]
        if date_filter_log and 'Timestamp' in df_show_log_viewer:
            df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["Timestamp"].dt.date == date_filter_log]
        
        st.markdown("---")
        st.markdown("**Log Details & Actions:**")
        
        cols_to_display = {
            "Timestamp": "Timestamp", "PortfolioName": "Portfolio", "Asset": "Asset",
            "Mode": "Mode", "Direction": "Direction", "Entry": "Entry", "SL": "SL", "TP": "TP",
            "Lot": "Lot", "Risk $": "Risk $" , "RR": "RR"
        }
        actual_cols_to_display = {k:v for k,v in cols_to_display.items() if k in df_show_log_viewer.columns}
        
        num_display_cols = len(actual_cols_to_display)
        header_display_cols = st.columns(num_display_cols + 1)

        for i, (col_key, col_name) in enumerate(actual_cols_to_display.items()):
            header_display_cols[i].markdown(f"**{col_name}**")
        header_display_cols[num_display_cols].markdown(f"**Action**")


        for index_log, row_log in df_show_log_viewer.iterrows():
            row_display_cols = st.columns(num_display_cols + 1)
            for i, col_key in enumerate(actual_cols_to_display.keys()):
                val = row_log.get(col_key, "-")
                if isinstance(val, float):
                    row_display_cols[i].write(f"{val:.2f}" if not np.isnan(val) else "-")
                elif isinstance(val, pd.Timestamp):
                    row_display_cols[i].write(val.strftime("%Y-%m-%d %H:%M") if pd.notnull(val) else "-")
                else:
                    row_display_cols[i].write(str(val) if pd.notnull(val) and str(val).strip() != "" else "-")

            if row_display_cols[num_display_cols].button(f"üìà Plot", key=f"plot_log_{row_log.get('LogID', index_log)}"):
                st.session_state['plot_data'] = row_log.to_dict()
                st.success(f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏î '{row_log.get('Asset', '-')}' ‡∏ó‡∏µ‡πà Entry '{row_log.get('Entry', '-')}' ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Plot ‡∏ö‡∏ô Chart Visualizer!")
                st.rerun()
        
        if 'plot_data' in st.session_state and st.session_state['plot_data']:
            st.sidebar.success(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° Plot: {st.session_state['plot_data'].get('Asset')} @ {st.session_state['plot_data'].get('Entry')}")
            st.sidebar.json(st.session_state['plot_data'], expanded=False)
