# ======================= SEC 0: IMPORT & CONFIG =======================
import streamlit as st
import pandas as pd
import openpyxl  
import numpy as np
import os
from datetime import datetime
import plotly.express as px
import google.generativeai as genai
import gspread # <--- ‡πÄ‡∏û‡∏¥‡πà‡∏° import gspread ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà

st.set_page_config(page_title="Ultimate-Chart", layout="wide")
acc_balance = 10000 
log_file = "trade_log.csv"


# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ Google Sheet ‡πÅ‡∏•‡∏∞ Worksheet ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement
GOOGLE_SHEET_NAME = "TradeLog" # **‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠ Google Sheet ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì**
GOOGLE_WORKSHEET_NAME = "Uploaded Statements" # ‡∏ä‡∏∑‡πà‡∏≠ Worksheet ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö Statement

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ gspread
def get_gspread_client():
    try:
        if "gcp_service_account" not in st.secrets:
            st.warning("‚ö†Ô∏è ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ 'gcp_service_account' ‡πÉ‡∏ô `.streamlit/secrets.toml` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets.")
            return None
        return gspread.service_account_from_dict(st.secrets["gcp_service_account"])
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets: {e}")
        st.info("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ 'gcp_service_account' ‡πÉ‡∏ô secrets.toml ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡πÅ‡∏ä‡∏£‡πå Sheet ‡∏Å‡∏±‡∏ö Service Account ‡πÅ‡∏•‡πâ‡∏ß")
        return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡∏à‡∏≤‡∏Å Google Sheets
import pandas as pd # <-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå main.py
import gspread     # <-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå main.py
import streamlit as st # <-- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå main.py

@st.cache_data(ttl=3600)
def load_statement_from_gsheets():
    gc = get_gspread_client()
    if gc is None:
        return {}

    try:
        sh = gc.open(GOOGLE_SHEET_NAME)
        try:
            worksheet = sh.worksheet(GOOGLE_WORKSHEET_NAME)
        except gspread.exceptions.WorksheetNotFound:
            st.info(f"‚ú® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Worksheet '{GOOGLE_WORKSHEET_NAME}' ‡πÉ‡∏ô Google Sheet '{GOOGLE_SHEET_NAME}'...")
            worksheet = sh.add_worksheet(title=GOOGLE_WORKSHEET_NAME, rows="1", cols="1")
            return {}

        all_sheet_values = worksheet.get_all_values()

        if not all_sheet_values or len(all_sheet_values) < 2:
            st.info(f"Worksheet '{GOOGLE_WORKSHEET_NAME}' ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ.")
            return {}

        parser_config = {
            "positions": {
                "start_keyword": "Positions",
                "header_row_offset": 1, 
                "end_keyword": "Orders"
            },
            "orders": {
                "start_keyword": "Orders",
                "header_row_offset": 1,
                "end_keyword": "Deals"
            },
            "deals": {
                "start_keyword": "Deals",
                "header_row_offset": 1,
                "end_keyword": "Balance" 
            },
            "balance_summary": { # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                "start_keyword": "Balance",
                "header_row_offset": 0, # ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 1 ‡∏ñ‡πâ‡∏≤‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Balance
                "end_keyword": "Drawdown"
            },
            # *** ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ***
            # ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏à‡∏≤‡∏Å Statement ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ß‡πà‡∏≤‡∏°‡∏µ Keyword ‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏±‡πâ‡∏ô
            # ‡πÅ‡∏•‡∏∞‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Keyword ‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡∏µ‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (header_row_offset)
            # ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà Keyword ‡∏≠‡∏∞‡πÑ‡∏£ (end_keyword)
        }

        all_sections_dfs = {}
        st.write("--- ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---")

        for section_name, config in parser_config.items():
            start_row_idx = -1
            end_row_idx = -1

            for i, row in enumerate(all_sheet_values):
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ start_keyword ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏∑‡πà‡∏ô
                # ‡πÉ‡∏ä‡πâ " ".join(row) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
                if config["start_keyword"] in " ".join(row): 
                    start_row_idx = i
                    break

            if start_row_idx == -1:
                st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡πà‡∏ß‡∏ô '{section_name}' ‡∏î‡πâ‡∏ß‡∏¢ keyword: '{config['start_keyword']}'.")
                continue

            if "end_keyword" in config and config["end_keyword"]:
                for i in range(start_row_idx + 1, len(all_sheet_values)):
                    if config["end_keyword"] in " ".join(all_sheet_values[i]):
                        end_row_idx = i
                        break

            if end_row_idx == -1:
                end_row_idx = len(all_sheet_values)

            header_row_actual_idx = start_row_idx + config["header_row_offset"]

            if header_row_actual_idx >= len(all_sheet_values):
                st.warning(f"‚ö†Ô∏è ‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô '{section_name}' ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï. ‡∏Ç‡πâ‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ.")
                continue

            header = all_sheet_values[header_row_actual_idx]
            clean_header = [h for h in header if h.strip() != '']

            if not clean_header:
                st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô '{section_name}'. ‡∏Ç‡πâ‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ.")
                continue

            # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÉ‡∏ô header ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            # ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÜ
            col_indices = []
            for i, h_val in enumerate(header):
                if h_val.strip() != '':
                    col_indices.append(i)
                elif len(col_indices) > 0 and (i - col_indices[-1] == 1): # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡∏±‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    # ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÄ‡∏ã‡∏•‡∏•‡πå‡πÉ‡∏ô Excel
                    # ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    # ‡πÅ‡∏ï‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏û‡∏∂‡πà‡∏á clean_header ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏¢
                    pass


            section_raw_data = []
            for row_idx in range(header_row_actual_idx + 1, end_row_idx):
                current_row = all_sheet_values[row_idx]
                if not any(c.strip() for c in current_row):
                    break

                # ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô clean_header
                truncated_row = [current_row[idx] if idx < len(current_row) else '' for idx in col_indices]
                section_raw_data.append(truncated_row)

            if section_raw_data:
                df_section = pd.DataFrame(section_raw_data, columns=clean_header)
                df_section.replace('', pd.NA, inplace=True)
                df_section.dropna(how='all', inplace=True)

                if not df_section.empty:
                    all_sections_dfs[section_name] = df_section
                    st.success(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô '{section_name}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ({len(df_section)} ‡πÅ‡∏ñ‡∏ß).")
                else:
                    st.info(f"‡∏™‡πà‡∏ß‡∏ô '{section_name}' ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÑ‡∏î‡πâ.")
            else:
                st.info(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô '{section_name}'.")

        if all_sections_dfs:
            st.success(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Google Sheet '{GOOGLE_SHEET_NAME}/{GOOGLE_WORKSHEET_NAME}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏î‡πÜ ‡πÉ‡∏ô Google Sheet. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå Statement ‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á.")

        return all_sections_dfs

    except gspread.exceptions.SpreadsheetNotFound:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Google Sheet ‡∏ä‡∏∑‡πà‡∏≠ '{GOOGLE_SHEET_NAME}'. ‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏ä‡∏£‡πå‡∏Å‡∏±‡∏ö Service Account ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")
        return {}
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡∏à‡∏≤‡∏Å Google Sheets: {e}")
        st.exception(e)
        return {}

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å DataFrame ‡∏•‡∏á Google Sheets (‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤)
# (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)

def save_statement_to_gsheets(df_to_save):
    if df_to_save.empty:
        st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets.")
        return

    gc = get_gspread_client()
    if gc is None:
        return

    try:
        sh = gc.open(GOOGLE_SHEET_NAME)
        try:
            worksheet = sh.worksheet(GOOGLE_WORKSHEET_NAME)
        except gspread.exceptions.WorksheetNotFound:
            st.info(f"‚ú® ‡∏™‡∏£‡πâ‡∏≤‡∏á Worksheet '{GOOGLE_WORKSHEET_NAME}' ‡πÉ‡∏ô Google Sheet '{GOOGLE_SHEET_NAME}'")
            worksheet = sh.add_worksheet(title=GOOGLE_WORKSHEET_NAME, rows="1", cols="1")

        # --- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ ---
        df_to_save_str = df_to_save.copy()
        for col in df_to_save_str.columns:
            if pd.api.types.is_datetime64_any_dtype(df_to_save_str[col]):
                df_to_save_str[col] = df_to_save_str[col].dt.strftime('%Y-%m-%d %H:%M:%S')
        # --- ‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏° ---

        worksheet.clear()
        worksheet.update([df_to_save_str.columns.values.tolist()] + df_to_save_str.astype(str).values.tolist())
        st.success(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheet '{GOOGLE_SHEET_NAME}/{GOOGLE_WORKSHEET_NAME}' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets: {e}")
        st.exception(e) # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏ß‡πâ ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡∏°‡∏µ Error ‡∏≠‡∏∑‡πà‡∏ô
        # ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏°‡∏µ st.stop() ‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤ # ‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô
        # # st.stop()

# (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)


# ========== Function Utility ==========
def get_today_drawdown(log_file, acc_balance):
    if not os.path.exists(log_file):
        return 0
    df = pd.read_csv(log_file)
    today_str = datetime.now().strftime("%Y-%m-%d")
    if "Timestamp" not in df.columns or "Risk $" not in df.columns:
        return 0
    df_today = df[df["Timestamp"].str.startswith(today_str)]
    try:
        drawdown = df_today["Risk $"].astype(float).sum()
    except Exception:
        drawdown = 0
    return drawdown

def get_performance(log_file, mode="week"):
    if not os.path.exists(log_file):
        return 0, 0, 0
    df = pd.read_csv(log_file)
    if "Timestamp" not in df.columns or "Risk $" not in df.columns:
        return 0, 0, 0
    now = datetime.now()
    if mode == "week":
        week_start = (now - pd.Timedelta(days=now.weekday())).strftime("%Y-%m-%d")
        df_period = df[df["Timestamp"] >= week_start]
    else:  # month
        month_start = now.strftime("%Y-%m-01")
        df_period = df[df["Timestamp"] >= month_start]
    win = df_period[df_period["Risk $"].astype(float) > 0].shape[0]
    loss = df_period[df_period["Risk $"].astype(float) <= 0].shape[0]
    total = win + loss if (win + loss) > 0 else 1
    winrate = 100 * win / total
    gain = df_period["Risk $"].astype(float).sum()
    return winrate, gain, total

# ======================= SEC 1: SIDEBAR / INPUT ZONE =======================

st.sidebar.header("üéõÔ∏è Trade Setup")

drawdown_limit_pct = st.sidebar.number_input(
    "Drawdown Limit ‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô (%)",
    min_value=0.1, max_value=20.0,
    value=2.0, step=0.1, format="%.1f"
)

mode = st.sidebar.radio("Trade Mode", ["FIBO", "CUSTOM"], horizontal=True, key="mode")


if st.sidebar.button("üîÑ Reset Form"):
    risk_keep = st.session_state.get("risk_pct", 1.0)
    asset_keep = st.session_state.get("asset", "XAUUSD")

    # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏ó‡∏∏‡∏Å key ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô risk_pct ‡∏Å‡∏±‡∏ö asset
    keys_to_keep = {"risk_pct", "asset"}
    keys_to_delete = [k for k in list(st.session_state.keys()) if k not in keys_to_keep]

    for k in keys_to_delete:
        del st.session_state[k]

    st.session_state["risk_pct"] = risk_keep
    st.session_state["asset"] = asset_keep

    # üëá ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠ ‚Äú‡∏•‡πâ‡∏≤‡∏á FIBO checkbox‚Äù
    st.session_state["fibo_flags"] = [False, False, False, False, False]

    st.rerun()


# -- Input Zone (‡πÅ‡∏¢‡∏Å FIBO/CUSTOM) --
# ======================= SEC 1: SIDEBAR / INPUT ZONE (FIBO) =======================
if mode == "FIBO":
    col1, col2, col3 = st.sidebar.columns([2, 2, 2])
    with col1:
        asset = st.text_input("Asset", value="XAUUSD", key="asset")
    with col2:
        risk_pct = st.number_input(
            "Risk %",
            min_value=0.01,
            max_value=100.0,
            step=0.01,
            format="%.2f",
            key="risk_pct"
        )
    with col3:
        direction = st.radio("Direction", ["Long", "Short"], horizontal=True)

    col4, col5 = st.sidebar.columns(2)
    with col4:
        swing_high = st.text_input("High", key="swing_high")
    with col5:
        swing_low = st.text_input("Low", key="swing_low")

    # üìê Entry Fibo Levels (‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Reset Form ‡πÑ‡∏î‡πâ)
    st.sidebar.markdown("**üìê Entry Fibo Levels**")
    fibos = [0.114, 0.25, 0.382, 0.5, 0.618]
    labels = [f"{l:.3f}" for l in fibos]
    cols = st.sidebar.columns(len(fibos))

    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ flags ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    if "fibo_flags" not in st.session_state:
        st.session_state.fibo_flags = [True] * len(fibos)

    fibo_selected = []
    for i, col in enumerate(cols):
        checked = col.checkbox(labels[i], value=st.session_state.fibo_flags[i])
        fibo_selected.append(checked)

    st.session_state.fibo_flags = fibo_selected

    try:
        high = float(swing_high)
        low = float(swing_low)
        if high <= low:
            st.sidebar.warning("High ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Low!")
    except Exception:
        pass

    if risk_pct <= 0:
        st.sidebar.warning("Risk% ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0")

    st.sidebar.markdown("---")
    try:
        high = float(swing_high)
        low = float(swing_low)
        if high > low:
            st.sidebar.markdown("**Preview (‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô):**")
            if direction == "Long":
                preview_entry = low + (high - low) * fibos[0]
            else:
                preview_entry = high - (high - low) * fibos[0]
            st.sidebar.markdown(f"Entry ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‚âà **{preview_entry:.2f}**")
            st.sidebar.caption("Lot/TP/‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ï‡πá‡∏°‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")
    except Exception:
        pass

    save_fibo = st.sidebar.button("Save Plan", key="save_fibo")



# ======================= SEC 1: SIDEBAR / INPUT ZONE (CUSTOM) =======================
elif mode == "CUSTOM":
    col1, col2, col3 = st.sidebar.columns([2, 2, 2])
    with col1:
        asset = st.text_input("Asset", value="XAUUSD", key="asset")
    with col2:
        risk_pct = st.number_input(
            "Risk %",
            min_value=0.01,
            max_value=100.0,
            value=1.00,
            step=0.01,
            format="%.2f"
        )
    with col3:
        n_entry = st.number_input(
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏°‡πâ",
            min_value=1,
            max_value=10,
            value=2,
            step=1
        )

    st.sidebar.markdown("**‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏°‡πâ**")
    custom_inputs = []
    risk_per_trade = risk_pct / 100
    risk_dollar_total = acc_balance * risk_per_trade
    risk_dollar_per_entry = risk_dollar_total / n_entry if n_entry > 0 else 0
    for i in range(int(n_entry)):
        st.sidebar.markdown(f"--- ‡πÑ‡∏°‡πâ‡∏ó‡∏µ‡πà {i+1} ---")
        col_e, col_s, col_t = st.sidebar.columns(3)
        with col_e:
            entry = st.text_input(f"Entry {i+1}", value="0.00", key=f"custom_entry_{i}")
        with col_s:
            sl = st.text_input(f"SL {i+1}", value="0.00", key=f"custom_sl_{i}")
        with col_t:
            tp = st.text_input(f"TP {i+1}", value="0.00", key=f"custom_tp_{i}")
        try:
            entry_val = float(entry)
            sl_val = float(sl)
            stop = abs(entry_val - sl_val)
            lot = risk_dollar_per_entry / stop if stop > 0 else 0
            lot_display = f"Lot: {lot:.2f}"
            risk_per_entry_display = f"Risk$ ‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πâ: {risk_dollar_per_entry:.2f}"
        except Exception:
            lot_display = "Lot: -"
            risk_per_entry_display = "Risk$ ‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πâ: -"
            stop = None
        try:
            if stop is not None and stop > 0:
                if 'direction' in locals() and direction == "Long": # This 'direction' would come from FIBO mode
                    tp_rr3 = entry_val + 3 * stop
                else: # Defaulting to Short if direction is not explicitly Long or not defined
                    tp_rr3 = entry_val - 3 * stop
                tp_rr3_display = f"TP ‡∏ó‡∏µ‡πà RR=3: {tp_rr3:.2f}"
            else:
                tp_rr3_display = "TP ‡∏ó‡∏µ‡πà RR=3: -"
        except Exception:
            tp_rr3_display = "TP ‡∏ó‡∏µ‡πà RR=3: -"
        st.sidebar.caption(lot_display + " | " + risk_per_entry_display + " | " + tp_rr3_display)
        custom_inputs.append({"entry": entry, "sl": sl, "tp": tp})
    if risk_pct <= 0:
        st.sidebar.warning("Risk% ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0")
    save_custom = st.sidebar.button("Save Plan", key="save_custom")

# ======================= SEC 4: SUMMARY (‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ Sidebar) =======================
st.sidebar.markdown("---")
st.sidebar.markdown("### üßæ Strategy Summary")

if mode == "FIBO":
    # FIBO Table Logic (‡∏Ñ‡∏∑‡∏ô‡∏™‡∏π‡∏ï‡∏£)
    try:
        high = float(swing_high)
        low = float(swing_low)
        selected_fibo_levels = [fibos[i] for i, sel in enumerate(fibo_selected) if sel]
        n = len(selected_fibo_levels)
        risk_per_trade = risk_pct / 100
        risk_dollar_total = acc_balance * risk_per_trade
        risk_dollar_per_entry = risk_dollar_total / n if n > 0 else 0
        entry_data = []
        for idx, fibo in enumerate(selected_fibo_levels):
            if direction == "Long":
                entry = low + (high - low) * fibo
                if abs(fibo - 0.5) < 1e-4:
                    sl = low + (high - low) * ((0.25 + 0.382)/2)
                elif abs(fibo - 0.618) < 1e-4:
                    sl = low + (high - low) * ((0.382 + 0.5)/2)
                else:
                    sl = low
            else:
                entry = high - (high - low) * fibo
                if abs(fibo - 0.5) < 1e-4:
                    sl = high - (high - low) * ((0.25 + 0.382)/2)
                elif abs(fibo - 0.618) < 1e-4:
                    sl = high - (high - low) * ((0.382 + 0.5)/2)
                else:
                    sl = high
            stop = abs(entry - sl)
            lot = risk_dollar_per_entry / stop if stop > 0 else 0
            risk_val = round(stop * lot, 2)
            entry_data.append({
                "Fibo Level": f"{fibo:.3f}",
                "Entry": f"{entry:.2f}",
                "SL": f"{sl:.2f}",
                "Lot": f"{lot:.2f}",
                "Risk $": f"{risk_val:.2f}",
            })
        if entry_data:
            entry_df = pd.DataFrame(entry_data)
            st.sidebar.write(f"**Total Lots:** {np.sum(entry_df['Lot'].astype(float)):.2f}")
            st.sidebar.write(f"**Total Risk $:** {np.sum(entry_df['Risk $'].astype(float)):.2f}")
    except Exception:
        entry_data = []
elif mode == "CUSTOM":
    try:
        n_entry = int(n_entry)
        risk_per_trade = risk_pct / 100
        risk_dollar_total = acc_balance * risk_per_trade
        risk_dollar_per_entry = risk_dollar_total / n_entry if n_entry > 0 else 0
        custom_entries = []
        rr_list = []
        for i in range(n_entry):
            entry_val = float(custom_inputs[i]["entry"])
            sl_val = float(custom_inputs[i]["sl"])
            tp_val = float(custom_inputs[i]["tp"])
            stop = abs(entry_val - sl_val)
            target = abs(tp_val - entry_val)
            lot = risk_dollar_per_entry / stop if stop > 0 else 0
            rr = (target / stop) if stop > 0 else 0
            rr_list.append(rr)
            custom_entries.append({
                "Entry": f"{entry_val:.2f}",
                "SL": f"{sl_val:.2f}",
                "TP": f"{tp_val:.2f}",
                "Lot": f"{lot:.2f}",
                "Risk $": f"{risk_dollar_per_entry:.2f}",
                "RR": f"{rr:.2f}"
            })
        if custom_entries:
            entry_df = pd.DataFrame(custom_entries)
            st.sidebar.write(f"**Total Lots:** {np.sum(entry_df['Lot'].astype(float)):.2f}")
            st.sidebar.write(f"**Total Risk $:** {np.sum(entry_df['Risk $'].astype(float)):.2f}")
            avg_rr = np.mean(rr_list) if len(rr_list) > 0 else None
            if avg_rr:
                st.sidebar.write(f"**Average RR:** {avg_rr:.2f}")
    except Exception:
        custom_entries = []

# ======================= SEC 1.x: SCALING MANAGER SETTINGS (EXPANDER, ‡∏ó‡πâ‡∏≤‡∏¢ SIDEBAR) =======================
with st.sidebar.expander("‚öôÔ∏è Scaling Manager Settings", expanded=False):
    scaling_step = st.number_input(
        "Scaling Step (%)", min_value=0.01, max_value=1.0, value=0.25, step=0.01, format="%.2f"
    )
    min_risk_pct = st.number_input(
        "Minimum Risk %", min_value=0.01, max_value=100.0, value=0.5, step=0.01, format="%.2f"
    )
    max_risk_pct = st.number_input(
        "Maximum Risk %", min_value=0.01, max_value=100.0, value=5.0, step=0.01, format="%.2f"
    )
    scaling_mode = st.radio(
        "Scaling Mode", ["Manual", "Auto"], horizontal=True
    )

# ======================= SEC 1.5: SCALING SUGGESTION & CONFIRM =======================
winrate, gain, total = get_performance(log_file, mode="week")
current_risk = risk_pct

if winrate > 55 and gain > 0.02 * acc_balance:
    suggest_risk = min(current_risk + scaling_step, max_risk_pct)
    scaling_msg = f"üéâ ‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏î‡∏µ! Winrate {winrate:.1f}%, ‡∏Å‡∏≥‡πÑ‡∏£ {gain:.2f} ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏° Risk% ‡πÄ‡∏õ‡πá‡∏ô {suggest_risk:.2f}"
elif winrate < 45 or gain < 0:
    suggest_risk = max(current_risk - scaling_step, min_risk_pct)
    scaling_msg = f"‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏£‡∏•‡∏î Risk%! Winrate {winrate:.1f}%, ‡∏Å‡∏≥‡πÑ‡∏£ {gain:.2f} ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏•‡∏î Risk% ‡πÄ‡∏õ‡πá‡∏ô {suggest_risk:.2f}"
else:
    suggest_risk = current_risk
    scaling_msg = "Risk% ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà"

st.sidebar.info(scaling_msg)

if scaling_mode == "Manual" and suggest_risk != current_risk:
    if st.sidebar.button(f"‡∏õ‡∏£‡∏±‡∏ö Risk% ‡πÄ‡∏õ‡πá‡∏ô {suggest_risk:.2f}"):
        risk_pct = suggest_risk
elif scaling_mode == "Auto":
    risk_pct = suggest_risk

# ======================= SEC 2+3: MAIN AREA ‚Äì ENTRY TABLE (FIBO/CUSTOM) =======================
with st.expander("üìã Entry Table (FIBO/CUSTOM)", expanded=True):
    if mode == "FIBO":
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### üéØ Entry Levels")
            if 'entry_data' in locals() and entry_data: # Ensure entry_data is defined
                entry_df = pd.DataFrame(entry_data)
                st.dataframe(entry_df, hide_index=True, use_container_width=True)
            else:
                st.info("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• High/Low ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Fibo Level ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Entry Levels.")
        with col2:
            st.markdown("### üéØ Take Profit Zones")
            try:
                high = float(swing_high)
                low = float(swing_low)
                if high > low: # Ensure high is greater than low for valid calculation
                    if direction == "Long":
                        tp1 = low + (high - low) * 1.618
                        tp2 = low + (high - low) * 2.618
                        tp3 = low + (high - low) * 4.236
                    else:
                        tp1 = high - (high - low) * 1.618
                        tp2 = high - (high - low) * 2.618
                        tp3 = high - (high - low) * 4.236
                    tp_df = pd.DataFrame({
                        "TP": ["TP1", "TP2", "TP3"],
                        "Price": [f"{tp1:.2f}", f"{tp2:.2f}", f"{tp3:.2f}"]
                    })
                    st.dataframe(tp_df, hide_index=True, use_container_width=True)
                else:
                    st.warning("üìå Define High and Low correctly to unlock your TP projection.")
            except (ValueError, NameError): # Catch ValueError for float conversion and NameError if swing_high/low aren't set
                st.warning("üìå Define High and Low to unlock your TP projection.")       
    elif mode == "CUSTOM":
        st.markdown("### üéØ Entry & Take Profit Zones ")
        if 'custom_entries' in locals() and custom_entries: # Ensure custom_entries is defined
            entry_df = pd.DataFrame(custom_entries)
            st.dataframe(entry_df, hide_index=True, use_container_width=True)
            # ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô RR
            for i, row in enumerate(custom_entries):
                try:
                    rr = float(row["RR"])
                    if rr < 2:
                        st.warning(f"üéØ Entry {i+1} RR is low ({rr:.2f}) ‚Äî fine-tune your TP/SL for better balance."
)
                except:
                    pass
        else:
            st.info("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Custom ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Entry & TP Zones.")


# ======================= SEC 5: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏õ‡∏∏‡πà‡∏° Save Plan ‡∏Å‡∏±‡∏ö save_plan + Drawdown Lock =======================
drawdown_today = get_today_drawdown(log_file, acc_balance)
drawdown_limit = -acc_balance * (drawdown_limit_pct / 100)

# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ drawdown ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô sidebar
if drawdown_today < 0:
    st.sidebar.markdown(f"**‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ:** {drawdown_today:,.2f} USD")
else:
    st.sidebar.markdown(f"**‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ:** {drawdown_today:,.2f} USD")

def save_plan(data, mode, asset, risk_pct, direction):
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    df_save = pd.DataFrame(data)
    df_save["Mode"] = mode
    df_save["Asset"] = asset
    df_save["Risk %"] = risk_pct
    df_save["Direction"] = direction # ensure direction is always passed
    df_save["Timestamp"] = now
    if os.path.exists(log_file):
        df_old = pd.read_csv(log_file)
        df_save = pd.concat([df_old, df_save], ignore_index=True)
    df_save.to_csv(log_file, index=False)


current_direction = None
if mode == "FIBO":
    if 'direction' in locals():
        current_direction = direction
elif mode == "CUSTOM":
    current_direction = "N/A" 


if mode == "FIBO" and 'entry_data' in locals() and save_fibo and entry_data and current_direction is not None:
    if drawdown_today <= drawdown_limit:
        st.sidebar.error(
            f"‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏î! ‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ {abs(drawdown_today):,.2f} ‡πÄ‡∏Å‡∏¥‡∏ô‡∏•‡∏¥‡∏°‡∏¥‡∏ï {abs(drawdown_limit):,.2f} ({drawdown_limit_pct:.1f}%)"
        )
    else:
        try:
            save_plan(entry_data, "FIBO", asset, risk_pct, current_direction)
            st.sidebar.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ú‡∏ô (FIBO) ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        except Exception as e:
            st.sidebar.error(f"Save ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

elif mode == "CUSTOM" and 'custom_entries' in locals() and save_custom and custom_entries and current_direction is not None:
    if drawdown_today <= drawdown_limit:
        st.sidebar.error(
            f"‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏î! ‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ {abs(drawdown_today):,.2f} ‡πÄ‡∏Å‡∏¥‡∏ô‡∏•‡∏¥‡∏°‡∏¥‡∏ï {abs(drawdown_limit):,.2f} ({drawdown_limit_pct:.1f}%)"
        )
    else:
        try:
            save_plan(custom_entries, "CUSTOM", asset, risk_pct, current_direction)
            st.sidebar.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ú‡∏ô (CUSTOM) ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        except Exception as e:
            st.sidebar.error(f"Save ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

# ======================= SEC 7: VISUALIZER (‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏Å‡∏£‡∏≤‡∏ü) =======================

with st.expander("üìà Chart Visualizer", expanded=True):
    plot = st.button("Plot Plan", key="plot_plan")

    if plot:
        st.components.v1.html("""
        <div class="tradingview-widget-container">
          <div id="tradingview_legendary"></div>
          <script type="text/javascript" src="https://s3.tradingview.com/tv.js"></script>
          <script type="text/javascript">
          new TradingView.widget({
            "width": "100%",
            "height": 600,
            "symbol": "OANDA:XAUUSD",      // ‡∏õ‡∏£‡∏±‡∏ö symbol ‡πÑ‡∏î‡πâ
            "interval": "15",
            "timezone": "Asia/Bangkok",
            "theme": "dark",
            "style": "1",
            "locale": "th",
            "toolbar_bg": "#f1f3f6",
            "enable_publishing": true,
            "withdateranges": true,
            "allow_symbol_change": true,
            "hide_side_toolbar": false,
            "details": true,
            "hotlist": true,
            "calendar": true,
            "container_id": "tradingview_legendary"
          });
          </script>
        </div>
        """, height=620)
    else:
        st.info("‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Plot Plan ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü TradingView")

# ======================= SEC 8: AI SUMMARY & INSIGHT =======================
with st.expander("	ü§ñ AI Assistant", expanded=True):
    if os.path.exists(log_file):
        try:
            df_log = pd.read_csv(log_file)
            if df_log.empty:
                st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡πÄ‡∏ó‡∏£‡∏î‡πÉ‡∏ô log")
            else:
                # 1. Winrate (‡∏£‡∏ß‡∏°/‡πÅ‡∏¢‡∏Å Mode)
                total_trades = df_log.shape[0]
                win_trades = df_log[df_log["Risk $"].astype(float) > 0].shape[0]
                loss_trades = df_log[df_log["Risk $"].astype(float) <= 0].shape[0]
                winrate = 100 * win_trades / total_trades if total_trades > 0 else 0

                # 2. ‡∏Å‡∏≥‡πÑ‡∏£/‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏™‡∏∏‡∏ó‡∏ò‡∏¥
                gross_profit = df_log["Risk $"].astype(float).sum()

                # 3. RR ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
                rr_list = []
                if "RR" in df_log.columns:
                    rr_list = pd.to_numeric(df_log["RR"], errors='coerce').dropna().tolist()
                avg_rr = np.mean(rr_list) if len(rr_list) > 0 else None

                # 4. Drawdown (‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢)
                balance = acc_balance
                max_balance = balance
                drawdowns = []
                for risk in df_log["Risk $"].astype(float):
                    balance += risk
                    if balance > max_balance:
                        max_balance = balance
                    drawdown = max_balance - balance
                    drawdowns.append(drawdown)
                max_drawdown = max(drawdowns) if drawdowns else 0

                # 5. ‡∏ß‡∏±‡∏ô/‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà win/loss ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
                df_log["Date"] = pd.to_datetime(df_log["Timestamp"], errors='coerce')
                if not df_log["Date"].isnull().all():
                    df_log["Weekday"] = df_log["Date"].dt.day_name()
                    win_day = df_log[df_log["Risk $"].astype(float) > 0]["Weekday"].mode()[0] if not df_log[df_log["Risk $"].astype(float) > 0].empty else "-"
                    loss_day = df_log[df_log["Risk $"].astype(float) <= 0]["Weekday"].mode()[0] if not df_log[df_log["Risk $"].astype(float) <= 0].empty else "-"
                else:
                    win_day = loss_day = "-"

                # 6. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ/Insight
                st.markdown("### üß† AI Intelligence Report")
                st.write(f"- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ú‡∏ô‡πÄ‡∏ó‡∏£‡∏î:** {total_trades:,}")
                st.write(f"- **Winrate:** {winrate:.2f}%")
                st.write(f"- **‡∏Å‡∏≥‡πÑ‡∏£/‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏™‡∏∏‡∏ó‡∏ò‡∏¥:** {gross_profit:,.2f} USD")
                if avg_rr is not None:
                    st.write(f"- **RR ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢:** {avg_rr:.2f}")
                st.write(f"- **Max Drawdown:** {max_drawdown:,.2f} USD")
                st.write(f"- **‡∏ß‡∏±‡∏ô‡∏ä‡∏ô‡∏∞‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î:** {win_day}")
                st.write(f"- **‡∏ß‡∏±‡∏ô‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î:** {loss_day}")

                # 7. Insight ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á/‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô (beta)
                st.markdown("### ü§ñ AI Insight (‡∏à‡∏≤‡∏Å‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á)")
                insight = []
                if winrate >= 60:
                    insight.append("‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ Winrate ‡∏™‡∏π‡∏á ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏†‡∏≤‡∏û‡∏î‡∏µ")
                elif winrate < 40:
                    insight.append("Winrate ‡∏ï‡πà‡∏≥ ‡∏Ñ‡∏ß‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏Ç‡πâ‡∏≤/‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÉ‡∏´‡∏°‡πà")
                if avg_rr is not None and avg_rr < 2:
                    insight.append("RR ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏•‡∏≤‡∏î (<2) ‡∏≠‡∏≤‡∏à‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
                if max_drawdown > acc_balance * 0.05:
                    insight.append("Drawdown ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (5%) ‡∏Ñ‡∏ß‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Money Management")
                if win_day != "-" and loss_day != "-" and win_day == loss_day:
                    insight.append("‡∏ß‡∏±‡∏ô‡πÄ‡∏ó‡∏£‡∏î‡∏ó‡∏µ‡πà‡∏ä‡∏ô‡∏∞‡πÅ‡∏•‡∏∞‡πÅ‡∏û‡πâ‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‡∏•‡∏≠‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå behavior ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
                if not insight:
                    insight = ["‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ó‡∏£‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"]
                for msg in insight:
                    st.info(msg)
        except Exception as e:
            st.warning(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå AI: {e}")
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• log_file ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Summary")
# ======================= SEC 7: Ultimate Statement Import & Auto-Mapping =======================
with st.expander("üìÇ SEC 7: Ultimate Statement Import & Auto-Mapping", expanded=False):
    st.markdown("### üìä ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Statement ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö")

    # ‡πÉ‡∏ä‡πâ st.session_state ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏á‡∏Ñ‡πà‡∏≤ all_statement_data ‡πÅ‡∏•‡∏∞ df_stmt_current ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á rerun
    # ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏£‡∏±‡∏ô‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏≠‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏•‡πâ‡∏≤‡∏á
    if 'all_statement_data' not in st.session_state:
        st.session_state.all_statement_data = {} # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Dictionary ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
        st.session_state.df_stmt_current = pd.DataFrame() # ‡πÅ‡∏•‡∏∞ df_stmt_current ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
        
        st.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡∏à‡∏≤‡∏Å Google Sheets ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å...")
        # NOTE: load_statement_from_gsheets ‡∏Ñ‡∏ß‡∏£‡∏ñ‡∏π‡∏Å import ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÑ‡∏ß‡πâ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô
        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô main.py ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏±‡∏ô‡πÉ‡∏ô SEC 0 ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
        # ‡πÄ‡∏ä‡πà‡∏ô:
        # def load_statement_from_gsheets():
        #     # ‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Google Sheets
        #     return {} # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô dictionary ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
        loaded_data = load_statement_from_gsheets()
        
        st.session_state.all_statement_data = loaded_data # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô session_state
        
        # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô 'deals' ‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô df_stmt_current
        if 'deals' in loaded_data and not loaded_data['deals'].empty:
            st.session_state.df_stmt_current = loaded_data['deals']
            st.success("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'Deals' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dashboard ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'Deals' ‡∏à‡∏≤‡∏Å Google Sheets ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å.")
    
    # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å session_state ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ
    all_statement_data = st.session_state.all_statement_data
    df_stmt_current = st.session_state.df_stmt_current

    st.markdown("---")
    st.subheader("üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Statement (CSV/XLSX) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
    st.info("‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î '‡πÑ‡∏ü‡∏•‡πå Statement ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö' ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏≠‡∏õ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    uploaded_files = st.file_uploader(
        "‡∏•‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Statement ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå",
        type=["xlsx", "csv"], 
        accept_multiple_files=True, 
        key="sec7_upload"
    )

    # --- ‡πÄ‡∏û‡∏¥‡πà‡∏° Debug Mode Checkbox ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ---
    if 'debug_mode' not in st.session_state:
        st.session_state.debug_mode = False
    
    st.session_state.debug_mode = st.checkbox("‚öôÔ∏è ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏´‡∏°‡∏î Debug ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Balance Summary (‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏¢‡∏≠‡∏∞)", value=st.session_state.debug_mode)
    if st.session_state.debug_mode:
        st.warning("‚ö†Ô∏è ‡πÇ‡∏´‡∏°‡∏î Debug ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Excel ‡∏≠‡∏≤‡∏à‡πÄ‡∏¢‡∏≠‡∏∞‡πÅ‡∏•‡∏∞‡∏£‡∏Å‡∏ï‡∏≤")
    # --- ‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° Debug Mode Checkbox ---


    # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß) ---
    def extract_sections_from_file(file):
        if file.name.endswith(".xlsx"):
            df_raw = pd.read_excel(file, header=None, engine='openpyxl')
        elif file.name.endswith(".csv"):
            df_raw = pd.read_csv(file, header=None)
        else:
            return {} # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ dictionary ‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà excel ‡∏´‡∏£‡∏∑‡∏≠ csv

        section_starts = {}
        current_section = None
        section_keywords = {
            "History": "History",
            "Open Trades": "Open Trades",
            "Exposure": "Exposure",
            "Orders": "Orders",
            "Results": "Results"
        }

        # Find start rows for main sections
        for r_idx in range(len(df_raw)):
            # Check for section headers (e.g., "History", "Open Trades", etc.)
            for col_idx in range(min(df_raw.shape[1], 15)): # Check more columns up to O (index 14)
                cell_value = str(df_raw.iloc[r_idx, col_idx]).strip()
                for key, keyword in section_keywords.items():
                    if keyword.lower() in cell_value.lower() and key not in section_starts:
                        section_starts[key] = r_idx
                        current_section = key
                        break
                if current_section:
                    break
            current_section = None # Reset for next search

        section_data = {}
        tabular_sections = ["History", "Open Trades", "Exposure", "Orders"]

        for section_name in tabular_sections:
            if section_name in section_starts:
                start_row = section_starts[section_name]
                
                # Find the header row (first non-empty row after section start)
                header_row_idx = -1
                for r_idx in range(start_row + 1, len(df_raw)):
                    if not df_raw.iloc[r_idx].isnull().all(): # Check if row is not entirely empty
                        header_row_idx = r_idx
                        break
                
                if header_row_idx != -1:
                    headers = [str(col).strip() for col in df_raw.iloc[header_row_idx] if pd.notna(col) and str(col).strip() != '']
                    
                    # Determine end row of the section
                    end_row = len(df_raw)
                    next_section_start = len(df_raw) # Default to end of file
                    for other_section_name, other_start_row in section_starts.items():
                        if other_section_name != section_name and other_start_row > start_row:
                            if other_start_row < next_section_start:
                                next_section_start = other_start_row
                    end_row = next_section_start

                    # Extract data rows for the current section
                    data_start_row = header_row_idx + 1
                    section_df = df_raw.iloc[data_start_row:end_row].copy()
                    
                    # Check if section_df is not empty before processing
                    if not section_df.empty:
                        # Drop rows where all values are NaN
                        section_df.dropna(how='all', inplace=True)
                        
                        if not section_df.empty:
                            # Re-index to make operations easier
                            section_df.reset_index(drop=True, inplace=True)

                            # Dynamically map headers to column indices
                            header_to_col_idx = {}
                            for i, col_name in enumerate(df_raw.iloc[header_row_idx]):
                                if pd.notna(col_name) and str(col_name).strip() != '':
                                    header_to_col_idx[str(col_name).strip()] = i

                            # Create a new DataFrame with correctly aligned columns
                            processed_data = []
                            for row_idx in range(len(section_df)):
                                row_values = []
                                for header in headers:
                                    original_col_idx = header_to_col_idx.get(header)
                                    if original_col_idx is not None and original_col_idx < len(df_raw.columns):
                                        # Use .loc with original DataFrame's column index
                                        # We need to use df_raw.iloc to get the value from the correct original position
                                        value = df_raw.iloc[data_start_row + row_idx, original_col_idx]
                                        row_values.append(value)
                                    else:
                                        row_values.append(np.nan) # Append NaN if header not found in original cols
                                processed_data.append(row_values)
                            
                            # Remove leading/trailing spaces from headers
                            cleaned_headers = [h.strip() for h in headers]
                            
                            temp_df = pd.DataFrame(processed_data, columns=cleaned_headers)

                            # Clean up values (remove $, comma, %)
                            for col in temp_df.columns:
                                # Apply cleaning only to columns that are likely to contain numbers
                                if temp_df[col].dtype == 'object': # Check if it's an object/string type
                                    # Ensure we don't apply regex to non-string types or if not necessary
                                    temp_df[col] = temp_df[col].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False).str.replace('%', '', regex=False)
                                    # Handle parentheses for negative numbers: (123.45) -> -123.45
                                    temp_df[col] = temp_df[col].apply(lambda x: f"-{x.replace('(', '').replace(')', '').strip()}" if isinstance(x, str) and '(' in x and ')' in x else x)
                                    # Attempt conversion to numeric after cleaning
                                    temp_df[col] = pd.to_numeric(temp_df[col], errors='coerce')
                                elif pd.api.types.is_numeric_dtype(temp_df[col]):
                                    # If already numeric, ensure negative signs from parentheses are handled if any exist (unlikely but safe)
                                    # This is more for string-like numbers that are already numeric (e.g., loaded as int but had parentheses)
                                    temp_df[col] = temp_df[col].apply(lambda x: -abs(x) if isinstance(x, (str)) and '(' in str(x) and ')' in str(x) else x)


                            section_data[section_name.lower().replace(" ", "_")] = temp_df
                        else:
                            st.warning(f"Warning: No valid data rows found for section '{section_name}'.")
                    else:
                        st.warning(f"Warning: Section '{section_name}' found but no data could be extracted.")
                else:
                    st.warning(f"Warning: Could not find header row for section '{section_name}'.")

        # --- Process "Results" section (Balance Summary) ---
        results_stats = {}
        if "Results" in section_starts:
            results_start_row = section_starts["Results"]
            # Start scanning from the row *after* "Results" keyword was found
            # and limit to a reasonable number of rows.
            scan_end_row = min(len(df_raw), results_start_row + 1 + 30) # Scan up to 30 rows after "Results" start for stats
            
            # Use a dictionary for faster lookup, mapping normalized label to (original_label, expected_label_col_idx, expected_value_col_idx)
            stat_lookup_map = {}
            
            # Based on your screenshots for ReportHistory-300379.xlsx and the new file:
            # Column mapping (0-indexed Pandas):
            # C (index 2) is value for B (index 1)
            # H (index 7) is value for G (index 6)
            # N (index 13) is value for K (index 10)
            stat_definitions_for_results = [
                ("Total Net Profit", 1, 2), # Label in B, Value in C
                ("Profit Factor", 1, 2),    # Label in B, Value in C
                ("Recovery Factor", 1, 2),  # Label in B, Value in C
                ("Balance Drawdown Absolute", 1, 2), # Label in B, Value in C
                ("Total Trades", 1, 2),     # Label in B, Value in C

                ("Gross Profit", 6, 7),     # Label in G, Value in H
                ("Expected Payoff", 6, 7),  # Label in G, Value in H
                ("Sharpe Ratio", 6, 7),     # Label in G, Value in H
                ("Balance Drawdown Maximal", 6, 7), # Label in G, Value in H
                ("Short Trades (won %)", 6, 7), # Label in G, Value in H
                ("Profit Trades (% of total)", 6, 7), # Label in G, Value in H
                ("Largest profit trade", 6, 7), # Label in G, Value in H
                ("Average profit trade", 6, 7), # Label in G, Value in H
                ("Maximum consecutive wins ($)", 6, 7), # Label in G, Value in H
                ("Maximal consecutive profit (count)", 6, 7), # Label in G, Value in H
                ("Average consecutive wins", 6, 7), # Label in G, Value in H

                ("Gross Loss", 10, 13),      # Label in K, Value in N
                ("Balance Drawdown Relative", 10, 13), # Label in K, Value in N
                ("Long Trades (won %)", 10, 13), # Label in K, Value in N
                ("Loss Trades (% of total)", 10, 13), # Label in K, Value in N
                ("Largest loss trade", 10, 13), # Label in K, Value in N
                ("Average loss trade", 10, 13), # Label in K, Value in N
                ("Maximum consecutive losses ($)", 10, 13), # Label in K, Value in N
                ("Maximal consecutive loss (count)", 10, 13), # Label in K, Value in N
                ("Average consecutive losses", 10, 13) # Label in K, Value in N
            ]

            for original_label, label_col, value_col in stat_definitions_for_results:
                normalized_key = "".join(filter(str.isalnum, original_label)).lower()
                stat_lookup_map[normalized_key] = (original_label, label_col, value_col)

            # ADD THIS DEBUG PRINT: ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á stat_lookup_map
            if st.session_state.debug_mode:
                st.write("DEBUG Balance Summary: stat_lookup_map built:")
                st.write(stat_lookup_map)
            
            # --- NEW: Use openpyxl for reliable cell access in "Results" section ---
            # Reset file pointer to beginning for openpyxl to read
            file.seek(0)
            try:
                workbook = openpyxl.load_workbook(file)
                sheet = workbook.active # Assuming data is on the active sheet
            except Exception as e:
                st.error(f"Error loading Excel with openpyxl: {e}")
                if st.session_state.debug_mode:
                    st.write(f"DEBUG openpyxl Error: {e}")
                return section_data # Return empty if openpyxl fails

            # Iterate using openpyxl's 1-indexed row/col system
            # results_start_row is 0-indexed from Pandas, so add 1 to get openpyxl row index for "Results" keyword
            # Then add another 1 to start scanning from the row *after* "Results"
            # scan_end_row (Pandas 0-indexed) also needs to be converted to openpyxl 1-indexed for the range
            for r_idx_openpyxl in range(results_start_row + 2, scan_end_row + 1): 
                # Convert pandas 0-indexed columns to openpyxl 1-indexed columns for potential label columns
                potential_label_cols_openpyxl = [col_idx_pandas + 1 for col_idx_pandas in [1, 6, 10]] # B, G, K -> 2, 7, 11 (in openpyxl)

                for current_label_col_openpyxl in potential_label_cols_openpyxl:
                    # Get cell value directly using openpyxl
                    raw_cell_content = None
                    try:
                        cell_obj = sheet.cell(row=r_idx_openpyxl, column=current_label_col_openpyxl)
                        raw_cell_content = cell_obj.value
                    except IndexError: # If column is out of bounds for this row in openpyxl
                        if st.session_state.debug_mode:
                            st.write(f"DEBUG Balance Summary (openpyxl): Cell ({r_idx_openpyxl}, {current_label_col_openpyxl}) out of sheet bounds. Skipping.")
                        continue # Skip to next column

                    # Use pd.isna for robustness with various NaN representations
                    is_nan_val = pd.isna(raw_cell_content) 

                    if st.session_state.debug_mode:
                        st.write(f"DEBUG Balance Summary (openpyxl): Checking Label Row {r_idx_openpyxl}, Col {current_label_col_openpyxl}. Raw Cell Content: '{raw_cell_content}', Type: {type(raw_cell_content)}, Is NaN: {is_nan_val}")

                    # Check if the string representation is not empty and not the literal string 'None' (for truly empty cells)
                    string_representation = str(raw_cell_content).strip()
                    if string_representation and string_representation.lower() != 'none':
                        label_text_from_excel_raw = string_representation
                        normalized_excel_label = "".join(filter(str.isalnum, label_text_from_excel_raw)).lower()

                        if st.session_state.debug_mode:
                            st.write(f"DEBUG Balance Summary (openpyxl): Scanning (Found Text) Row {r_idx_openpyxl}, Col {current_label_col_openpyxl}: Raw Text='{label_text_from_excel_raw}', Normalized='{normalized_excel_label}'")
                        
                        if normalized_excel_label in stat_lookup_map:
                            original_stat_key, expected_label_col_pandas, expected_value_col_pandas = stat_lookup_map[normalized_excel_label]
                            
                            # Convert expected pandas 0-indexed columns to openpyxl 1-indexed columns
                            expected_label_col_openpyxl = expected_label_col_pandas + 1
                            expected_value_col_openpyxl = expected_value_col_pandas + 1
                            
                            # Double-check if the found label column matches the expected label column for this stat
                            if current_label_col_openpyxl == expected_label_col_openpyxl:
                                value_col_to_read_openpyxl = expected_value_col_openpyxl
                                
                                raw_value_content = None
                                try:
                                    value_cell_obj = sheet.cell(row=r_idx_openpyxl, column=value_col_to_read_openpyxl)
                                    raw_value_content = value_cell_obj.value
                                except IndexError: # If value column is out of bounds
                                     if st.session_state.debug_mode:
                                        st.write(f"DEBUG Balance Summary (openpyxl): Value Cell ({r_idx_openpyxl}, {value_col_to_read_openpyxl}) out of sheet bounds. Skipping.")
                                     continue # Skip to next iteration

                                if st.session_state.debug_mode:
                                    st.write(f"DEBUG Balance Summary (openpyxl): Attempting to read value for '{original_stat_key}' from Row {r_idx_openpyxl}, Value Col {value_col_to_read_openpyxl}. Raw Cell Content: '{raw_value_content}', Is NaN: {pd.isna(raw_value_content)}")
                                
                                # Process if value content is not NaN/empty
                                if pd.notna(raw_value_content) and str(raw_value_content).strip().lower() != 'none': 
                                    value = str(raw_value_content).strip()
                                    
                                    # Handle percentages like "11.46% (1 211.92)" by taking only the first part
                                    if '%' in value and '(' in value:
                                        value = value.split('%')[0].strip()
                                    # Handle negative numbers in parentheses like "(123.45)"
                                    elif '(' in value and ')' in value:
                                        value = "-" + value.replace('(', '').replace(')', '').strip()
                                    
                                    # Remove common non-numeric characters
                                    value = value.replace('$', '').replace(',', '').replace('%', '')
                                    
                                    try:
                                        value = float(value)
                                    except ValueError:
                                        try:
                                            value = int(value)
                                        except ValueError:
                                            if st.session_state.debug_mode:
                                                st.warning(f"DEBUG Balance Summary (openpyxl): Could not convert '{value}' for '{original_stat_key}' to numeric. Keeping as string.")
                                            continue # Skip to next iteration if value is not numeric
                                    
                                    results_stats[original_stat_key] = value
                                    
                                    if st.session_state.debug_mode:
                                        st.write(f"DEBUG Balance Summary (openpyxl): --- Found and extracted '{original_stat_key}' --- Value: '{value}' from Row {r_idx_openpyxl}, Label Col {current_label_col_openpyxl}, Value Col {value_col_to_read_openpyxl}")
                                else: # If value is NaN or empty string
                                     if st.session_state.debug_mode:
                                         st.write(f"DEBUG Balance Summary (openpyxl): Skipping '{original_stat_key}' - Value cell is NaN, empty, or 'None'.")
                            else: # If current_label_col_openpyxl != expected_label_col_openpyxl
                                if st.session_state.debug_mode:
                                    st.write(f"DEBUG Balance Summary (openpyxl): Mismatch label column for '{original_stat_key}'. Expected {expected_label_col_openpyxl}, got {current_label_col_openpyxl}.")
                        else: # If normalized_excel_label not in stat_lookup_map
                            if st.session_state.debug_mode:
                                st.write(f"DEBUG Balance Summary (openpyxl): '{normalized_excel_label}' (from Col {current_label_col_openpyxl}) not in stat_lookup_map.")
                    else: # If string_representation is empty or 'None'
                        if st.session_state.debug_mode:
                            st.write(f"DEBUG Balance Summary (openpyxl): Cell at Row {r_idx_openpyxl}, Col {current_label_col_openpyxl} is empty or 'None' after stripping. Skipping label check.")

            if results_stats:
                section_data["balance_summary"] = pd.DataFrame(list(results_stats.items()), columns=['Metric', 'Value'])
                if st.session_state.debug_mode:
                    st.write("DEBUG Balance Summary: Final results_stats collected:")
                    st.write(results_stats)
            else:
                st.warning("Warning: 'Results' section found but no recognizable statistics extracted for Balance Summary.")
                if st.session_state.debug_mode:
                    st.write("DEBUG Balance Summary: No stats found using current logic.")

        return section_data # <--- ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô extract_sections_from_file

    # ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô extract_sections_from_file)
    # ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô with st.expander("üìÇ SEC 7: ..."):
    if uploaded_files:
        for uploaded_file in uploaded_files:
            file_name = uploaded_file.name
            st.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå: {file_name}")
            
            with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {file_name}..."):
                extracted_data = extract_sections_from_file(uploaded_file)
                
                if extracted_data:
                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô session_state
                    for key, df in extracted_data.items():
                        if key not in st.session_state.all_statement_data:
                            st.session_state.all_statement_data[key] = df
                        else:
                            st.session_state.all_statement_data[key] = pd.concat([st.session_state.all_statement_data[key], df], ignore_index=True)
                            st.session_state.all_statement_data[key].drop_duplicates(inplace=True) # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
                    
                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï df_stmt_current ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡πà‡∏ß‡∏ô 'history' (‡∏ã‡∏∂‡πà‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 'deals')
                    if 'history' in extracted_data: # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö 'history' ‡∏Å‡πà‡∏≠‡∏ô
                        st.session_state.df_stmt_current = extracted_data['history']
                    elif 'deals' in extracted_data: # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö 'history' ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ 'deals'
                        st.session_state.df_stmt_current = extracted_data['deals']
                    else:
                        st.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡πà‡∏ß‡∏ô 'History' ‡∏´‡∏£‡∏∑‡∏≠ 'Deals' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå {file_name} ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Dashboard ‡∏´‡∏•‡∏±‡∏Å")
                        
                    st.success(f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {file_name} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô: {', '.join(extracted_data.keys())}")

                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Balance Summary ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÅ‡∏•‡∏∞ Debug Mode ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà
                    if st.session_state.debug_mode and 'balance_summary' in extracted_data:
                        st.write("### üìä Balance Summary (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•)")
                        st.dataframe(extracted_data['balance_summary'])
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ (‡∏ñ‡πâ‡∏≤ Debug Mode ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà)
                    if st.session_state.debug_mode:
                        for section_key, section_df in extracted_data.items():
                            if section_key != 'balance_summary':
                                st.write(f"### üìÑ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô: {section_key.replace('_', ' ').title()}")
                                st.dataframe(section_df)
                else:
                    st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏î‡πÜ ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå {file_name} ‡πÑ‡∏î‡πâ ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå")
        # st.experimental_rerun() # ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ AttributeError
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå Statement ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")

    st.markdown("---")
    st.subheader("üìÅ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
    st.info("‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'Deals' (‡∏´‡∏£‡∏∑‡∏≠ History) ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Dashboard ‡∏´‡∏•‡∏±‡∏Å")
    st.dataframe(df_stmt_current)

    # ‡∏õ‡∏∏‡πà‡∏°‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏ß‡∏° Google Sheets)", key="clear_all_statements"):
        st.session_state.all_statement_data = {}
        st.session_state.df_stmt_current = pd.DataFrame()
        st.success("‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statement ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß")
        st.experimental_rerun() # ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà
