# ===================== SEC 0: IMPORT & CONFIG =======================

import streamlit as st

import pandas as pd

import numpy as np

from datetime import datetime, date

import plotly.express as px

import google.generativeai as genai

import gspread

import plotly.graph_objects as go

import random

import ioÂ 

import uuid

import hashlib



st.set_page_config(page_title="Ultimate-Chart", layout="wide")



if 'uploader_key_version' not in st.session_state:

Â  Â  st.session_state.uploader_key_version = 0



if 'latest_statement_equity' not in st.session_state:

Â  Â  st.session_state.latest_statement_equity = NoneÂ 



if 'current_account_balance' not in st.session_state:

Â  Â  st.session_state.current_account_balance = 10000.0 # Default fallback



# à¸à¸³à¸«à¸™à¸”à¸Šà¸·à¹ˆà¸­ Google Sheet à¹à¸¥à¸° Worksheet à¸—à¸µà¹ˆà¸ˆà¸°à¹ƒà¸Šà¹‰à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥

GOOGLE_SHEET_NAME = "TradeLog"

WORKSHEET_PORTFOLIOS = "Portfolios"

WORKSHEET_PLANNED_LOGS = "PlannedTradeLogs"

WORKSHEET_ACTUAL_TRADES = "ActualTrades"

WORKSHEET_ACTUAL_ORDERS = "ActualOrders"

WORKSHEET_ACTUAL_POSITIONS = "ActualPositions"

WORKSHEET_STATEMENT_SUMMARIES = "StatementSummaries"

WORKSHEET_UPLOAD_HISTORY = "UploadHistory"



@st.cache_resource

def get_gspread_client():

Â  Â  try:

Â  Â  Â  Â  if "gcp_service_account" not in st.secrets:

Â  Â  Â  Â  Â  Â  st.warning("âš ï¸ à¹‚à¸›à¸£à¸”à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² 'gcp_service_account' à¹ƒà¸™ `.streamlit/secrets.toml` à¹€à¸à¸·à¹ˆà¸­à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Google Sheets.")

Â  Â  Â  Â  Â  Â  return None

Â  Â  Â  Â  return gspread.service_account_from_dict(st.secrets["gcp_service_account"])

Â  Â  except Exception as e:

Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Google Sheets: {e}")

Â  Â  Â  Â  st.info("à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² 'gcp_service_account' à¹ƒà¸™ secrets.toml à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ à¹à¸¥à¸°à¹„à¸”à¹‰à¹à¸Šà¸£à¹Œ Sheet à¸à¸±à¸š Service Account à¹à¸¥à¹‰à¸§")

Â  Â  Â  Â  return None



@st.cache_data(ttl=300)

def load_portfolios_from_gsheets():

Â  Â  gc = get_gspread_client()

Â  Â  if gc is None:

Â  Â  Â  Â  st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸­à¸£à¹Œà¸•à¹„à¸”à¹‰: Client Google Sheets à¹„à¸¡à¹ˆà¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™")

Â  Â  Â  Â  return pd.DataFrame()



Â  Â  try:

Â  Â  Â  Â  sh = gc.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  worksheet = sh.worksheet(WORKSHEET_PORTFOLIOS)

Â  Â  Â  Â  records = worksheet.get_all_records()

Â  Â  Â  Â Â 

Â  Â  Â  Â  if not records:

Â  Â  Â  Â  Â  Â  st.info(f"à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™ Worksheet '{WORKSHEET_PORTFOLIOS}'.")

Â  Â  Â  Â  Â  Â  return pd.DataFrame()

Â  Â  Â  Â Â 

Â  Â  Â  Â  df_portfolios = pd.DataFrame(records)

Â  Â  Â  Â Â 

Â  Â  Â  Â  cols_to_numeric_type = {

Â  Â  Â  Â  Â  Â  'InitialBalance': float, 'ProfitTargetPercent': float,Â 

Â  Â  Â  Â  Â  Â  'DailyLossLimitPercent': float, 'TotalStopoutPercent': float,

Â  Â  Â  Â  Â  Â  'Leverage': float, 'MinTradingDays': int,

Â  Â  Â  Â  Â  Â  'OverallProfitTarget': float, 'WeeklyProfitTarget': float, 'DailyProfitTarget': float,

Â  Â  Â  Â  Â  Â  'MaxAcceptableDrawdownOverall': float, 'MaxAcceptableDrawdownDaily': float,

Â  Â  Â  Â  Â  Â  'ScaleUp_MinWinRate': float, 'ScaleUp_MinGainPercent': float, 'ScaleUp_RiskIncrementPercent': float,

Â  Â  Â  Â  Â  Â  'ScaleDown_MaxLossPercent': float, 'ScaleDown_LowWinRate': float, 'ScaleDown_RiskDecrementPercent': float,

Â  Â  Â  Â  Â  Â  'MinRiskPercentAllowed': float, 'MaxRiskPercentAllowed': float, 'CurrentRiskPercent': float

Â  Â  Â  Â  }

Â  Â  Â  Â  for col, target_type in cols_to_numeric_type.items():

Â  Â  Â  Â  Â  Â  if col in df_portfolios.columns:

Â  Â  Â  Â  Â  Â  Â  Â  df_portfolios[col] = pd.to_numeric(df_portfolios[col], errors='coerce').fillna(0)

Â  Â  Â  Â  Â  Â  Â  Â  if target_type == int:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_portfolios[col] = df_portfolios[col].astype(int)



Â  Â  Â  Â  if 'EnableScaling' in df_portfolios.columns:

Â  Â  Â  Â  Â  Â  Â df_portfolios['EnableScaling'] = df_portfolios['EnableScaling'].astype(str).str.upper().map({'TRUE': True, 'YES': True, '1': True, 'FALSE': False, 'NO': False, '0': False}).fillna(False)



Â  Â  Â  Â  date_cols = ['CompetitionEndDate', 'TargetEndDate', 'CreationDate']

Â  Â  Â  Â  for col in date_cols:

Â  Â  Â  Â  Â  Â  if col in df_portfolios.columns:

Â  Â  Â  Â  Â  Â  Â  Â  df_portfolios[col] = pd.to_datetime(df_portfolios[col], errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S')



Â  Â  Â  Â  return df_portfolios

Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  st.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š Worksheet à¸Šà¸·à¹ˆà¸­ '{WORKSHEET_PORTFOLIOS}' à¹ƒà¸™ Google Sheet '{GOOGLE_SHEET_NAME}'.")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  except gspread.exceptions.APIError as e_api:

Â  Â  Â  Â  if hasattr(e_api, 'response') and e_api.response and e_api.response.status_code == 429:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸” Portfolios (Quota Exceeded): {e_api.args[0] if e_api.args else 'Unknown quota error'}. à¸¥à¸­à¸‡à¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡à¹ƒà¸™à¸ à¸²à¸¢à¸«à¸¥à¸±à¸‡")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸” Portfolios (API Error): {e_api}")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  except Exception as e:

Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸” Portfolios: {e}")

Â  Â  Â  Â  return pd.DataFrame()



@st.cache_data(ttl=180)

def load_all_planned_trade_logs_from_gsheets():

Â  Â  gc = get_gspread_client()

Â  Â  if gc is None:

Â  Â  Â  Â  print("Warning: GSpread client not available for loading planned trade logs.")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  try:

Â  Â  Â  Â  sh = gc.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  worksheet = sh.worksheet(WORKSHEET_PLANNED_LOGS)

Â  Â  Â  Â  records = worksheet.get_all_records()

Â  Â  Â  Â Â 

Â  Â  Â  Â  if not records:

Â  Â  Â  Â  Â  Â  return pd.DataFrame()

Â  Â  Â  Â Â 

Â  Â  Â  Â  df_logs = pd.DataFrame(records)

Â  Â  Â  Â Â 

Â  Â  Â  Â  if 'Timestamp' in df_logs.columns:

Â  Â  Â  Â  Â  Â  df_logs['Timestamp'] = pd.to_datetime(df_logs['Timestamp'], errors='coerce')

Â  Â  Â  Â  if 'Risk $' in df_logs.columns:

Â  Â  Â  Â  Â  Â  df_logs['Risk $'] = pd.to_numeric(df_logs['Risk $'], errors='coerce').fillna(0)

Â  Â  Â  Â  if 'RR' in df_logs.columns:

Â  Â  Â  Â  Â  Â  df_logs['RR'] = pd.to_numeric(df_logs['RR'], errors='coerce')

Â  Â  Â  Â  if 'PortfolioID' in df_logs.columns:

Â  Â  Â  Â  Â  Â  df_logs['PortfolioID'] = df_logs['PortfolioID'].astype(str)

Â  Â  Â  Â Â 

Â  Â  Â  Â  cols_to_numeric_viewer = ['Entry', 'SL', 'TP', 'Lot', 'Risk %']

Â  Â  Â  Â  for col_viewer in cols_to_numeric_viewer:

Â  Â  Â  Â  Â  Â  if col_viewer in df_logs.columns:

Â  Â  Â  Â  Â  Â  Â  Â  df_logs[col_viewer] = pd.to_numeric(df_logs[col_viewer], errors='coerce')



Â  Â  Â  Â  return df_logs

Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  print(f"Warning: Worksheet '{WORKSHEET_PLANNED_LOGS}' not found for centralized loading.")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  except gspread.exceptions.APIError as e_api:

Â  Â  Â  Â  if hasattr(e_api, 'response') and e_api.response and e_api.response.status_code == 429:

Â  Â  Â  Â  Â  Â  print(f"APIError (Quota Exceeded) loading planned trade logs: {e_api.args[0] if e_api.args else 'Unknown quota error'}")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  print(f"APIError loading planned trade logs: {e_api}")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"Unexpected error loading all planned trade logs: {e}")

Â  Â  Â  Â  return pd.DataFrame()



@st.cache_data(ttl=180)

def load_actual_trades_from_gsheets():

Â  Â  gc = get_gspread_client()

Â  Â  if gc is None:

Â  Â  Â  Â  print("Warning: GSpread client not available for loading actual trades.")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  try:

Â  Â  Â  Â  sh = gc.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  worksheet = sh.worksheet(WORKSHEET_ACTUAL_TRADES)

Â  Â  Â  Â Â 

Â  Â  Â  Â  records = worksheet.get_all_records(numericise_ignore=['all'])

Â  Â  Â  Â Â 

Â  Â  Â  Â  if not records:

Â  Â  Â  Â  Â  Â  return pd.DataFrame()

Â  Â  Â  Â Â 

Â  Â  Â  Â  df_actual_trades = pd.DataFrame(records)

Â  Â  Â  Â Â 

Â  Â  Â  Â  if 'Time_Deal' in df_actual_trades.columns:

Â  Â  Â  Â  Â  Â  df_actual_trades['Time_Deal'] = pd.to_datetime(df_actual_trades['Time_Deal'], errors='coerce')



Â  Â  Â  Â  numeric_cols_actual = [

Â  Â  Â  Â  Â  Â  'Volume_Deal', 'Price_Deal', 'Commission_Deal',Â 

Â  Â  Â  Â  Â  Â  'Fee_Deal', 'Swap_Deal', 'Profit_Deal', 'Balance_Deal'

Â  Â  Â  Â  ]

Â  Â  Â  Â  for col in numeric_cols_actual:

Â  Â  Â  Â  Â  Â  if col in df_actual_trades.columns:

Â  Â  Â  Â  Â  Â  Â  Â  df_actual_trades[col] = pd.to_numeric(df_actual_trades[col], errors='coerce')



Â  Â  Â  Â  if 'PortfolioID' in df_actual_trades.columns:

Â  Â  Â  Â  Â  Â  df_actual_trades['PortfolioID'] = df_actual_trades['PortfolioID'].astype(str)

Â  Â  Â  Â Â 

Â  Â  Â  Â  return df_actual_trades



Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  print(f"Warning: Worksheet '{WORKSHEET_ACTUAL_TRADES}' not found for loading actual trades.")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  except gspread.exceptions.APIError as e_api:

Â  Â  Â  Â  if hasattr(e_api, 'response') and e_api.response and e_api.response.status_code == 429:

Â  Â  Â  Â  Â  Â  print(f"APIError (Quota Exceeded) loading actual trades from '{WORKSHEET_ACTUAL_TRADES}': {e_api.args[0] if e_api.args else 'Unknown quota error'}")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  print(f"APIError loading actual trades from '{WORKSHEET_ACTUAL_TRADES}': {e_api}")

Â  Â  Â  Â  return pd.DataFrame()

Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"Unexpected error loading actual trades from '{WORKSHEET_ACTUAL_TRADES}': {e}")

Â  Â  Â  Â  return pd.DataFrame()



# ===================== SEC 1: PORTFOLIO SELECTION (Sidebar) =======================

df_portfolios_gs = load_portfolios_from_gsheets()



st.sidebar.markdown("---")

st.sidebar.subheader("à¹€à¸¥à¸·à¸­à¸à¸à¸­à¸£à¹Œà¸•à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Active Portfolio)")



if 'active_portfolio_name_gs' not in st.session_state:

Â  Â  st.session_state.active_portfolio_name_gs = ""

if 'active_portfolio_id_gs' not in st.session_state:

Â  Â  st.session_state.active_portfolio_id_gs = None

if 'current_portfolio_details' not in st.session_state:

Â  Â  st.session_state.current_portfolio_details = None



portfolio_names_list_gs = [""]

if not df_portfolios_gs.empty and 'PortfolioName' in df_portfolios_gs.columns:

Â  Â  valid_portfolio_names = sorted(df_portfolios_gs['PortfolioName'].dropna().unique().tolist())

Â  Â  portfolio_names_list_gs.extend(valid_portfolio_names)



if st.session_state.active_portfolio_name_gs not in portfolio_names_list_gs:

Â  Â  st.session_state.active_portfolio_name_gs = portfolio_names_list_gs[0]



selected_portfolio_name_gs = st.sidebar.selectbox(

Â  Â  "à¹€à¸¥à¸·à¸­à¸à¸à¸­à¸£à¹Œà¸•:",

Â  Â  options=portfolio_names_list_gs,

Â  Â  index=portfolio_names_list_gs.index(st.session_state.active_portfolio_name_gs),

Â  Â  key='sb_active_portfolio_selector_gs'

)



if selected_portfolio_name_gs != st.session_state.active_portfolio_name_gs:

Â  Â  if 'ultimate_stmt_uploader_v7_final' in st.session_state and st.session_state.ultimate_stmt_uploader_v7_final is not None:

Â  Â  Â  Â  st.session_state.ultimate_stmt_uploader_v7_final = None

Â  Â  Â  Â  st.sidebar.warning("âš ï¸ à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸à¸­à¸£à¹Œà¸•à¸—à¸³à¹ƒà¸«à¹‰à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸§à¹‰ (à¹ƒà¸™à¸ªà¹ˆà¸§à¸™ Statement Import) à¸–à¸¹à¸à¸£à¸µà¹€à¸‹à¹‡à¸• à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡à¸«à¸²à¸à¸•à¹‰à¸­à¸‡à¸à¸²à¸£")



if selected_portfolio_name_gs != "":

Â  Â  st.session_state.active_portfolio_name_gs = selected_portfolio_name_gs

Â  Â  if not df_portfolios_gs.empty:

Â  Â  Â  Â  selected_portfolio_row_df = df_portfolios_gs[df_portfolios_gs['PortfolioName'] == selected_portfolio_name_gs]

Â  Â  Â  Â  if not selected_portfolio_row_df.empty:

Â  Â  Â  Â  Â  Â  st.session_state.current_portfolio_details = selected_portfolio_row_df.iloc[0].to_dict()

Â  Â  Â  Â  Â  Â  if 'PortfolioID' in st.session_state.current_portfolio_details:

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.active_portfolio_id_gs = st.session_state.current_portfolio_details['PortfolioID']

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.active_portfolio_id_gs = None

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.warning("à¹„à¸¡à¹ˆà¸à¸š PortfolioID à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸•à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸.")



Â  Â  Â  Â  Â  Â  portfolio_initial_balance_val = st.session_state.current_portfolio_details.get('InitialBalance')

Â  Â  Â  Â  Â  Â  if pd.notna(portfolio_initial_balance_val):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_account_balance = float(portfolio_initial_balance_val)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.latest_statement_equity = NoneÂ 

Â  Â  Â  Â  Â  Â  Â  Â  except (ValueError, TypeError):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.warning("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸›à¸¥à¸‡ InitialBalance à¸ˆà¸²à¸à¸à¸­à¸£à¹Œà¸•à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¹„à¸”à¹‰ à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹à¸—à¸™.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_account_balance = 10000.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.latest_statement_equity = None

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_account_balance = 10000.0

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.latest_statement_equity = None



Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  st.session_state.active_portfolio_id_gs = None

Â  Â  Â  Â  Â  Â  st.session_state.current_portfolio_details = None

Â  Â  Â  Â  Â  Â  st.sidebar.warning(f"à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸•à¸Šà¸·à¹ˆà¸­ '{selected_portfolio_name_gs}'.")

else:

Â  Â  st.session_state.active_portfolio_name_gs = ""

Â  Â  st.session_state.active_portfolio_id_gs = None

Â  Â  st.session_state.current_portfolio_details = None

Â  Â  st.session_state.current_account_balance = 10000.0

Â  Â  st.session_state.latest_statement_equity = None



if st.session_state.current_portfolio_details:

Â  Â  details = st.session_state.current_portfolio_details

Â  Â  st.sidebar.markdown(f"**ğŸ’¡ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸­à¸£à¹Œà¸• '{details.get('PortfolioName', 'N/A')}'**")

Â  Â  if pd.notna(details.get('InitialBalance')): st.sidebar.write(f"- Balance à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™: {details['InitialBalance']:,.2f} USD")

Â  Â  if pd.notna(details.get('ProgramType')): st.sidebar.write(f"- à¸›à¸£à¸°à¹€à¸ à¸—: {details['ProgramType']}")

Â  Â  if pd.notna(details.get('Status')): st.sidebar.write(f"- à¸ªà¸–à¸²à¸™à¸°: {details['Status']}")

Â  Â Â 

Â  Â  if details.get('ProgramType') in ["Prop Firm Challenge", "Funded Account", "Trading Competition"]:

Â  Â  Â  Â  if pd.notna(details.get('ProfitTargetPercent')): st.sidebar.write(f"- à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸à¸³à¹„à¸£: {details['ProfitTargetPercent']:.1f}%")

Â  Â  Â  Â  if pd.notna(details.get('DailyLossLimitPercent')): st.sidebar.write(f"- Daily Loss Limit: {details['DailyLossLimitPercent']:.1f}%")

Â  Â  Â  Â  if pd.notna(details.get('TotalStopoutPercent')): st.sidebar.write(f"- Total Stopout: {details['TotalStopoutPercent']:.1f}%")

elif not df_portfolios_gs.empty and selected_portfolio_name_gs == "":

Â  Â  Â st.sidebar.info("à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¸à¸­à¸£à¹Œà¸•à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£")

elif df_portfolios_gs.empty:

Â  Â  st.sidebar.warning("à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Portfolio à¹ƒà¸™ Google Sheets à¸«à¸£à¸·à¸­à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”.")



# ========== Function Utility (à¸•à¹ˆà¸­à¸ˆà¸²à¸à¸‚à¸­à¸‡à¹€à¸”à¸´à¸¡) ==========

def get_today_drawdown(log_source_df, acc_balance_input):

Â  Â  if log_source_df.empty:

Â  Â  Â  Â  return 0

Â  Â  today_str = datetime.now().strftime("%Y-%m-%d")

Â  Â  try:

Â  Â  Â  Â  if not pd.api.types.is_datetime64_any_dtype(log_source_df['Timestamp']):

Â  Â  Â  Â  Â  Â  log_source_df['Timestamp'] = pd.to_datetime(log_source_df['Timestamp'], errors='coerce')

Â  Â  Â  Â Â 

Â  Â  Â  Â  log_source_df = log_source_df.dropna(subset=['Timestamp'])



Â  Â  Â  Â  log_source_df['Risk $'] = pd.to_numeric(log_source_df['Risk $'], errors='coerce').fillna(0)

Â  Â  Â  Â  df_today = log_source_df[log_source_df["Timestamp"].dt.strftime("%Y-%m-%d") == today_str]

Â  Â  Â  Â  drawdown = df_today["Risk $"].sum()

Â  Â  Â  Â  return drawdown

Â  Â  except KeyError as e:Â 

Â  Â  Â  Â  return 0

Â  Â  except Exception as e:Â 

Â  Â  Â  Â  return 0



def get_performance(log_source_df, mode="week"):

Â  Â  if log_source_df.empty: return 0, 0, 0

Â  Â  try:

Â  Â  Â  Â  if not pd.api.types.is_datetime64_any_dtype(log_source_df['Timestamp']):

Â  Â  Â  Â  Â  Â  log_source_df['Timestamp'] = pd.to_datetime(log_source_df['Timestamp'], errors='coerce')

Â  Â  Â  Â Â 

Â  Â  Â  Â  log_source_df = log_source_df.dropna(subset=['Timestamp'])



Â  Â  Â  Â  log_source_df['Risk $'] = pd.to_numeric(log_source_df['Risk $'], errors='coerce').fillna(0)

Â  Â  Â  Â  now = datetime.now()

Â  Â  Â  Â  if mode == "week":

Â  Â  Â  Â  Â  Â  week_start_date = now - pd.Timedelta(days=now.weekday())

Â  Â  Â  Â  Â  Â  df_period = log_source_df[log_source_df["Timestamp"] >= week_start_date.replace(hour=0, minute=0, second=0, microsecond=0)]

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  month_start_date = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

Â  Â  Â  Â  Â  Â  df_period = log_source_df[log_source_df["Timestamp"] >= month_start_date]

Â  Â  Â  Â Â 

Â  Â  Â  Â  if "Risk $" not in df_period.columns:

Â  Â  Â  Â  Â  Â  return 0,0,0



Â  Â  Â  Â  win = df_period[df_period["Risk $"] > 0].shape[0]

Â  Â  Â  Â  loss = df_period[df_period["Risk $"] <= 0].shape[0]

Â  Â  Â  Â  total_trades = win + loss

Â  Â  Â  Â  winrate = (100 * win / total_trades) if total_trades > 0 else 0

Â  Â  Â  Â  gain = df_period["Risk $"].sum()

Â  Â  Â  Â  return winrate, gain, total_trades

Â  Â  except KeyError as e:Â 

Â  Â  Â  Â  return 0,0,0

Â  Â  except Exception as e:Â 

Â  Â  Â  Â  return 0,0,0



def save_plan_to_gsheets(plan_data_list, trade_mode_arg, asset_name, risk_percentage, trade_direction, portfolio_id, portfolio_name):

Â  Â  gc = get_gspread_client()

Â  Â  if not gc:

Â  Â  Â  Â  st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Google Sheets Client à¹€à¸à¸·à¹ˆà¸­à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸œà¸™à¹„à¸”à¹‰")

Â  Â  Â  Â  return False

Â  Â  try:

Â  Â  Â  Â  sh = gc.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  ws = sh.worksheet(WORKSHEET_PLANNED_LOGS)

Â  Â  Â  Â  timestamp_now = datetime.now()

Â  Â  Â  Â  rows_to_append = []

Â  Â  Â  Â  expected_headers_plan = [Â 

Â  Â  Â  Â  Â  Â  "LogID", "PortfolioID", "PortfolioName", "Timestamp", "Asset", "Mode", "Direction",

Â  Â  Â  Â  Â  Â  "Risk %", "Fibo Level", "Entry", "SL", "TP", "Lot", "Risk $", "RR"

Â  Â  Â  Â  ]

Â  Â  Â  Â  current_headers_plan = []

Â  Â  Â  Â  if ws.row_count > 0:

Â  Â  Â  Â  Â  Â  try: current_headers_plan = ws.row_values(1)

Â  Â  Â  Â  Â  Â  except Exception: current_headers_plan = []

Â  Â  Â  Â Â 

Â  Â  Â  Â  if not current_headers_plan or all(h == "" for h in current_headers_plan):

Â  Â  Â  Â  Â  Â  ws.update([expected_headers_plan], value_input_option='USER_ENTERED')

Â  Â  Â  Â  elif set(current_headers_plan) != set(expected_headers_plan) and any(h!="" for h in current_headers_plan):

Â  Â  Â  Â  Â  Â  Â st.warning(f"Worksheet '{WORKSHEET_PLANNED_LOGS}' has incorrect headers. Please ensure headers match: {', '.join(expected_headers_plan)}")



Â  Â  Â  Â  for idx, plan_entry in enumerate(plan_data_list):

Â  Â  Â  Â  Â  Â  log_id = f"{timestamp_now.strftime('%Y%m%d%H%M%S')}-{random.randint(1000,9999)}-{idx}"

Â  Â  Â  Â  Â  Â  row_data = {

Â  Â  Â  Â  Â  Â  Â  Â  "LogID": log_id, "PortfolioID": portfolio_id, "PortfolioName": portfolio_name,

Â  Â  Â  Â  Â  Â  Â  Â  "Timestamp": timestamp_now.strftime("%Y-%m-%d %H:%M:%S"), "Asset": asset_name,

Â  Â  Â  Â  Â  Â  Â  Â  "Mode": trade_mode_arg, "Direction": trade_direction, "Risk %": risk_percentage,

Â  Â  Â  Â  Â  Â  Â  Â  "Fibo Level": plan_entry.get("Fibo Level", ""), "Entry": plan_entry.get("Entry", "0.00"),

Â  Â  Â  Â  Â  Â  Â  Â  "SL": plan_entry.get("SL", "0.00"), "TP": plan_entry.get("TP", "0.00"),

Â  Â  Â  Â  Â  Â  Â  Â  "Lot": plan_entry.get("Lot", "0.00"), "Risk $": plan_entry.get("Risk $", "0.00"),

Â  Â  Â  Â  Â  Â  Â  Â  "RR": plan_entry.get("RR", "")

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  rows_to_append.append([str(row_data.get(h, "")) for h in expected_headers_plan])

Â  Â  Â  Â  if rows_to_append:

Â  Â  Â  Â  Â  Â  ws.append_rows(rows_to_append, value_input_option='USER_ENTERED')

Â  Â  Â  Â  Â  Â  return True

Â  Â  Â  Â  return False

Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  st.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š Worksheet à¸Šà¸·à¹ˆà¸­ '{WORKSHEET_PLANNED_LOGS}'.")

Â  Â  Â  Â  return False

Â  Â  except Exception as e:

Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸œà¸™: {e}")

Â  Â  Â  Â  return False



def save_new_portfolio_to_gsheets(portfolio_data_dict):

Â  Â  gc = get_gspread_client()Â 

Â  Â  if not gc:

Â  Â  Â  Â  st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Google Sheets Client à¹€à¸à¸·à¹ˆà¸­à¸šà¸±à¸™à¸—à¸¶à¸à¸à¸­à¸£à¹Œà¸•à¹„à¸”à¹‰")

Â  Â  Â  Â  return False

Â  Â  try:

Â  Â  Â  Â  sh = gc.open(GOOGLE_SHEET_NAME)Â 

Â  Â  Â  Â  ws = sh.worksheet(WORKSHEET_PORTFOLIOS)



Â  Â  Â  Â  expected_gsheet_headers_portfolio = [Â 

Â  Â  Â  Â  Â  Â  'PortfolioID', 'PortfolioName', 'ProgramType', 'EvaluationStep',Â 

Â  Â  Â  Â  Â  Â  'Status', 'InitialBalance', 'CreationDate',Â 

Â  Â  Â  Â  Â  Â  'ProfitTargetPercent', 'DailyLossLimitPercent', 'TotalStopoutPercent',

Â  Â  Â  Â  Â  Â  'Leverage', 'MinTradingDays',

Â  Â  Â  Â  Â  Â  'CompetitionEndDate', 'CompetitionGoalMetric',

Â  Â  Â  Â  Â  Â  'OverallProfitTarget', 'TargetEndDate', 'WeeklyProfitTarget', 'DailyProfitTarget',

Â  Â  Â  Â  Â  Â  'MaxAcceptableDrawdownOverall', 'MaxAcceptableDrawdownDaily',

Â  Â  Â  Â  Â  Â  'EnableScaling', 'ScalingCheckFrequency',

Â  Â  Â  Â  Â  Â  'ScaleUp_MinWinRate', 'ScaleUp_MinGainPercent', 'ScaleUp_RiskIncrementPercent',

Â  Â  Â  Â  Â  Â  'ScaleDown_MaxLossPercent', 'ScaleDown_LowWinRate', 'ScaleDown_RiskDecrementPercent',

Â  Â  Â  Â  Â  Â  'MinRiskPercentAllowed', 'MaxRiskPercentAllowed', 'CurrentRiskPercent',

Â  Â  Â  Â  Â  Â  'Notes'Â 

Â  Â  Â  Â  ]

Â  Â  Â  Â Â 

Â  Â  Â  Â  current_sheet_headers = []

Â  Â  Â  Â  if ws.row_count > 0:

Â  Â  Â  Â  Â  Â  try: current_sheet_headers = ws.row_values(1)

Â  Â  Â  Â  Â  Â  except Exception: passÂ 

Â  Â  Â  Â Â 

Â  Â  Â  Â  if not current_sheet_headers or all(h == "" for h in current_sheet_headers) :

Â  Â  Â  Â  Â  Â  Â ws.update([expected_gsheet_headers_portfolio], value_input_option='USER_ENTERED')Â 



Â  Â  Â  Â  new_row_values = [str(portfolio_data_dict.get(header, "")).strip() for header in expected_gsheet_headers_portfolio]

Â  Â  Â  Â  ws.append_row(new_row_values, value_input_option='USER_ENTERED')

Â  Â  Â  Â  return True

Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  st.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š Worksheet à¸Šà¸·à¹ˆà¸­ '{WORKSHEET_PORTFOLIOS}'. à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸µà¸•à¸™à¸µà¹‰à¸à¹ˆà¸­à¸™ à¹à¸¥à¸°à¹ƒà¸ªà¹ˆ Headers à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")

Â  Â  Â  Â  return False

Â  Â  except Exception as e:

Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¸à¸­à¸£à¹Œà¸•à¹ƒà¸«à¸¡à¹ˆà¹„à¸›à¸¢à¸±à¸‡ Google Sheets: {e}")

Â  Â  Â  Â  st.exception(e)Â 

Â  Â  Â  Â  return False



# ===================== SEC 1.5: PORTFOLIO MANAGEMENT UI (Main Area) =======================

def on_program_type_change_v8():

Â  Â  st.session_state.exp_pf_type_select_v8_key = st.session_state.exp_pf_type_selector_widget_v8



with st.expander("ğŸ’¼ à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸­à¸£à¹Œà¸• (à¹€à¸à¸´à¹ˆà¸¡/à¸”à¸¹à¸à¸­à¸£à¹Œà¸•)", expanded=True):

Â  Â  st.subheader("à¸à¸­à¸£à¹Œà¸•à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸‚à¸­à¸‡à¸„à¸¸à¸“")

Â  Â  if df_portfolios_gs.empty:

Â  Â  Â  Â  st.info("à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸­à¸£à¹Œà¸• à¸«à¸£à¸·à¸­à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸­à¸£à¹Œà¸• à¹‚à¸›à¸£à¸”à¹€à¸à¸´à¹ˆà¸¡à¸à¸­à¸£à¹Œà¸•à¹ƒà¸«à¸¡à¹ˆà¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡ à¸«à¸£à¸·à¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Google Sheets")

Â  Â  else:

Â  Â  Â  Â  cols_to_display_pf_table = ['PortfolioID', 'PortfolioName', 'ProgramType', 'EvaluationStep', 'Status', 'InitialBalance']

Â  Â  Â  Â  cols_exist_pf_table = [col for col in cols_to_display_pf_table if col in df_portfolios_gs.columns]

Â  Â  Â  Â  if cols_exist_pf_table:

Â  Â  Â  Â  Â  Â  st.dataframe(df_portfolios_gs[cols_exist_pf_table], use_container_width=True, hide_index=True)

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  st.info("à¹„à¸¡à¹ˆà¸à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹à¸ªà¸”à¸‡à¹ƒà¸™à¸•à¸²à¸£à¸²à¸‡à¸à¸­à¸£à¹Œà¸• (à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š df_portfolios_gs à¹à¸¥à¸°à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥)")



Â  Â  st.markdown("---")

Â  Â  st.subheader("â• à¹€à¸à¸´à¹ˆà¸¡à¸à¸­à¸£à¹Œà¸•à¹ƒà¸«à¸¡à¹ˆ")



Â  Â  program_type_options_outside = ["", "Personal Account", "Prop Firm Challenge", "Funded Account", "Trading Competition"]

Â  Â Â 

Â  Â  if 'exp_pf_type_select_v8_key' not in st.session_state:Â 

Â  Â  Â  Â  st.session_state.exp_pf_type_select_v8_key = ""



Â  Â  st.selectbox(

Â  Â  Â  Â  "à¸›à¸£à¸°à¹€à¸ à¸—à¸à¸­à¸£à¹Œà¸• (Program Type)*",Â 

Â  Â  Â  Â  options=program_type_options_outside,Â 

Â  Â  Â  Â  index=program_type_options_outside.index(st.session_state.exp_pf_type_select_v8_key),Â 

Â  Â  Â  Â  key="exp_pf_type_selector_widget_v8",Â 

Â  Â  Â  Â  on_change=on_program_type_change_v8Â 

Â  Â  )

Â  Â Â 

Â  Â  selected_program_type_to_use_in_form = st.session_state.exp_pf_type_select_v8_key



Â  Â  with st.form("new_portfolio_form_main_v8_final", clear_on_submit=True):Â 

Â  Â  Â  Â  st.markdown(f"**à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸­à¸£à¹Œà¸• (à¸ªà¸³à¸«à¸£à¸±à¸šà¸›à¸£à¸°à¹€à¸ à¸—: {selected_program_type_to_use_in_form if selected_program_type_to_use_in_form else 'à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸·à¸­à¸'})**")

Â  Â  Â  Â Â 

Â  Â  Â  Â  form_c1_in_form, form_c2_in_form = st.columns(2)

Â  Â  Â  Â  with form_c1_in_form:

Â  Â  Â  Â  Â  Â  form_new_portfolio_name_in_form = st.text_input("à¸Šà¸·à¹ˆà¸­à¸à¸­à¸£à¹Œà¸• (Portfolio Name)*", key="form_pf_name_v8")

Â  Â  Â  Â  with form_c2_in_form:

Â  Â  Â  Â  Â  Â  form_new_initial_balance_in_form = st.number_input("à¸šà¸²à¸¥à¸²à¸™à¸‹à¹Œà¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ (Initial Balance)*", min_value=0.01, value=10000.0, format="%.2f", key="form_pf_balance_v8")

Â  Â  Â  Â Â 

Â  Â  Â  Â  form_status_options_in_form = ["Active", "Inactive", "Pending", "Passed", "Failed"]

Â  Â  Â  Â  form_new_status_in_form = st.selectbox("à¸ªà¸–à¸²à¸™à¸°à¸à¸­à¸£à¹Œà¸• (Status)*", options=form_status_options_in_form, index=0, key="form_pf_status_v8")

Â  Â  Â  Â Â 

Â  Â  Â  Â  form_new_evaluation_step_val_in_form = ""

Â  Â  Â  Â  if selected_program_type_to_use_in_form == "Prop Firm Challenge":

Â  Â  Â  Â  Â  Â  evaluation_step_options_in_form = ["", "Phase 1", "Phase 2", "Phase 3", "Verification"]

Â  Â  Â  Â  Â  Â  form_new_evaluation_step_val_in_form = st.selectbox("à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™ (Evaluation Step)",Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  options=evaluation_step_options_in_form, index=0,Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key="form_pf_eval_step_select_v8")



Â  Â  Â  Â  form_profit_target_val = 8.0; form_daily_loss_val = 5.0; form_total_stopout_val = 10.0; form_leverage_val = 100.0; form_min_days_val = 0

Â  Â  Â  Â  form_comp_end_date = None; form_comp_goal_metric = ""

Â  Â  Â  Â  form_profit_target_val_comp = 20.0

Â  Â  Â  Â  form_daily_loss_val_comp = 5.0Â  Â Â 

Â  Â  Â  Â  form_total_stopout_val_comp = 10.0



Â  Â  Â  Â  form_pers_overall_profit_val = 0.0; form_pers_target_end_date = None; form_pers_weekly_profit_val = 0.0; form_pers_daily_profit_val = 0.0

Â  Â  Â  Â  form_pers_max_dd_overall_val = 0.0; form_pers_max_dd_daily_val = 0.0

Â  Â  Â  Â  form_enable_scaling_checkbox_val = False; form_scaling_freq_val = "Weekly"; form_su_wr_val = 55.0; form_su_gain_val = 2.0; form_su_inc_val = 0.25

Â  Â  Â  Â  form_sd_loss_val = -5.0; form_sd_wr_val = 40.0; form_sd_dec_val = 0.25; form_min_risk_val = 0.25; form_max_risk_val = 2.0; form_current_risk_val = 1.0

Â  Â  Â  Â  form_notes_val = ""



Â  Â  Â  Â  if selected_program_type_to_use_in_form in ["Prop Firm Challenge", "Funded Account"]:

Â  Â  Â  Â  Â  Â  st.markdown("**à¸à¸à¹€à¸à¸“à¸‘à¹Œ Prop Firm/Funded:**")

Â  Â  Â  Â  Â  Â  f_pf1, f_pf2, f_pf3 = st.columns(3)

Â  Â  Â  Â  Â  Â  with f_pf1: form_profit_target_val = st.number_input("à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸à¸³à¹„à¸£ %*", value=form_profit_target_val, format="%.1f", key="f_pf_profit_v8")

Â  Â  Â  Â  Â  Â  with f_pf2: form_daily_loss_val = st.number_input("à¸ˆà¸³à¸à¸±à¸”à¸‚à¸²à¸”à¸—à¸¸à¸™à¸•à¹ˆà¸­à¸§à¸±à¸™ %*", value=form_daily_loss_val, format="%.1f", key="f_pf_dd_v8")

Â  Â  Â  Â  Â  Â  with f_pf3: form_total_stopout_val = st.number_input("à¸ˆà¸³à¸à¸±à¸”à¸‚à¸²à¸”à¸—à¸¸à¸™à¸£à¸§à¸¡ %*", value=form_total_stopout_val, format="%.1f", key="f_pf_maxdd_v8")

Â  Â  Â  Â  Â  Â  f_pf_col1, f_pf_col2 = st.columns(2)

Â  Â  Â  Â  Â  Â  with f_pf_col1: form_leverage_val = st.number_input("Leverage", value=form_leverage_val, format="%.0f", key="f_pf_lev_v8")

Â  Â  Â  Â  Â  Â  with f_pf_col2: form_min_days_val = st.number_input("à¸ˆà¸³à¸™à¸§à¸™à¸§à¸±à¸™à¹€à¸—à¸£à¸”à¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³", value=form_min_days_val, step=1, key="f_pf_mindays_v8")

Â  Â  Â  Â Â 

Â  Â  Â  Â  if selected_program_type_to_use_in_form == "Trading Competition":

Â  Â  Â  Â  Â  Â  st.markdown("**à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¹à¸‚à¹ˆà¸‡à¸‚à¸±à¸™:**")

Â  Â  Â  Â  Â  Â  f_tc1, f_tc2 = st.columns(2)

Â  Â  Â  Â  Â  Â  with f_tc1:Â 

Â  Â  Â  Â  Â  Â  Â  Â  form_comp_end_date = st.date_input("à¸§à¸±à¸™à¸ªà¸´à¹‰à¸™à¸ªà¸¸à¸”à¸à¸²à¸£à¹à¸‚à¹ˆà¸‡à¸‚à¸±à¸™", value=form_comp_end_date, key="f_tc_enddate_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_profit_target_val_comp = st.number_input("à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸à¸³à¹„à¸£ % (Comp)", value=form_profit_target_val_comp, format="%.1f", key="f_tc_profit_v8")Â 

Â  Â  Â  Â  Â  Â  with f_tc2:Â 

Â  Â  Â  Â  Â  Â  Â  Â  form_comp_goal_metric = st.text_input("à¸•à¸±à¸§à¸Šà¸µà¹‰à¸§à¸±à¸”à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢ (Comp)", value=form_comp_goal_metric, help="à¹€à¸Šà¹ˆà¸™ %Gain, ROI", key="f_tc_goalmetric_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_daily_loss_val_comp = st.number_input("à¸ˆà¸³à¸à¸±à¸”à¸‚à¸²à¸”à¸—à¸¸à¸™à¸•à¹ˆà¸­à¸§à¸±à¸™ % (Comp)", value=form_daily_loss_val_comp, format="%.1f", key="f_tc_dd_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_total_stopout_val_comp = st.number_input("à¸ˆà¸³à¸à¸±à¸”à¸‚à¸²à¸”à¸—à¸¸à¸™à¸£à¸§à¸¡ % (Comp)", value=form_total_stopout_val_comp, format="%.1f", key="f_tc_maxdd_v8")



Â  Â  Â  Â  if selected_program_type_to_use_in_form == "Personal Account":

Â  Â  Â  Â  Â  Â  st.markdown("**à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸ªà¹ˆà¸§à¸™à¸•à¸±à¸§ (Optional):**")

Â  Â  Â  Â  Â  Â  f_ps1, f_ps2 = st.columns(2)

Â  Â  Â  Â  Â  Â  with f_ps1:

Â  Â  Â  Â  Â  Â  Â  Â  form_pers_overall_profit_val = st.number_input("à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸à¸³à¹„à¸£à¹‚à¸”à¸¢à¸£à¸§à¸¡ ($)", value=form_pers_overall_profit_val, format="%.2f", key="f_ps_profit_overall_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_pers_weekly_profit_val = st.number_input("à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸à¸³à¹„à¸£à¸£à¸²à¸¢à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œ ($)", value=form_pers_weekly_profit_val, format="%.2f", key="f_ps_profit_weekly_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_pers_max_dd_overall_val = st.number_input("Max DD à¸£à¸§à¸¡à¸—à¸µà¹ˆà¸¢à¸­à¸¡à¸£à¸±à¸šà¹„à¸”à¹‰ ($)", value=form_pers_max_dd_overall_val, format="%.2f", key="f_ps_dd_overall_v8")

Â  Â  Â  Â  Â  Â  with f_ps2:

Â  Â  Â  Â  Â  Â  Â  Â  form_pers_target_end_date = st.date_input("à¸§à¸±à¸™à¸—à¸µà¹ˆà¸„à¸²à¸”à¸§à¹ˆà¸²à¸ˆà¸°à¸–à¸¶à¸‡à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸£à¸§à¸¡", value=form_pers_target_end_date, key="f_ps_enddate_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_pers_daily_profit_val = st.number_input("à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸à¸³à¹„à¸£à¸£à¸²à¸¢à¸§à¸±à¸™ ($)", value=form_pers_daily_profit_val, format="%.2f", key="f_ps_profit_daily_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_pers_max_dd_daily_val = st.number_input("Max DD à¸•à¹ˆà¸­à¸§à¸±à¸™à¸—à¸µà¹ˆà¸¢à¸­à¸¡à¸£à¸±à¸šà¹„à¸”à¹‰ ($)", value=form_pers_max_dd_daily_val, format="%.2f", key="f_ps_dd_daily_v8")



Â  Â  Â  Â  st.markdown("**à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Scaling Manager (Optional):**")

Â  Â  Â  Â  form_enable_scaling_checkbox_val = st.checkbox("à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Scaling Manager?", value=form_enable_scaling_checkbox_val, key="f_scale_enable_v8")

Â  Â  Â  Â  if form_enable_scaling_checkbox_val:

Â  Â  Â  Â  Â  Â  f_sc1, f_sc2, f_sc3 = st.columns(3)

Â  Â  Â  Â  Â  Â  with f_sc1:

Â  Â  Â  Â  Â  Â  Â  Â  form_scaling_freq_val = st.selectbox("à¸„à¸§à¸²à¸¡à¸–à¸µà¹ˆà¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Scaling", ["Weekly", "Monthly"], index=["Weekly", "Monthly"].index(form_scaling_freq_val), key="f_scale_freq_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_su_wr_val = st.number_input("Scale Up: Min Winrate %", value=form_su_wr_val, format="%.1f", key="f_scale_su_wr_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_sd_loss_val = st.number_input("Scale Down: Max Loss %", value=form_sd_loss_val, format="%.1f", key="f_scale_sd_loss_v8")

Â  Â  Â  Â  Â  Â  with f_sc2:

Â  Â  Â  Â  Â  Â  Â  Â  form_min_risk_val = st.number_input("Min Risk % Allowed", value=form_min_risk_val, format="%.2f", key="f_scale_min_risk_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_su_gain_val = st.number_input("Scale Up: Min Gain %", value=form_su_gain_val, format="%.1f", key="f_scale_su_gain_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_sd_wr_val = st.number_input("Scale Down: Low Winrate %", value=form_sd_wr_val, format="%.1f", key="f_scale_sd_wr_v8")

Â  Â  Â  Â  Â  Â  with f_sc3:

Â  Â  Â  Â  Â  Â  Â  Â  form_max_risk_val = st.number_input("Max Risk % Allowed", value=form_max_risk_val, format="%.2f", key="f_scale_max_risk_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_su_inc_val = st.number_input("Scale Up: Risk Increment %", value=form_su_inc_val, format="%.2f", key="f_scale_su_inc_v8")

Â  Â  Â  Â  Â  Â  Â  Â  form_sd_dec_val = st.number_input("Scale Down: Risk Decrement %", value=form_sd_dec_val, format="%.2f", key="f_scale_sd_dec_v8")

Â  Â  Â  Â  Â  Â  form_current_risk_val = st.number_input("Current Risk % (à¸ªà¸³à¸«à¸£à¸±à¸š Scaling)", value=form_current_risk_val, format="%.2f", key="f_scale_current_risk_v8")



Â  Â  Â  Â  form_notes_val = st.text_area("à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡ (Notes)", value=form_notes_val, key="f_pf_notes_v8")



Â  Â  Â  Â  submitted_add_portfolio_in_form = st.form_submit_button("ğŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸à¸à¸­à¸£à¹Œà¸•à¹ƒà¸«à¸¡à¹ˆ")

Â  Â  Â  Â Â 

Â  Â  Â  Â  if submitted_add_portfolio_in_form:

Â  Â  Â  Â  Â  Â  if not form_new_portfolio_name_in_form or not selected_program_type_to_use_in_form or not form_new_status_in_form or form_new_initial_balance_in_form <= 0:

Â  Â  Â  Â  Â  Â  Â  Â  st.warning("à¸à¸£à¸¸à¸“à¸²à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™ (*) à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹à¸¥à¸°à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡: à¸Šà¸·à¹ˆà¸­à¸à¸­à¸£à¹Œà¸•, à¸›à¸£à¸°à¹€à¸ à¸—à¸à¸­à¸£à¹Œà¸•, à¸ªà¸–à¸²à¸™à¸°à¸à¸­à¸£à¹Œà¸•, à¹à¸¥à¸°à¸¢à¸­à¸”à¹€à¸‡à¸´à¸™à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 0")

Â  Â  Â  Â  Â  Â  elif not df_portfolios_gs.empty and form_new_portfolio_name_in_form in df_portfolios_gs['PortfolioName'].astype(str).values:

Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"à¸Šà¸·à¹ˆà¸­à¸à¸­à¸£à¹Œà¸• '{form_new_portfolio_name_in_form}' à¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§ à¸à¸£à¸¸à¸“à¸²à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¸­à¸·à¹ˆà¸™")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  new_id_value = str(uuid.uuid4())

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  data_to_save = {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PortfolioID': new_id_value,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PortfolioName': form_new_portfolio_name_in_form,Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ProgramType': selected_program_type_to_use_in_form,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'EvaluationStep': form_new_evaluation_step_val_in_form if selected_program_type_to_use_in_form == "Prop Firm Challenge" else "",Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Status': form_new_status_in_form,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'InitialBalance': form_new_initial_balance_in_form,Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'CreationDate': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Notes': form_notes_val

Â  Â  Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  Â  Â  if selected_program_type_to_use_in_form in ["Prop Firm Challenge", "Funded Account"]:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data_to_save.update({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ProfitTargetPercent': form_profit_target_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DailyLossLimitPercent': form_daily_loss_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'TotalStopoutPercent': form_total_stopout_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Leverage': form_leverage_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'MinTradingDays': form_min_days_val

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if selected_program_type_to_use_in_form == "Trading Competition":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data_to_save.update({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'CompetitionEndDate': form_comp_end_date.strftime("%Y-%m-%d") if form_comp_end_date else None,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'CompetitionGoalMetric': form_comp_goal_metric,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ProfitTargetPercent': form_profit_target_val_comp,Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DailyLossLimitPercent': form_daily_loss_val_comp,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'TotalStopoutPercent': form_total_stopout_val_comp

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })



Â  Â  Â  Â  Â  Â  Â  Â  if selected_program_type_to_use_in_form == "Personal Account":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data_to_save.update({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'OverallProfitTarget': form_pers_overall_profit_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'TargetEndDate': form_pers_target_end_date.strftime("%Y-%m-%d") if form_pers_target_end_date else None,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'WeeklyProfitTarget': form_pers_weekly_profit_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DailyProfitTarget': form_pers_daily_profit_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'MaxAcceptableDrawdownOverall': form_pers_max_dd_overall_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'MaxAcceptableDrawdownDaily': form_pers_max_dd_daily_val

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })



Â  Â  Â  Â  Â  Â  Â  Â  if form_enable_scaling_checkbox_val:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data_to_save.update({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'EnableScaling': True,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ScalingCheckFrequency': form_scaling_freq_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ScaleUp_MinWinRate': form_su_wr_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ScaleUp_MinGainPercent': form_su_gain_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ScaleUp_RiskIncrementPercent': form_su_inc_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ScaleDown_MaxLossPercent': form_sd_loss_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ScaleDown_LowWinRate': form_sd_wr_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ScaleDown_RiskDecrementPercent': form_sd_dec_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'MinRiskPercentAllowed': form_min_risk_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'MaxRiskPercentAllowed': form_max_risk_val,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'CurrentRiskPercent': form_current_risk_val

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data_to_save['EnableScaling'] = False

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data_to_save['CurrentRiskPercent'] = form_current_risk_val



Â  Â  Â  Â  Â  Â  Â  Â  success_save = save_new_portfolio_to_gsheets(data_to_save)Â 

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if success_save:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"à¹€à¸à¸´à¹ˆà¸¡à¸à¸­à¸£à¹Œà¸• '{form_new_portfolio_name_in_form}' (ID: {new_id_value}) à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.exp_pf_type_select_v8_key = ""

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if hasattr(load_portfolios_from_gsheets, 'clear'):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â load_portfolios_from_gsheets.clear()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¸à¸­à¸£à¹Œà¸•à¹ƒà¸«à¸¡à¹ˆà¹„à¸›à¸¢à¸±à¸‡ Google Sheets")



# ==============================================================================

# END: à¸ªà¹ˆà¸§à¸™à¸ˆà¸±à¸”à¸à¸²à¸£ Portfolio (SEC 1.5)

# ==============================================================================



# ===================== SEC 2: COMMON INPUTS & MODE SELECTION =======================

active_balance_to_use = 10000.0

initial_risk_pct_from_portfolio = 1.0



if 'latest_statement_equity' in st.session_state and st.session_state.latest_statement_equity is not None:

Â  Â  active_balance_to_use = st.session_state.latest_statement_equity

Â  Â  st.session_state.current_account_balance = st.session_state.latest_statement_equity

Â  Â  st.sidebar.markdown(f"**ğŸ’° Balance à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“:** <font color='lime'>{st.session_state.current_account_balance:,.2f} USD (à¸ˆà¸²à¸ Statement Equity)</font>", unsafe_allow_html=True)

elif 'current_portfolio_details' in st.session_state and st.session_state.current_portfolio_details:

Â  Â  details = st.session_state.current_portfolio_details

Â  Â Â 

Â  Â  portfolio_initial_balance_val = details.get('InitialBalance')

Â  Â  if pd.notna(portfolio_initial_balance_val):

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  active_balance_to_use = float(portfolio_initial_balance_val)

Â  Â  Â  Â  Â  Â  st.session_state.current_account_balance = active_balance_to_use

Â  Â  Â  Â  Â  Â  st.sidebar.markdown(f"**ğŸ’° Balance à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“:** <font color='gold'>{st.session_state.current_account_balance:,.2f} USD (à¸ˆà¸²à¸ Initial Balance à¸à¸­à¸£à¹Œà¸•)</font>", unsafe_allow_html=True)

Â  Â  Â  Â  except (ValueError, TypeError):

Â  Â  Â  Â  Â  Â  st.sidebar.warning("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸›à¸¥à¸‡ InitialBalance à¸ˆà¸²à¸à¸à¸­à¸£à¹Œà¸•à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¹„à¸”à¹‰ à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹à¸—à¸™")

Â  Â  Â  Â  Â  Â  st.session_state.current_account_balance = 10000.0

Â  Â  Â  Â  Â  Â  st.sidebar.markdown(f"**ğŸ’° Balance à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“:** {st.session_state.current_account_balance:,.2f} USD (à¸ˆà¸²à¸à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™)", unsafe_allow_html=True)

Â  Â  else:

Â  Â  Â  Â  st.session_state.current_account_balance = 10000.0

Â  Â  Â  Â  st.sidebar.markdown(f"**ğŸ’° Balance à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“:** {st.session_state.current_account_balance:,.2f} USD (à¸ˆà¸²à¸à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™)", unsafe_allow_html=True)



else:

Â  Â  st.session_state.current_account_balance = 10000.0

Â  Â  st.sidebar.info("à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸·à¸­à¸à¸à¸­à¸£à¹Œà¸• à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸­à¸£à¹Œà¸• à¹ƒà¸Šà¹‰ Balance à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™: 10,000.00 USD")

Â  Â  st.sidebar.markdown(f"**ğŸ’° Balance à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“:** {st.session_state.current_account_balance:,.2f} USD (à¸ˆà¸²à¸à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™)", unsafe_allow_html=True)



if 'current_portfolio_details' in st.session_state and st.session_state.current_portfolio_details:

Â  Â  details = st.session_state.current_portfolio_details

Â  Â  current_risk_val_str = details.get('CurrentRiskPercent')

Â  Â  if pd.notna(current_risk_val_str) and str(current_risk_val_str).strip() != "":

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  risk_val_float = float(current_risk_val_str)

Â  Â  Â  Â  Â  Â  if risk_val_float > 0:

Â  Â  Â  Â  Â  Â  Â  Â  Â initial_risk_pct_from_portfolio = risk_val_float

Â  Â  Â  Â  except (ValueError, TypeError):

Â  Â  Â  Â  Â  Â  st.sidebar.warning("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸›à¸¥à¸‡ CurrentRiskPercent à¸ˆà¸²à¸à¸à¸­à¸£à¹Œà¸•à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¹„à¸”à¹‰ à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹à¸—à¸™")

Â  Â  Â  Â  Â  Â  pass



drawdown_limit_pct = st.sidebar.number_input(

Â  Â  "Drawdown Limit à¸•à¹ˆà¸­à¸§à¸±à¸™ (%)",

Â  Â  min_value=0.1, max_value=20.0,

Â  Â  value=st.session_state.get("drawdown_limit_pct", 2.0),

Â  Â  step=0.1, format="%.1f",

Â  Â  key="drawdown_limit_pct"

)



mode = st.sidebar.radio("Trade Mode", ["FIBO", "CUSTOM"], horizontal=True, key="mode")



if st.sidebar.button("ğŸ”„ Reset Form"):

Â  Â  mode_to_keep = st.session_state.get("mode", "FIBO")

Â  Â  dd_limit_to_keep = st.session_state.get("drawdown_limit_pct", 2.0)

Â  Â Â 

Â  Â  active_portfolio_name_gs_keep = st.session_state.get('active_portfolio_name_gs', "")

Â  Â  active_portfolio_id_gs_keep = st.session_state.get('active_portfolio_id_gs', None)

Â  Â  current_portfolio_details_keep = st.session_state.get('current_portfolio_details', None)

Â  Â Â 

Â  Â  sb_active_portfolio_selector_gs_keep = st.session_state.get('sb_active_portfolio_selector_gs', "")



Â  Â  keys_to_fully_preserve = {"gcp_service_account"}

Â  Â  temp_preserved_values = {}

Â  Â  for k_fp in keys_to_fully_preserve:

Â  Â  Â  Â  if k_fp in st.session_state:

Â  Â  Â  Â  Â  Â  temp_preserved_values[k_fp] = st.session_state[k_fp]



Â  Â  keys_to_clear = [k for k in st.session_state.keys() if k not in keys_to_fully_preserve]

Â  Â  for key in keys_to_clear:

Â  Â  Â  Â  del st.session_state[key]

Â  Â  Â  Â  Â  Â Â 

Â  Â  for k_fp, v_fp in temp_preserved_values.items():

Â  Â  Â  Â  st.session_state[k_fp] = v_fp



Â  Â  st.session_state.mode = mode_to_keep

Â  Â  st.session_state.drawdown_limit_pct = dd_limit_to_keep

Â  Â Â 

Â  Â  st.session_state.active_portfolio_name_gs = active_portfolio_name_gs_keep

Â  Â  st.session_state.active_portfolio_id_gs = active_portfolio_id_gs_keep

Â  Â  st.session_state.current_portfolio_details = current_portfolio_details_keep

Â  Â Â 

Â  Â  if sb_active_portfolio_selector_gs_keep:Â 

Â  Â  Â  Â  st.session_state.sb_active_portfolio_selector_gs = sb_active_portfolio_selector_gs_keep



Â  Â  preserved_active_balance = 10000.0

Â  Â  preserved_initial_risk = 1.0

Â  Â  preserved_latest_statement_equity = None

Â  Â  if 'latest_statement_equity' in st.session_state and st.session_state.latest_statement_equity is not None:

Â  Â  Â  Â  preserved_latest_statement_equity = st.session_state.latest_statement_equity

Â  Â  Â  Â  preserved_active_balance = preserved_latest_statement_equity

Â  Â  elif current_portfolio_details_keep:

Â  Â  Â  Â  pf_balance_val = current_portfolio_details_keep.get('InitialBalance')

Â  Â  Â  Â  if pd.notna(pf_balance_val):

Â  Â  Â  Â  Â  Â  try: preserved_active_balance = float(pf_balance_val)

Â  Â  Â  Â  Â  Â  except (ValueError, TypeError): pass

Â  Â  Â  Â Â 

Â  Â  Â  Â  pf_risk_str = current_portfolio_details_keep.get('CurrentRiskPercent')

Â  Â  Â  Â  if pd.notna(pf_risk_str) and str(pf_risk_str).strip() != "":

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  pf_risk_float = float(pf_risk_str)

Â  Â  Â  Â  Â  Â  Â  Â  if pf_risk_float > 0: preserved_initial_risk = pf_risk_float

Â  Â  Â  Â  Â  Â  except (ValueError, TypeError): pass

Â  Â  Â  Â  Â  Â Â 

Â  Â  st.session_state.current_account_balance = preserved_active_balance

Â  Â  st.session_state.latest_statement_equity = preserved_latest_statement_equity



Â  Â  st.session_state.risk_pct_fibo_val_v2 = preserved_initial_risk

Â  Â  st.session_state.asset_fibo_val_v2 = "XAUUSD"Â 

Â  Â  st.session_state.risk_pct_custom_val_v2 = preserved_initial_risk

Â  Â  st.session_state.asset_custom_val_v2 = "XAUUSD"Â 



Â  Â  st.session_state.swing_high_fibo_val_v2 = ""

Â  Â  st.session_state.swing_low_fibo_val_v2 = ""

Â  Â  st.session_state.fibo_flags_v2 = [True] * 5



Â  Â  default_n_entries_custom = 2

Â  Â  st.session_state.n_entry_custom_val_v2 = default_n_entries_custom

Â  Â  for i in range(default_n_entries_custom):

Â  Â  Â  Â  st.session_state[f"custom_entry_{i}_v3"] = "0.00"

Â  Â  Â  Â  st.session_state[f"custom_sl_{i}_v3"] = "0.00"

Â  Â  Â  Â  st.session_state[f"custom_tp_{i}_v3"] = "0.00"

Â  Â  Â  Â Â 

Â  Â  if 'plot_data' in st.session_state:

Â  Â  Â  Â  del st.session_state['plot_data']

Â  Â  Â  Â Â 

Â  Â  st.toast("à¸£à¸µà¹€à¸‹à¹‡à¸•à¸Ÿà¸­à¸£à¹Œà¸¡à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¹à¸¥à¹‰à¸§!", icon="ğŸ”„")

Â  Â  st.rerun()



# ===================== SEC 2.1: FIBO TRADE DETAILS =======================

if mode == "FIBO":

Â  Â  col1_fibo_v2, col2_fibo_v2, col3_fibo_v2 = st.sidebar.columns([2, 2, 2])

Â  Â  with col1_fibo_v2:

Â  Â  Â  Â  asset_fibo_v2 = st.text_input("Asset",Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â value=st.session_state.get("asset_fibo_val_v2", "XAUUSD"),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â key="asset_fibo_input_v3")Â 

Â  Â  Â  Â  st.session_state.asset_fibo_val_v2 = asset_fibo_v2

Â  Â  with col2_fibo_v2:

Â  Â  Â  Â  risk_pct_fibo_v2 = st.number_input(

Â  Â  Â  Â  Â  Â  "Risk %",

Â  Â  Â  Â  Â  Â  min_value=0.01, max_value=100.0,

Â  Â  Â  Â  Â  Â  value=st.session_state.get("risk_pct_fibo_val_v2", initial_risk_pct_from_portfolio),

Â  Â  Â  Â  Â  Â  step=0.01, format="%.2f",

Â  Â  Â  Â  Â  Â  key="risk_pct_fibo_input_v3")Â 

Â  Â  Â  Â  st.session_state.risk_pct_fibo_val_v2 = risk_pct_fibo_v2

Â  Â  with col3_fibo_v2:

Â  Â  Â  Â  default_direction_index = 0

Â  Â  Â  Â  if "direction_fibo_val_v2" in st.session_state:

Â  Â  Â  Â  Â  Â  if st.session_state.direction_fibo_val_v2 == "Short":

Â  Â  Â  Â  Â  Â  Â  Â  default_direction_index = 1

Â  Â  Â  Â Â 

Â  Â  Â  Â  direction_fibo_v2 = st.radio("Direction", ["Long", "Short"],Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  index=default_direction_index,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  horizontal=True, key="fibo_direction_radio_v3")Â 

Â  Â  Â  Â  st.session_state.direction_fibo_val_v2 = direction_fibo_v2



Â  Â  col4_fibo_v2, col5_fibo_v2 = st.sidebar.columns(2)

Â  Â  with col4_fibo_v2:

Â  Â  Â  Â  swing_high_fibo_v2 = st.text_input("High",Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value=st.session_state.get("swing_high_fibo_val_v2", ""),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key="swing_high_fibo_input_v3")Â 

Â  Â  Â  Â  st.session_state.swing_high_fibo_val_v2 = swing_high_fibo_v2

Â  Â  with col5_fibo_v2:

Â  Â  Â  Â  swing_low_fibo_v2 = st.text_input("Low",Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â value=st.session_state.get("swing_low_fibo_val_v2", ""),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â key="swing_low_fibo_input_v3")Â 

Â  Â  Â  Â  st.session_state.swing_low_fibo_val_v2 = swing_low_fibo_v2



Â  Â  st.sidebar.markdown("**ğŸ“ Entry Fibo Levels**")

Â  Â  fibos_fibo_v2 = [0.114, 0.25, 0.382, 0.5, 0.618]Â 

Â  Â  labels_fibo_v2 = [f"{l:.3f}" for l in fibos_fibo_v2]

Â  Â  cols_fibo_v2 = st.sidebar.columns(len(fibos_fibo_v2))



Â  Â  if "fibo_flags_v2" not in st.session_state:Â 

Â  Â  Â  Â  st.session_state.fibo_flags_v2 = [True] * len(fibos_fibo_v2)



Â  Â  fibo_selected_flags_v2 = []

Â  Â  for i, col_fibo_v2_loop in enumerate(cols_fibo_v2):Â 

Â  Â  Â  Â  checked_fibo_v2 = col_fibo_v2_loop.checkbox(labels_fibo_v2[i],Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â value=st.session_state.fibo_flags_v2[i],Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â key=f"fibo_cb_{i}_v3")Â 

Â  Â  Â  Â  fibo_selected_flags_v2.append(checked_fibo_v2)

Â  Â  st.session_state.fibo_flags_v2 = fibo_selected_flags_v2



Â  Â  try:

Â  Â  Â  Â  high_val_fibo_v2 = float(swing_high_fibo_v2) if swing_high_fibo_v2 else 0.0

Â  Â  Â  Â  low_val_fibo_v2 = float(swing_low_fibo_v2) if swing_low_fibo_v2 else 0.0

Â  Â  Â  Â  if swing_high_fibo_v2 and swing_low_fibo_v2:

Â  Â  Â  Â  Â  Â  if high_val_fibo_v2 <= low_val_fibo_v2:

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.warning("High à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² Low!")

Â  Â  except ValueError:

Â  Â  Â  Â  if swing_high_fibo_v2 or swing_low_fibo_v2:

Â  Â  Â  Â  Â  Â  st.sidebar.warning("à¸à¸£à¸¸à¸“à¸²à¹ƒà¸ªà¹ˆ High/Low à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")



Â  Â  if risk_pct_fibo_v2 <= 0:Â 

Â  Â  Â  Â  st.sidebar.warning("Risk% à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 0")



Â  Â  st.sidebar.markdown("---")

Â  Â  try:

Â  Â  Â  Â  if swing_high_fibo_v2 and swing_low_fibo_v2:

Â  Â  Â  Â  Â  Â  high_preview_fibo_v2 = float(swing_high_fibo_v2)

Â  Â  Â  Â  Â  Â  low_preview_fibo_v2 = float(swing_low_fibo_v2)

Â  Â  Â  Â  Â  Â  if high_preview_fibo_v2 > low_preview_fibo_v2 and any(st.session_state.fibo_flags_v2):

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.markdown("**Preview (à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™):**")

Â  Â  Â  Â  Â  Â  Â  Â  first_selected_fibo_index_v2 = -1

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  first_selected_fibo_index_v2 = st.session_state.fibo_flags_v2.index(True)

Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if first_selected_fibo_index_v2 != -1:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  preview_entry_fibo_v2 = 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if direction_fibo_v2 == "Long":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  preview_entry_fibo_v2 = low_preview_fibo_v2 + (high_preview_fibo_v2 - low_preview_fibo_v2) * fibos_fibo_v2[first_selected_fibo_index_v2]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  preview_entry_fibo_v2 = high_preview_fibo_v2 - (high_preview_fibo_v2 - low_preview_fibo_v2) * fibos_fibo_v2[first_selected_fibo_index_v2]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.markdown(f"Entry à¹à¸£à¸à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸ â‰ˆ **{preview_entry_fibo_v2:.2f}**")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.caption("Lot/TP/à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹€à¸•à¹‡à¸¡à¸­à¸¢à¸¹à¹ˆà¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡ (à¹ƒà¸™ Strategy Summary)")

Â  Â  except ValueError:

Â  Â  Â  Â  pass

Â  Â  except Exception:

Â  Â  Â  Â  pass



Â  Â  save_fibo = st.sidebar.button("ğŸ’¾ Save Plan (FIBO)", key="save_fibo_v3")



# ===================== SEC 2.2: CUSTOM TRADE DETAILS =======================

elif mode == "CUSTOM":

Â  Â  col1_custom_v2, col2_custom_v2, col3_custom_v2 = st.sidebar.columns([2, 2, 2])

Â  Â  with col1_custom_v2:

Â  Â  Â  Â  asset_custom_v2 = st.text_input("Asset",Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â value=st.session_state.get("asset_custom_val_v2", "XAUUSD"),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â key="asset_custom_input_v3")Â 

Â  Â  Â  Â  st.session_state.asset_custom_val_v2 = asset_custom_v2

Â  Â  with col2_custom_v2:

Â  Â  Â  Â  risk_pct_custom_v2 = st.number_input(Â 

Â  Â  Â  Â  Â  Â  "Risk %",

Â  Â  Â  Â  Â  Â  min_value=0.01, max_value=100.0,

Â  Â  Â  Â  Â  Â  value=st.session_state.get("risk_pct_custom_val_v2", initial_risk_pct_from_portfolio),

Â  Â  Â  Â  Â  Â  step=0.01, format="%.2f",

Â  Â  Â  Â  Â  Â  key="risk_pct_custom_input_v3")Â 

Â  Â  Â  Â  st.session_state.risk_pct_custom_val_v2 = risk_pct_custom_v2

Â  Â  with col3_custom_v2:

Â  Â  Â  Â  n_entry_custom_v2 = st.number_input(Â 

Â  Â  Â  Â  Â  Â  "à¸ˆà¸³à¸™à¸§à¸™à¹„à¸¡à¹‰",

Â  Â  Â  Â  Â  Â  min_value=1, max_value=10,

Â  Â  Â  Â  Â  Â  value=st.session_state.get("n_entry_custom_val_v2", 2),Â 

Â  Â  Â  Â  Â  Â  step=1,

Â  Â  Â  Â  Â  Â  key="n_entry_custom_input_v3")Â 

Â  Â  Â  Â  st.session_state.n_entry_custom_val_v2 = int(n_entry_custom_v2)



Â  Â  st.sidebar.markdown("**à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸•à¹ˆà¸¥à¸°à¹„à¸¡à¹‰**")

Â  Â  custom_inputs_v2 = []Â 

Â  Â Â 

Â  Â  current_custom_risk_pct_v2 = risk_pct_custom_v2Â 

Â  Â  risk_per_trade_custom_v2 = current_custom_risk_pct_v2 / 100.0Â 

Â  Â Â 

Â  Â  risk_dollar_total_custom_v2 = active_balance_to_use * risk_per_trade_custom_v2Â 

Â  Â Â 

Â  Â  num_entries_val_custom_v2 = st.session_state.n_entry_custom_val_v2

Â  Â  risk_dollar_per_entry_custom_v2 = risk_dollar_total_custom_v2 / num_entries_val_custom_v2 if num_entries_val_custom_v2 > 0 else 0



Â  Â  for i in range(num_entries_val_custom_v2):

Â  Â  Â  Â  st.sidebar.markdown(f"--- à¹„à¸¡à¹‰à¸—à¸µà¹ˆ {i+1} ---")

Â  Â  Â  Â  col_e_v2, col_s_v2, col_t_v2 = st.sidebar.columns(3)

Â  Â  Â  Â  entry_key_v2 = f"custom_entry_{i}_v3"Â 

Â  Â  Â  Â  sl_key_v2 = f"custom_sl_{i}_v3"Â  Â  Â  Â 

Â  Â  Â  Â  tp_key_v2 = f"custom_tp_{i}_v3"Â  Â  Â  Â 



Â  Â  Â  Â  if entry_key_v2 not in st.session_state: st.session_state[entry_key_v2] = "0.00"

Â  Â  Â  Â  if sl_key_v2 not in st.session_state: st.session_state[sl_key_v2] = "0.00"

Â  Â  Â  Â  if tp_key_v2 not in st.session_state: st.session_state[tp_key_v2] = "0.00"



Â  Â  Â  Â  with col_e_v2:

Â  Â  Â  Â  Â  Â  entry_str_v2 = st.text_input(f"Entry {i+1}", value=st.session_state[entry_key_v2], key=entry_key_v2)

Â  Â  Â  Â  with col_s_v2:

Â  Â  Â  Â  Â  Â  sl_str_v2 = st.text_input(f"SL {i+1}", value=st.session_state[sl_key_v2], key=sl_key_v2)

Â  Â  Â  Â  with col_t_v2:

Â  Â  Â  Â  Â  Â  tp_str_v2 = st.text_input(f"TP {i+1}", value=st.session_state[tp_key_v2], key=tp_key_v2)

Â  Â  Â  Â Â 

Â  Â  Â  Â  lot_display_str_v2 = "Lot: - (Error)"

Â  Â  Â  Â  risk_per_entry_display_str_v2 = f"Risk$ à¸•à¹ˆà¸­à¹„à¸¡à¹‰: {risk_dollar_per_entry_custom_v2:.2f}"

Â  Â  Â  Â  tp_rr3_info_str_v2 = "Stop: - (Error)"

Â  Â  Â  Â  stop_val_v2 = None



Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  entry_float_v2 = float(entry_str_v2)

Â  Â  Â  Â  Â  Â  sl_float_v2 = float(sl_str_v2)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if sl_float_v2 == entry_float_v2:

Â  Â  Â  Â  Â  Â  Â  Â  stop_val_v2 = 0

Â  Â  Â  Â  Â  Â  Â  Â  lot_display_str_v2 = "Lot: - (SL=Entry)"

Â  Â  Â  Â  Â  Â  Â  Â  tp_rr3_info_str_v2 = "Stop: 0 (SL=Entry)"

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  stop_val_v2 = abs(entry_float_v2 - sl_float_v2)

Â  Â  Â  Â  Â  Â  Â  Â  if stop_val_v2 > 1e-9:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lot_val_v2 = risk_dollar_per_entry_custom_v2 / stop_val_v2

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lot_display_str_v2 = f"Lot: {lot_val_v2:.2f}"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp_rr3_info_str_v2 = f"Stop: {stop_val_v2:.5f}"

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lot_display_str_v2 = "Lot: - (Stop=0)"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp_rr3_info_str_v2 = "Stop: 0"



Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  except Exception:

Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â Â 

Â  Â  Â  Â  st.sidebar.caption(f"{lot_display_str_v2} | {risk_per_entry_display_str_v2} | {tp_rr3_info_str_v2}")

Â  Â  Â  Â  custom_inputs_v2.append({"entry": entry_str_v2, "sl": sl_str_v2, "tp": tp_str_v2})



Â  Â  if current_custom_risk_pct_v2 <= 0:

Â  Â  Â  Â  st.sidebar.warning("Risk% à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 0")

Â  Â  save_custom = st.sidebar.button("ğŸ’¾ Save Plan (CUSTOM)", key="save_custom_v3")



# ===================== SEC 2.3: SIDEBAR - CALCULATIONS, SUMMARY & ACTIONS =======================

st.sidebar.markdown("---")

st.sidebar.markdown("### ğŸ§¾ Strategy Summary")



summary_total_lots = 0.0

summary_total_risk_dollar = 0.0

summary_avg_rr = 0.0

summary_total_profit_at_primary_tp = 0.0

custom_tp_recommendation_messages = []Â 



RATIO_TP1_EFF = 1.618

RATIO_TP2_EFF = 2.618

RATIO_TP3_EFF = 4.236



entry_data_summary_sec3 = []

custom_entries_summary_sec3 = []



if mode == "FIBO":

Â  Â  try:

Â  Â  Â  Â  h_input_str_fibo = st.session_state.get("swing_high_fibo_val_v2", "")

Â  Â  Â  Â  l_input_str_fibo = st.session_state.get("swing_low_fibo_val_v2", "")

Â  Â  Â  Â  direction_fibo = st.session_state.get("direction_fibo_val_v2", "Long")

Â  Â  Â  Â  risk_pct_fibo = st.session_state.get("risk_pct_fibo_val_v2", 1.0)



Â  Â  Â  Â  if 'fibos_fibo_v2' not in locals() and 'fibos_fibo_v2' not in globals():

Â  Â  Â  Â  Â  Â  Â fibos_fibo_v2 = [0.114, 0.25, 0.382, 0.5, 0.618]

Â  Â  Â  Â  current_fibo_flags_fibo = st.session_state.get("fibo_flags_v2", [True] * len(fibos_fibo_v2))



Â  Â  Â  Â  if not h_input_str_fibo or not l_input_str_fibo:

Â  Â  Â  Â  Â  Â  st.sidebar.info("à¸à¸£à¸­à¸ High à¹à¸¥à¸° Low (FIBO) à¹€à¸à¸·à¹ˆà¸­à¸„à¸³à¸™à¸§à¸“ Summary")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  high_fibo_input = float(h_input_str_fibo)

Â  Â  Â  Â  Â  Â  low_fibo_input = float(l_input_str_fibo)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  valid_hl_fibo = False

Â  Â  Â  Â  Â  Â  fibo_0_percent_level_calc = 0.0Â 



Â  Â  Â  Â  Â  Â  if direction_fibo == "Long":

Â  Â  Â  Â  Â  Â  Â  Â  if high_fibo_input > low_fibo_input:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fibo_0_percent_level_calc = low_fibo_input

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  valid_hl_fibo = True

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.warning("Long: Swing High à¸—à¸µà¹ˆà¸à¸£à¸­à¸ à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² Swing Low à¸—à¸µà¹ˆà¸à¸£à¸­à¸!")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  if high_fibo_input > low_fibo_input:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fibo_0_percent_level_calc = high_fibo_input

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  valid_hl_fibo = True

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.warning("Short: Swing High à¸—à¸µà¹ˆà¸à¸£à¸­à¸ à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² Swing Low à¸—à¸µà¹ˆà¸à¸£à¸­à¸!")



Â  Â  Â  Â  Â  Â  if not valid_hl_fibo:

Â  Â  Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  Â  Â  elif risk_pct_fibo <= 0:

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.warning("Risk % (FIBO) à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 0")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  range_fibo_calc = abs(high_fibo_input - low_fibo_input)



Â  Â  Â  Â  Â  Â  Â  Â  if range_fibo_calc <= 1e-9:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.warning("Range à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ High à¹à¸¥à¸° Low à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 0 à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸µà¸™à¸±à¸¢à¸ªà¸³à¸„à¸±à¸")

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  global_tp1_fibo, global_tp2_fibo, global_tp3_fibo = 0.0, 0.0, 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if direction_fibo == "Long":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  global_tp1_fibo = low_fibo_input + (range_fibo_calc * RATIO_TP1_EFF)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  global_tp1_fibo = high_fibo_input - (range_fibo_calc * RATIO_TP1_EFF)



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  selected_fibo_levels_count = sum(current_fibo_flags_fibo)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if selected_fibo_levels_count > 0:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  risk_dollar_total_fibo_plan = active_balance_to_use * (risk_pct_fibo / 100.0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  risk_dollar_per_entry_fibo = risk_dollar_total_fibo_plan / selected_fibo_levels_count

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_fibo_rr_to_tp1_list = []

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_fibo_entry_details_for_saving = []Â 



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for i, is_selected_fibo in enumerate(current_fibo_flags_fibo):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if is_selected_fibo:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fibo_ratio_for_entry = fibos_fibo_v2[i]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_price_fibo, sl_price_fibo_final = 0.0, 0.0



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if direction_fibo == "Long":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_price_fibo = fibo_0_percent_level_calc + (range_fibo_calc * fibo_ratio_for_entry)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sl_price_fibo_final = fibo_0_percent_level_calcÂ 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_price_fibo = fibo_0_percent_level_calc - (range_fibo_calc * fibo_ratio_for_entry)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sl_price_fibo_final = fibo_0_percent_level_calc

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stop_distance_fibo = abs(entry_price_fibo - sl_price_fibo_final)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lot_size_fibo, actual_risk_dollar_fibo = 0.0, 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if stop_distance_fibo > 1e-9:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lot_size_fibo = risk_dollar_per_entry_fibo / stop_distance_fibo

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  actual_risk_dollar_fibo = lot_size_fibo * stop_distance_fibo

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  actual_risk_dollar_fibo = risk_dollar_per_entry_fibo

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lot_size_fibo = 0



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  profit_at_tp1_fibo, rr_to_tp1_fibo = 0.0, 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if stop_distance_fibo > 1e-9:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  price_diff_to_tp1 = abs(global_tp1_fibo - entry_price_fibo)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (direction_fibo == "Long" and global_tp1_fibo > entry_price_fibo) or \

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â (direction_fibo == "Short" and global_tp1_fibo < entry_price_fibo):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  profit_at_tp1_fibo = lot_size_fibo * price_diff_to_tp1

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rr_to_tp1_fibo = price_diff_to_tp1 / stop_distance_fibo

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_fibo_rr_to_tp1_list.append(rr_to_tp1_fibo)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_total_lots += lot_size_fibo

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_total_risk_dollar += actual_risk_dollar_fiboÂ 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_total_profit_at_primary_tp += profit_at_tp1_fibo



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_fibo_entry_details_for_saving.append({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Fibo Level": f"{fibo_ratio_for_entry:.3f}",

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Entry": round(entry_price_fibo, 5),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "SL": round(sl_price_fibo_final, 5),Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lot": round(lot_size_fibo, 2),Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Risk $": round(actual_risk_dollar_fibo, 2),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "TP": round(global_tp1_fibo, 5),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "RR": round(rr_to_tp1_fibo, 2) if rr_to_tp1_fibo is not None else "N/A"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_data_summary_sec3 = temp_fibo_entry_details_for_savingÂ 



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if temp_fibo_rr_to_tp1_list:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  valid_rrs = [r for r in temp_fibo_rr_to_tp1_list if isinstance(r, (float, int)) and pd.notna(r) and r > 0]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_avg_rr = np.mean(valid_rrs) if valid_rrs else 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_avg_rr = 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.info("à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸ Fibo Level à¸ªà¸³à¸«à¸£à¸±à¸š Entry")

Â  Â  Â  Â  Â  Â Â 

Â  Â  except ValueError:

Â  Â  Â  Â  if st.session_state.get("swing_high_fibo_val_v2", "") or st.session_state.get("swing_low_fibo_val_v2", ""):

Â  Â  Â  Â  Â  Â  Â st.sidebar.warning("à¸à¸£à¸­à¸ High/Low (FIBO) à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚")

Â  Â  except Exception as e_fibo_summary:

Â  Â  Â  Â  st.sidebar.error(f"à¸„à¸³à¸™à¸§à¸“ FIBO Summary à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {e_fibo_summary}")



elif mode == "CUSTOM":

Â  Â  try:

Â  Â  Â  Â  n_entry_custom = st.session_state.get("n_entry_custom_val_v2", 1)

Â  Â  Â  Â  risk_pct_custom = st.session_state.get("risk_pct_custom_val_v2", 1.0)



Â  Â  Â  Â  if risk_pct_custom <= 0:

Â  Â  Â  Â  Â  Â  st.sidebar.warning("Risk % (CUSTOM) à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 0")

Â  Â  Â  Â  elif n_entry_custom <=0:

Â  Â  Â  Â  Â  Â  st.sidebar.warning("à¸ˆà¸³à¸™à¸§à¸™à¹„à¸¡à¹‰ (CUSTOM) à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 0")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  risk_per_trade_custom_total = active_balance_to_use * (risk_pct_custom / 100.0)

Â  Â  Â  Â  Â  Â  risk_dollar_per_entry_custom = risk_per_trade_custom_total / n_entry_custom

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  temp_custom_rr_list = []

Â  Â  Â  Â  Â  Â  temp_custom_legs_for_saving = []Â 

Â  Â  Â  Â  Â  Â  current_total_actual_risk_custom = 0.0

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  for i in range(int(n_entry_custom)):

Â  Â  Â  Â  Â  Â  Â  Â  entry_str = st.session_state.get(f"custom_entry_{i}_v3", "0.00")

Â  Â  Â  Â  Â  Â  Â  Â  sl_str = st.session_state.get(f"custom_sl_{i}_v3", "0.00")

Â  Â  Â  Â  Â  Â  Â  Â  tp_str = st.session_state.get(f"custom_tp_{i}_v3", "0.00")



Â  Â  Â  Â  Â  Â  Â  Â  entry_val, sl_val, tp_val = 0.0, 0.0, 0.0

Â  Â  Â  Â  Â  Â  Â  Â  lot_custom, actual_risk_dollar_custom, rr_custom, profit_at_user_tp_custom = 0.0, 0.0, 0.0, 0.0

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_val = float(entry_str)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sl_val = float(sl_str)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp_val = float(tp_str)



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if sl_val == entry_val:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stop_custom = 0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stop_custom = abs(entry_val - sl_val)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_custom = abs(tp_val - entry_val)



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if stop_custom > 1e-9:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lot_custom = risk_dollar_per_entry_custom / stop_customÂ 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  actual_risk_dollar_custom = lot_custom * stop_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if target_custom > 1e-9 and tp_val != entry_val :

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rr_custom = target_custom / stop_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  profit_at_user_tp_custom = lot_custom * target_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_custom_rr_list.append(rr_custom)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if 0 <= rr_custom < 3.0 :

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recommended_tp_target_distance = 3 * stop_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recommended_tp_price = 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if sl_val < entry_val:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recommended_tp_price = entry_val + recommended_tp_target_distance

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif sl_val > entry_val:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recommended_tp_price = entry_val - recommended_tp_target_distance

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if recommended_tp_price != 0.0:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  custom_tp_recommendation_messages.append(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"à¹„à¸¡à¹‰ {i+1}: à¸«à¸²à¸à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ RRâ‰ˆ3, TP à¸„à¸§à¸£à¹€à¸›à¹‡à¸™ â‰ˆ {recommended_tp_price:.5f} (TP à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™ RR={rr_custom:.2f})"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â actual_risk_dollar_custom = risk_dollar_per_entry_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_total_lots += lot_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_total_actual_risk_custom += actual_risk_dollar_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  summary_total_profit_at_primary_tp += profit_at_user_tp_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_custom_legs_for_saving.append({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Entry": round(entry_val, 5),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "SL": round(sl_val, 5),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "TP": round(tp_val, 5),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lot": round(lot_custom, 2),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Risk $": round(actual_risk_dollar_custom, 2),Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "RR": round(rr_custom, 2) if rr_custom is not None else "N/A"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })



Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_total_actual_risk_custom += risk_dollar_per_entry_custom

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_custom_legs_for_saving.append({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Entry": entry_str, "SL": sl_str, "TP": tp_str,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lot": "Error", "Risk $": f"{risk_dollar_per_entry_custom:.2f}", "RR": "Error"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  custom_entries_summary_sec3 = temp_custom_legs_for_savingÂ 

Â  Â  Â  Â  Â  Â  summary_total_risk_dollar = current_total_actual_risk_customÂ 



Â  Â  Â  Â  Â  Â  if temp_custom_rr_list:

Â  Â  Â  Â  Â  Â  Â  Â  valid_rrs = [r for r in temp_custom_rr_list if isinstance(r, (float, int)) and pd.notna(r) and r > 0]

Â  Â  Â  Â  Â  Â  Â  Â  summary_avg_rr = np.mean(valid_rrs) if valid_rrs else 0.0

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  summary_avg_rr = 0.0

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  except ValueError:

Â  Â  Â  Â  st.sidebar.warning("à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ CUSTOM à¹„à¸¡à¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ˆà¸³à¸™à¸§à¸™à¹„à¸¡à¹‰)")

Â  Â  except Exception as e_custom_summary:

Â  Â  Â  Â  st.sidebar.error(f"à¸„à¸³à¸™à¸§à¸“ CUSTOM Summary à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {e_custom_summary}")



display_summary_info = False

if mode == "FIBO" and entry_data_summary_sec3 and (st.session_state.get("swing_high_fibo_val_v2", "") and st.session_state.get("swing_low_fibo_val_v2", "")):

Â  Â  display_summary_info = True

elif mode == "CUSTOM" and custom_entries_summary_sec3 and st.session_state.get("n_entry_custom_val_v2", 0) > 0 :

Â  Â  display_summary_info = True

elif mode == "CUSTOM" and custom_tp_recommendation_messages:

Â  Â  display_summary_info = True





if display_summary_info:

Â  Â  current_risk_display = 0.0

Â  Â  active_balance_display = active_balance_to_use



Â  Â  if mode == "FIBO": current_risk_display = st.session_state.get('risk_pct_fibo_val_v2', 0.0)

Â  Â  elif mode == "CUSTOM": current_risk_display = st.session_state.get('risk_pct_custom_val_v2', 0.0)



Â  Â  st.sidebar.write(f"**Total Lots ({mode}):** {summary_total_lots:.2f}")

Â  Â  st.sidebar.write(f"**Total Risk $ ({mode}):** {summary_total_risk_dollar:.2f} (Balance: {active_balance_display:,.2f}, Risk: {current_risk_display:.2f}%)")

Â  Â Â 

Â  Â  if summary_avg_rr > 0:Â 

Â  Â  Â  Â  tp_ref_text = "(to Global TP1)" if mode == "FIBO" else "(to User TP)"

Â  Â  Â  Â  st.sidebar.write(f"**Average RR ({mode}) {tp_ref_text}:** {summary_avg_rr:.2f}")

Â  Â  else:

Â  Â  Â  Â  st.sidebar.write(f"**Average RR ({mode}):** N/A")



Â  Â  profit_ref_text = "(at Global TP1)" if mode == "FIBO" else "(at User TP)"

Â  Â  st.sidebar.write(f"**Total Expected Profit {profit_ref_text} ({mode}):** {summary_total_profit_at_primary_tp:,.2f} USD")

Â  Â Â 

Â  Â  if mode == "CUSTOM" and custom_tp_recommendation_messages:

Â  Â  Â  Â  st.sidebar.markdown("**à¸„à¸³à¹à¸™à¸°à¸™à¸³ TP (à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ RR â‰ˆ 3):**")

Â  Â  Â  Â  for msg in custom_tp_recommendation_messages:

Â  Â  Â  Â  Â  Â  st.sidebar.caption(msg)

else:

Â  Â  show_fallback_info = True

Â  Â  if mode == "FIBO" and (not st.session_state.get("swing_high_fibo_val_v2", "") or not st.session_state.get("swing_low_fibo_val_v2", "")):

Â  Â  Â  Â  show_fallback_info = FalseÂ 

Â  Â  elif mode == "CUSTOM" and not (st.session_state.get("n_entry_custom_val_v2", 0) > 0 and st.session_state.get("risk_pct_custom_val_v2", 0.0) > 0):

Â  Â  Â  Â  show_fallback_info = False

Â  Â Â 

Â  Â  if show_fallback_info:

Â  Â  Â  Â  fibo_inputs_present = mode == "FIBO" and st.session_state.get("swing_high_fibo_val_v2", "") and st.session_state.get("swing_low_fibo_val_v2", "")

Â  Â  Â  Â  fibo_no_levels_selected = fibo_inputs_present and not any(st.session_state.get("fibo_flags_v2", []))

Â  Â  Â  Â Â 

Â  Â  Â  Â  custom_inputs_present = mode == "CUSTOM" and st.session_state.get("n_entry_custom_val_v2",0) > 0 and st.session_state.get("risk_pct_custom_val_v2",0.0) > 0

Â  Â  Â  Â Â 

Â  Â  Â  Â  if (fibo_inputs_present and not entry_data_summary_sec3) or \

Â  Â  Â  Â  Â  Â (custom_inputs_present and not custom_entries_summary_sec3 and not custom_tp_recommendation_messages):

Â  Â  Â  Â  Â  Â  st.sidebar.info("à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹à¸¥à¸°à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ à¸«à¸£à¸·à¸­à¹€à¸¥à¸·à¸­à¸à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚ (à¹€à¸Šà¹ˆà¸™ Fibo Levels) à¹€à¸à¸·à¹ˆà¸­à¸„à¸³à¸™à¸§à¸“ Summary")



# --- End of modified SEC 2.3 (formerly SEC 3) ---



# ===================== SEC 2.4: SCALING MANAGER =======================

with st.sidebar.expander("âš™ï¸ Scaling Manager Settings", expanded=False):

Â  Â  scaling_step_default = 0.25

Â  Â  min_risk_pct_default = 0.5

Â  Â  max_risk_pct_default = 5.0

Â  Â  scaling_mode_default = 'Manual'

Â  Â Â 

Â  Â  scaling_step = st.number_input(

Â  Â  Â  Â  "Scaling Step (%)", min_value=0.01, max_value=1.0,

Â  Â  Â  Â  value=st.session_state.get('scaling_step', scaling_step_default),Â 

Â  Â  Â  Â  step=0.01, format="%.2f", key='scaling_step'

Â  Â  )

Â  Â  min_risk_pct = st.number_input(

Â  Â  Â  Â  "Minimum Risk %", min_value=0.01, max_value=100.0,Â 

Â  Â  Â  Â  value=st.session_state.get('min_risk_pct', min_risk_pct_default),Â 

Â  Â  Â  Â  step=0.01, format="%.2f", key='min_risk_pct'

Â  Â  )

Â  Â  max_risk_pct = st.number_input(

Â  Â  Â  Â  "Maximum Risk %", min_value=0.01, max_value=100.0,Â 

Â  Â  Â  Â  value=st.session_state.get('max_risk_pct', max_risk_pct_default),Â 

Â  Â  Â  Â  step=0.01, format="%.2f", key='max_risk_pct'

Â  Â  )

Â  Â  scaling_mode = st.radio(

Â  Â  Â  Â  "Scaling Mode", ["Manual", "Auto"],Â 

Â  Â  Â  Â  index=0 if st.session_state.get('scaling_mode', scaling_mode_default) == 'Manual' else 1,

Â  Â  Â  Â  horizontal=True, key='scaling_mode'

Â  Â  )



# ===================== SEC 2.4.1: SCALING SUGGESTION LOGIC =======================

df_planned_logs_for_scaling_all = load_all_planned_trade_logs_from_gsheets()Â 



active_portfolio_id_for_scaling = st.session_state.get('active_portfolio_id_gs', None)

df_planned_logs_for_scaling_filtered = pd.DataFrame()



if active_portfolio_id_for_scaling and not df_planned_logs_for_scaling_all.empty:

Â  Â  if 'PortfolioID' in df_planned_logs_for_scaling_all.columns:

Â  Â  Â  Â  df_planned_logs_for_scaling_filtered = df_planned_logs_for_scaling_all[

Â  Â  Â  Â  Â  Â  df_planned_logs_for_scaling_all['PortfolioID'] == str(active_portfolio_id_for_scaling)

Â  Â  Â  Â  ].copy()

Â  Â  else:

Â  Â  Â  Â  df_planned_logs_for_scaling_filtered = df_planned_logs_for_scaling_all.copy()

elif not df_planned_logs_for_scaling_all.empty:

Â  Â  df_planned_logs_for_scaling_filtered = df_planned_logs_for_scaling_all.copy()



winrate_perf, gain_perf, total_trades_perf = get_performance(df_planned_logs_for_scaling_filtered.copy(), mode="week")



current_risk_for_scaling = initial_risk_pct_from_portfolio

if mode == "FIBO":

Â  Â  current_risk_for_scaling = st.session_state.get("risk_pct_fibo_val_v2", initial_risk_pct_from_portfolio)

elif mode == "CUSTOM":

Â  Â  current_risk_for_scaling = st.session_state.get("risk_pct_custom_val_v2", initial_risk_pct_from_portfolio)



scaling_step_val = st.session_state.get('scaling_step', 0.25)Â 

max_risk_pct_val = st.session_state.get('max_risk_pct', 5.0)Â  Â 

min_risk_pct_val = st.session_state.get('min_risk_pct', 0.5)Â  Â 

current_scaling_mode = st.session_state.get('scaling_mode', 'Manual')Â 



suggest_risk = current_risk_for_scalingÂ 

scaling_msg = f"Risk% à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™: {current_risk_for_scaling:.2f}%. "



if total_trades_perf > 0:

Â  Â  gain_threshold = 0.02 * active_balance_to_useÂ 

Â  Â  if winrate_perf > 55 and gain_perf > gain_threshold:

Â  Â  Â  Â  suggest_risk = min(current_risk_for_scaling + scaling_step_val, max_risk_pct_val)

Â  Â  Â  Â  scaling_msg += f"ğŸ‰ à¸œà¸¥à¸‡à¸²à¸™à¸”à¸µ! Winrate {winrate_perf:.1f}%, à¸à¸³à¹„à¸£ {gain_perf:,.2f} (à¹€à¸›à¹‰à¸² {gain_threshold:,.2f}). à¹à¸™à¸°à¸™à¸³à¹€à¸à¸´à¹ˆà¸¡ Risk% à¹€à¸›à¹‡à¸™ {suggest_risk:.2f}%"

Â  Â  elif winrate_perf < 45 or gain_perf < 0:

Â  Â  Â  Â  suggest_risk = max(current_risk_for_scaling - scaling_step_val, min_risk_pct_val)

Â  Â  Â  Â  scaling_msg += f"âš ï¸ à¸„à¸§à¸£à¸¥à¸” Risk! Winrate {winrate_perf:.1f}%, à¸à¸³à¹„à¸£ {gain_perf:,.2f}. à¹à¸™à¸°à¸™à¸³à¸¥à¸” Risk% à¹€à¸›à¹‡à¸™ {suggest_risk:.2f}%"

Â  Â  else:

Â  Â  Â  Â  scaling_msg += f"à¸„à¸‡ Risk% (Winrate {winrate_perf:.1f}%, à¸à¸³à¹„à¸£ {gain_perf:,.2f})"

else:

Â  Â  scaling_msg += "à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Performance à¹€à¸à¸µà¸¢à¸‡à¸à¸­à¹ƒà¸™à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸™à¸µà¹‰ à¸«à¸£à¸·à¸­ Performance à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¹€à¸à¸“à¸‘à¹Œ"



st.sidebar.info(scaling_msg)



if abs(suggest_risk - current_risk_for_scaling) > 1e-3:Â 

Â  Â  if current_scaling_mode == "Manual":

Â  Â  Â  Â  if st.sidebar.button(f"à¸›à¸£à¸±à¸š Risk% à¸•à¸²à¸¡à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹€à¸›à¹‡à¸™ {suggest_risk:.2f}%"):

Â  Â  Â  Â  Â  Â  if mode == "FIBO":

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.risk_pct_fibo_val_v2 = suggest_riskÂ 

Â  Â  Â  Â  Â  Â  elif mode == "CUSTOM":

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.risk_pct_custom_val_v2 = suggest_riskÂ 

Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  elif current_scaling_mode == "Auto":

Â  Â  Â  Â  risk_changed_by_auto = False

Â  Â  Â  Â  if mode == "FIBO" and abs(st.session_state.get("risk_pct_fibo_val_v2", initial_risk_pct_from_portfolio) - suggest_risk) > 1e-3:

Â  Â  Â  Â  Â  Â  st.session_state.risk_pct_fibo_val_v2 = suggest_riskÂ 

Â  Â  Â  Â  Â  Â  risk_changed_by_auto = True

Â  Â  Â  Â  elif mode == "CUSTOM" and abs(st.session_state.get("risk_pct_custom_val_v2", initial_risk_pct_from_portfolio) - suggest_risk) > 1e-3:

Â  Â  Â  Â  Â  Â  st.session_state.risk_pct_custom_val_v2 = suggest_risk

Â  Â  Â  Â  Â  Â  risk_changed_by_auto = True

Â  Â  Â  Â Â 

Â  Â  Â  Â  if risk_changed_by_auto:

Â  Â  Â  Â  Â  Â  if st.session_state.get(f"last_auto_suggested_risk_{mode}", current_risk_for_scaling) != suggest_risk:Â 

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state[f"last_auto_suggested_risk_{mode}"] = suggest_risk

Â  Â  Â  Â  Â  Â  Â  Â  st.toast(f"Auto Scaling: à¸›à¸£à¸±à¸š Risk% à¸‚à¸­à¸‡à¹‚à¸«à¸¡à¸” {mode} à¹€à¸›à¹‡à¸™ {suggest_risk:.2f}%", icon="âš™ï¸")

Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()



# ===================== SEC 2.5: SAVE PLAN ACTION & DRAWDOWN LOCK =======================

df_drawdown_check_all = load_all_planned_trade_logs_from_gsheets()Â 



active_portfolio_id_for_drawdown = st.session_state.get('active_portfolio_id_gs', None)

df_drawdown_check_filtered = pd.DataFrame()



if active_portfolio_id_for_drawdown and not df_drawdown_check_all.empty:

Â  Â  if 'PortfolioID' in df_drawdown_check_all.columns:

Â  Â  Â  Â  df_drawdown_check_filtered = df_drawdown_check_all[

Â  Â  Â  Â  Â  Â  df_drawdown_check_all['PortfolioID'] == str(active_portfolio_id_for_drawdown)

Â  Â  Â  Â  ].copy()

Â  Â  else:

Â  Â  Â  Â  df_drawdown_check_filtered = df_drawdown_check_all.copy()

elif not df_drawdown_check_all.empty:

Â  Â  df_drawdown_check_filtered = df_drawdown_check_all.copy()



drawdown_today = get_today_drawdown(df_drawdown_check_filtered.copy(), active_balance_to_use)Â 

drawdown_limit_pct_val = st.session_state.get('drawdown_limit_pct', 2.0)

drawdown_limit_abs = -abs(active_balance_to_use * (drawdown_limit_pct_val / 100.0))Â 



if drawdown_today < 0:

Â  Â  st.sidebar.markdown(f"**à¸‚à¸²à¸”à¸—à¸¸à¸™à¸ˆà¸²à¸à¹à¸œà¸™à¸§à¸±à¸™à¸™à¸µà¹‰:** <font color='red'>{drawdown_today:,.2f} USD</font>", unsafe_allow_html=True)

Â  Â  st.sidebar.markdown(f"**à¸¥à¸´à¸¡à¸´à¸•à¸‚à¸²à¸”à¸—à¸¸à¸™à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡à¹„à¸§à¹‰:** {drawdown_limit_abs:,.2f} USD ({drawdown_limit_pct_val:.1f}% à¸‚à¸­à¸‡ {active_balance_to_use:,.2f} USD)")

else:

Â  Â  st.sidebar.markdown(f"**à¸‚à¸²à¸”à¸—à¸¸à¸™à¸ˆà¸²à¸à¹à¸œà¸™à¸§à¸±à¸™à¸™à¸µà¹‰:** {drawdown_today:,.2f} USD")



active_portfolio_id = st.session_state.get('active_portfolio_id_gs', None)

active_portfolio_name = st.session_state.get('active_portfolio_name_gs', None)



asset_to_save = ""

risk_pct_to_save = 0.0

direction_to_save = "N/A"

current_data_to_save = []



save_button_pressed_flag = False



if mode == "FIBO" and 'save_fibo' in st.session_state and st.session_state.save_fibo:

Â  Â  save_button_pressed_flag = True

elif mode == "CUSTOM" and 'save_custom' in st.session_state and st.session_state.save_custom:

Â  Â  save_button_pressed_flag = True



if mode == "FIBO":

Â  Â  asset_to_save = st.session_state.get("asset_fibo_val_v2", "XAUUSD")

Â  Â  risk_pct_to_save = st.session_state.get("risk_pct_fibo_val_v2", 1.0)

Â  Â  direction_to_save = st.session_state.get("direction_fibo_val_v2", "Long")

Â  Â  current_data_to_save = entry_data_summary_sec3

elif mode == "CUSTOM":

Â  Â  asset_to_save = st.session_state.get("asset_custom_val_v2", "XAUUSD")

Â  Â  risk_pct_to_save = st.session_state.get("risk_pct_custom_val_v2", 1.0)

Â  Â Â 

Â  Â  if custom_entries_summary_sec3:Â 

Â  Â  Â  Â  long_count = 0

Â  Â  Â  Â  short_count = 0

Â  Â  Â  Â  valid_trade_count = 0

Â  Â  Â  Â  for item in custom_entries_summary_sec3:

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  entry_price_str = item.get("Entry")

Â  Â  Â  Â  Â  Â  Â  Â  sl_price_str = item.get("SL")

Â  Â  Â  Â  Â  Â  Â  Â  if entry_price_str is None or sl_price_str is None or \

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â str(entry_price_str).lower() == "error" or str(sl_price_str).lower() == "error":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue



Â  Â  Â  Â  Â  Â  Â  Â  entry_price = float(entry_price_str)

Â  Â  Â  Â  Â  Â  Â  Â  sl_price = float(sl_price_str)

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if pd.notna(entry_price) and pd.notna(sl_price) and entry_price != sl_price:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  valid_trade_count += 1

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if entry_price > sl_price:Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  long_count += 1

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif entry_price < sl_price:Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  short_count += 1

Â  Â  Â  Â  Â  Â  except (ValueError, TypeError):

Â  Â  Â  Â  Â  Â  Â  Â  passÂ 



Â  Â  Â  Â  if valid_trade_count > 0:

Â  Â  Â  Â  Â  Â  if long_count == valid_trade_count and short_count == 0:

Â  Â  Â  Â  Â  Â  Â  Â  direction_to_save = "Long"

Â  Â  Â  Â  Â  Â  elif short_count == valid_trade_count and long_count == 0:

Â  Â  Â  Â  Â  Â  Â  Â  direction_to_save = "Short"

Â  Â  Â  Â  Â  Â  elif long_count > 0 and short_count > 0:Â 

Â  Â  Â  Â  Â  Â  Â  Â  direction_to_save = "Mixed"

Â  Â  Â  Â  Â  Â  elif long_count > 0:Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â direction_to_save = "Long"

Â  Â  Â  Â  Â  Â  elif short_count > 0:Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â direction_to_save = "Short"

Â  Â  current_data_to_save = custom_entries_summary_sec3



if save_button_pressed_flag:

Â  Â  if not current_data_to_save:

Â  Â  Â  Â  st.sidebar.warning(f"à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸œà¸™ ({mode}) à¸—à¸µà¹ˆà¸ˆà¸°à¸šà¸±à¸™à¸—à¸¶à¸ à¸à¸£à¸¸à¸“à¸²à¸„à¸³à¸™à¸§à¸“à¹à¸œà¸™à¹ƒà¸™ Summary à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸à¹ˆà¸­à¸™")

Â  Â  elif drawdown_today <= drawdown_limit_abs and drawdown_today != 0 :

Â  Â  Â  Â  st.sidebar.error(

Â  Â  Â  Â  Â  Â  f"à¸«à¸¢à¸¸à¸”à¹€à¸—à¸£à¸”! à¸‚à¸²à¸”à¸—à¸¸à¸™à¸ˆà¸²à¸à¹à¸œà¸™à¸£à¸§à¸¡à¸§à¸±à¸™à¸™à¸µà¹‰ {abs(drawdown_today):,.2f} à¸–à¸¶à¸‡/à¹€à¸à¸´à¸™à¸¥à¸´à¸¡à¸´à¸• {abs(drawdown_limit_abs):,.2f} ({drawdown_limit_pct_val:.1f}%)"

Â  Â  Â  Â  )

Â  Â  elif not active_portfolio_id:

Â  Â  Â  Â  st.sidebar.error("à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¸à¸­à¸£à¹Œà¸•à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Active Portfolio) à¹ƒà¸™ Sidebar à¸”à¹‰à¸²à¸™à¸šà¸™à¸à¹ˆà¸­à¸™à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸œà¸™")

Â  Â  else:

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  if save_plan_to_gsheets(current_data_to_save, mode, asset_to_save, risk_pct_to_save, direction_to_save, active_portfolio_id, active_portfolio_name):

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.success(f"à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸œà¸™ ({mode}) à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸• '{active_portfolio_name}' à¸¥à¸‡ Google Sheets à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

Â  Â  Â  Â  Â  Â  Â  Â  st.balloons()

Â  Â  Â  Â  Â  Â  Â  Â  if mode == "FIBO" and 'save_fibo' in st.session_state: st.session_state.save_fibo = False

Â  Â  Â  Â  Â  Â  Â  Â  if mode == "CUSTOM" and 'save_custom' in st.session_state: st.session_state.save_custom = False

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.error(f"Save ({mode}) à¹„à¸›à¸¢à¸±à¸‡ Google Sheets à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ (à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Headers à¸«à¸£à¸·à¸­à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­)")

Â  Â  Â  Â  except Exception as e_save_plan:

Â  Â  Â  Â  Â  Â  st.sidebar.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸£à¸¸à¸™à¹à¸£à¸‡à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸œà¸™ ({mode}): {e_save_plan}")



# --- End of SEC 2.5 (formerly SEC 3.2) ---



# ===================== SEC 3: MAIN AREA - ENTRY PLAN DETAILS TABLE =======================

with st.expander("ğŸ“‹ Entry Table (FIBO/CUSTOM)", expanded=True):

Â  Â  if mode == "FIBO":

Â  Â  Â  Â  col1_main, col2_main = st.columns(2)

Â  Â  Â  Â  with col1_main:

Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ¯ Entry Levels (FIBO)")

Â  Â  Â  Â  Â  Â  if 'entry_data_summary_sec3' in locals() and entry_data_summary_sec3:

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_df_main = pd.DataFrame(entry_data_summary_sec3)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  expected_cols_fibo = ["Fibo Level", "Entry", "SL", "Lot", "Risk $", "TP", "RR"]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cols_to_display_fibo = [col for col in expected_cols_fibo if col in entry_df_main.columns]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if cols_to_display_fibo:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(entry_df_main[cols_to_display_fibo], hide_index=True, use_container_width=True)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("à¹„à¸¡à¹ˆà¸à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸œà¸¥ Entry Levels (FIBO).")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e_df_fibo:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡ FIBO Entry Levels: {e_df_fibo}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Input à¹ƒà¸™ Sidebar")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  st.info("à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ High/Low à¹à¸¥à¸°à¹€à¸¥à¸·à¸­à¸ Fibo Level à¹ƒà¸™ Sidebar à¹€à¸à¸·à¹ˆà¸­à¸”à¸¹ Entry Levels (à¸«à¸£à¸·à¸­à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸£à¸¸à¸›).")

Â  Â  Â  Â Â 

Â  Â  Â  Â  with col2_main:

Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ¯ Take Profit Zones (FIBO)")

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  current_swing_high_tp_sec4 = st.session_state.get("swing_high_fibo_val_v2", "")

Â  Â  Â  Â  Â  Â  Â  Â  current_swing_low_tp_sec4 = st.session_state.get("swing_low_fibo_val_v2", "")

Â  Â  Â  Â  Â  Â  Â  Â  current_fibo_direction_tp_sec4 = st.session_state.get("direction_fibo_val_v2", "Long")



Â  Â  Â  Â  Â  Â  Â  Â  if not current_swing_high_tp_sec4 or not current_swing_low_tp_sec4:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("ğŸ“Œ à¸à¸£à¸­à¸ High/Low à¹ƒà¸™ Sidebar (FIBO) à¹ƒà¸«à¹‰à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹€à¸à¸·à¹ˆà¸­à¸„à¸³à¸™à¸§à¸“ TP.")

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  high_tp = float(current_swing_high_tp_sec4)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  low_tp = float(current_swing_low_tp_sec4)



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if high_tp > low_tp:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp1_main, tp2_main, tp3_main = 0.0, 0.0, 0.0

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if current_fibo_direction_tp_sec4 == "Long":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp1_main = low_tp + (high_tp - low_tp) * 1.618

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp2_main = low_tp + (high_tp - low_tp) * 2.618

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp3_main = low_tp + (high_tp - low_tp) * 4.236

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp1_main = high_tp - (high_tp - low_tp) * 1.618

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp2_main = high_tp - (high_tp - low_tp) * 2.618

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp3_main = high_tp - (high_tp - low_tp) * 4.236

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tp_df_main = pd.DataFrame({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "TP Zone": ["TP1 (1.618)", "TP2 (2.618)", "TP3 (4.236)"],

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Price": [f"{tp1_main:.5f}", f"{tp2_main:.5f}", f"{tp3_main:.5f}"]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(tp_df_main, hide_index=True, use_container_width=True)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ğŸ“Œ High à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸à¸à¸§à¹ˆà¸² Low à¹€à¸à¸·à¹ˆà¸­à¸„à¸³à¸™à¸§à¸“ TP.")

Â  Â  Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ğŸ“Œ à¸à¸£à¸­à¸ High/Low (FIBO) à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¹€à¸à¸·à¹ˆà¸­à¸„à¸³à¸™à¸§à¸“ TP.")

Â  Â  Â  Â  Â  Â  except Exception as e_tp_fibo:

Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"ğŸ“Œ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“ TP (FIBO): {e_tp_fibo}")



Â  Â  elif mode == "CUSTOM":

Â  Â  Â  Â  st.markdown("### ğŸ¯ Entry & Take Profit Zones (CUSTOM)")

Â  Â  Â  Â  if 'custom_entries_summary_sec3' in locals() and custom_entries_summary_sec3:

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  custom_df_main = pd.DataFrame(custom_entries_summary_sec3)

Â  Â  Â  Â  Â  Â  Â  Â  expected_cols_custom = ["Entry", "SL", "TP", "Lot", "Risk $", "RR"]

Â  Â  Â  Â  Â  Â  Â  Â  cols_to_display_custom = [col for col in expected_cols_custom if col in custom_df_main.columns]



Â  Â  Â  Â  Â  Â  Â  Â  if cols_to_display_custom:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.dataframe(custom_df_main[cols_to_display_custom], hide_index=True, use_container_width=True)

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.info("à¹„à¸¡à¹ˆà¸à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸„à¸²à¸”à¸«à¸§à¸±à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸ªà¸”à¸‡à¸œà¸¥ CUSTOM Trades.")

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  for i, row_data_dict in enumerate(custom_entries_summary_sec3):Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rr_val_str = str(row_data_dict.get("RR", "0")).lower()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if rr_val_str == "error" or rr_val_str == "n/a" or rr_val_str == "" or rr_val_str == "nan":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continueÂ 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rr_val = float(rr_val_str)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if 0 <= rr_val < 2:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_label = row_data_dict.get("à¹„à¸¡à¹‰à¸—à¸µà¹ˆ", i + 1)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"ğŸ¯ Entry {entry_label} à¸¡à¸µ RR à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸•à¹ˆà¸³ ({rr_val:.2f}) â€” à¸¥à¸­à¸‡à¸›à¸£à¸±à¸š TP/SL à¹€à¸à¸·à¹ˆà¸­ Risk:Reward à¸—à¸µà¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  passÂ 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception:Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  Â  Â  except Exception as e_df_custom:

Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸²à¸£à¸²à¸‡ CUSTOM Trades: {e_df_custom}")

Â  Â  Â  Â  Â  Â  Â  Â  st.info("à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Input à¹ƒà¸™ Sidebar")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  st.info("à¸à¸£à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Custom à¹ƒà¸™ Sidebar à¹€à¸à¸·à¹ˆà¸­à¸”à¸¹ Entry & TP Zones (à¸«à¸£à¸·à¸­à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸£à¸¸à¸›).")



# --- End of SEC 3 (formerly SEC 4) ---



# ===================== SEC 4: MAIN AREA - CHART VISUALIZER =======================

with st.expander("ğŸ“ˆ Chart Visualizer", expanded=False):

Â  Â  asset_to_display = "OANDA:XAUUSD"

Â  Â  current_asset_input_from_form = ""Â 



Â  Â  if mode == "FIBO":

Â  Â  Â  Â  current_asset_input_from_form = st.session_state.get("asset_fibo_val_v2", "XAUUSD")Â 

Â  Â  elif mode == "CUSTOM":

Â  Â  Â  Â  current_asset_input_from_form = st.session_state.get("asset_custom_val_v2", "XAUUSD")Â 

Â  Â Â 

Â  Â  if 'plot_data' in st.session_state and st.session_state['plot_data'] and st.session_state['plot_data'].get('Asset'):

Â  Â  Â  Â  asset_from_log = st.session_state['plot_data'].get('Asset')

Â  Â  Â  Â  st.info(f"à¸à¸³à¸¥à¸±à¸‡à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ TradingView à¸ªà¸³à¸«à¸£à¸±à¸š: {str(asset_from_log).upper()} (à¸ˆà¸²à¸ Log Viewer)")

Â  Â  Â  Â  asset_str_upper = str(asset_from_log).upper()

Â  Â  Â  Â  if asset_str_upper == "XAUUSD":

Â  Â  Â  Â  Â  Â  asset_to_display = "OANDA:XAUUSD"

Â  Â  Â  Â  elif asset_str_upper == "EURUSD":

Â  Â  Â  Â  Â  Â  asset_to_display = "OANDA:EURUSD"

Â  Â  Â  Â  elif ":" not in asset_str_upper:Â 

Â  Â  Â  Â  Â  Â  asset_to_display = f"OANDA:{asset_str_upper}"Â 

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  asset_to_display = asset_str_upper

Â  Â  elif current_asset_input_from_form:

Â  Â  Â  Â  st.info(f"à¸à¸³à¸¥à¸±à¸‡à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ TradingView à¸ªà¸³à¸«à¸£à¸±à¸š: {str(current_asset_input_from_form).upper()} (à¸ˆà¸²à¸ Input à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™)")

Â  Â  Â  Â  asset_str_upper = str(current_asset_input_from_form).upper()

Â  Â  Â  Â  if asset_str_upper == "XAUUSD":

Â  Â  Â  Â  Â  Â  asset_to_display = "OANDA:XAUUSD"

Â  Â  Â  Â  elif asset_str_upper == "EURUSD":

Â  Â  Â  Â  Â  Â  asset_to_display = "OANDA:EURUSD"

Â  Â  Â  Â  elif ":" not in asset_str_upper:

Â  Â  Â  Â  Â  Â  asset_to_display = f"OANDA:{asset_str_upper}"

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  asset_to_display = asset_str_upper

Â  Â  else:Â 

Â  Â  Â  Â  st.info(f"à¸à¸³à¸¥à¸±à¸‡à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿ TradingView à¸ªà¸³à¸«à¸£à¸±à¸š: {asset_to_display} (à¸„à¹ˆà¸²à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™)")



Â  Â  tradingview_html = f"""

Â  Â  <div class="tradingview-widget-container" style="height:100%;width:100%">

Â  Â  Â  <div id="tradingview_legendary" style="height:calc(100% - 32px);width:100%"></div>

Â  Â  Â  <div class="tradingview-widget-copyright">

Â  Â  Â  Â  Â  <a href="https://th.tradingview.com/" rel="noopener nofollow" target="_blank">

Â  Â  Â  Â  Â  Â  Â  <span class="blue-text">à¸•à¸´à¸”à¸•à¸²à¸¡à¸•à¸¥à¸²à¸”à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸²à¸‡ TradingView</span>

Â  Â  Â  Â  Â  </a>

Â  Â  Â  </div>

Â  Â  Â  <script type="text/javascript" src="https://s3.tradingview.com/tv.js"></script>

Â  Â  Â  <script type="text/javascript">

Â  Â  Â  new TradingView.widget({{

Â  Â  Â  Â  "autosize": true,

Â  Â  Â  Â  "symbol": "{asset_to_display}",

Â  Â  Â  Â  "interval": "15",

Â  Â  Â  Â  "timezone": "Asia/Bangkok",

Â  Â  Â  Â  "theme": "dark",

Â  Â  Â  Â  "style": "1",

Â  Â  Â  Â  "locale": "th",

Â  Â  Â  Â  "enable_publishing": false,

Â  Â  Â  Â  "withdateranges": true,

Â  Â  Â  Â  "hide_side_toolbar": false,

Â  Â  Â  Â  "allow_symbol_change": true,

Â  Â  Â  Â  "details": true,

Â  Â  Â  Â  "hotlist": true,

Â  Â  Â  Â  "calendar": true,

Â  Â  Â  Â  "container_id": "tradingview_legendary"

Â  Â  Â  }});

Â  Â  Â  </script>

Â  Â  </div>

Â  Â  """

Â  Â  st.components.v1.html(tradingview_html, height=620)



# --- End of SEC 4 (formerly SEC 5) ---





# ===================== SEC 5: MAIN AREA - AI ASSISTANT =======================

with st.expander("ğŸ¤– AI Assistant", expanded=True):

Â  Â  active_portfolio_id_ai = st.session_state.get('active_portfolio_id_gs', None)

Â  Â  active_portfolio_name_ai = st.session_state.get('active_portfolio_name_gs', "à¸—à¸±à¹ˆà¸§à¹„à¸› (à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸·à¸­à¸à¸à¸­à¸£à¹Œà¸•)")

Â  Â Â 

Â  Â  balance_for_ai_sim = active_balance_to_use

Â  Â  report_title_suffix_planned = "(à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸œà¸™à¹€à¸—à¸£à¸”à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”)"

Â  Â  report_title_suffix_actual = "(à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”)"



Â  Â  if active_portfolio_id_ai:

Â  Â  Â  Â  report_title_suffix_planned = f"(à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸•: '{active_portfolio_name_ai}' à¸ˆà¸²à¸à¹à¸œà¸™)"

Â  Â  Â  Â  report_title_suffix_actual = f"(à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸•: '{active_portfolio_name_ai}' à¸ˆà¸²à¸à¸œà¸¥à¸ˆà¸£à¸´à¸‡)"

Â  Â  Â  Â  st.info(f"AI Assistant à¸à¸³à¸¥à¸±à¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸•: '{active_portfolio_name_ai}' (Balance à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸ˆà¸³à¸¥à¸­à¸‡: {balance_for_ai_sim:,.2f} USD)")

Â  Â  else:

Â  Â  Â  Â  st.info(f"AI Assistant à¸à¸³à¸¥à¸±à¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹à¸œà¸™à¹€à¸—à¸£à¸”à¹à¸¥à¸°à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸¥à¸·à¸­à¸ Active Portfolio - Balance à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸ˆà¸³à¸¥à¸­à¸‡: {balance_for_ai_sim:,.2f} USD)")



Â  Â  df_ai_logs_all_cached = load_all_planned_trade_logs_from_gsheets()

Â  Â  df_ai_logs_to_analyze = pd.DataFrame()

Â  Â Â 

Â  Â  if active_portfolio_id_ai and not df_ai_logs_all_cached.empty:

Â  Â  Â  Â  if 'PortfolioID' in df_ai_logs_all_cached.columns:

Â  Â  Â  Â  Â  Â  df_ai_logs_to_analyze = df_ai_logs_all_cached[df_ai_logs_all_cached['PortfolioID'] == str(active_portfolio_id_ai)].copy()

Â  Â  elif not df_ai_logs_all_cached.empty:

Â  Â  Â  Â  df_ai_logs_to_analyze = df_ai_logs_all_cached.copy()



Â  Â  if df_ai_logs_to_analyze.empty:

Â  Â  Â  Â  if df_ai_logs_all_cached.empty:

Â  Â  Â  Â  Â  Â  Â st.markdown(f"### ğŸ§  AI Intelligence Report {report_title_suffix_planned}")

Â  Â  Â  Â  Â  Â  Â st.info("à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸œà¸™à¹€à¸—à¸£à¸”à¹ƒà¸™ Log (Google Sheets) à¸ªà¸³à¸«à¸£à¸±à¸šà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ")

Â  Â  Â  Â  elif active_portfolio_id_ai :

Â  Â  Â  Â  Â  Â  Â st.markdown(f"### ğŸ§  AI Intelligence Report {report_title_suffix_planned}")

Â  Â  Â  Â  Â  Â  Â st.info(f"à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸œà¸™à¹€à¸—à¸£à¸”à¹ƒà¸™ Log à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸• '{active_portfolio_name_ai}'.")

Â  Â  else:Â 

Â  Â  Â  Â  total_trades_ai_planned = df_ai_logs_to_analyze.shape[0]

Â  Â  Â  Â  win_trades_ai_planned = 0

Â  Â  Â  Â  if "Risk $" in df_ai_logs_to_analyze.columns:

Â  Â  Â  Â  Â  Â  Â win_trades_ai_planned = df_ai_logs_to_analyze[df_ai_logs_to_analyze["Risk $"] > 0].shape[0]

Â  Â  Â  Â  winrate_ai_planned = (100 * win_trades_ai_planned / total_trades_ai_planned) if total_trades_ai_planned > 0 else 0

Â  Â  Â  Â Â 

Â  Â  Â  Â  gross_profit_ai_planned = 0.0

Â  Â  Â  Â  if "Risk $" in df_ai_logs_to_analyze.columns:

Â  Â  Â  Â  Â  Â  gross_profit_ai_planned = df_ai_logs_to_analyze["Risk $"].sum()

Â  Â  Â  Â Â 

Â  Â  Â  Â  avg_rr_ai_planned = None

Â  Â  Â  Â  if "RR" in df_ai_logs_to_analyze.columns:

Â  Â  Â  Â  Â  Â  rr_series_planned = pd.to_numeric(df_ai_logs_to_analyze["RR"], errors='coerce').dropna()

Â  Â  Â  Â  Â  Â  if not rr_series_planned.empty: avg_rr_ai_planned = rr_series_planned.mean()



Â  Â  Â  Â  max_drawdown_ai_planned = 0.0

Â  Â  Â  Â  if "Risk $" in df_ai_logs_to_analyze.columns and not df_ai_logs_to_analyze.empty:

Â  Â  Â  Â  Â  Â  df_ai_logs_sorted_for_dd_planned = df_ai_logs_to_analyze

Â  Â  Â  Â  Â  Â  if "Timestamp" in df_ai_logs_to_analyze.columns and not df_ai_logs_to_analyze["Timestamp"].isnull().all():

Â  Â  Â  Â  Â  Â  Â  Â  Â df_ai_logs_sorted_for_dd_planned = df_ai_logs_to_analyze.sort_values(by="Timestamp")

Â  Â  Â  Â  Â  Â  current_balance_sim_planned = balance_for_ai_simÂ 

Â  Â  Â  Â  Â  Â  peak_balance_sim_planned = balance_for_ai_sim

Â  Â  Â  Â  Â  Â  for pnl_val_planned in df_ai_logs_sorted_for_dd_planned["Risk $"]:

Â  Â  Â  Â  Â  Â  Â  Â  if pd.notna(pnl_val_planned):Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_balance_sim_planned += pnl_val_planned

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if current_balance_sim_planned > peak_balance_sim_planned: peak_balance_sim_planned = current_balance_sim_planned

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  drawdown_val_planned = peak_balance_sim_planned - current_balance_sim_planned

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if drawdown_val_planned > max_drawdown_ai_planned: max_drawdown_ai_planned = drawdown_val_planned

Â  Â  Â  Â Â 

Â  Â  Â  Â  win_day_ai_planned, loss_day_ai_planned = "-", "-"

Â  Â  Â  Â  if "Timestamp" in df_ai_logs_to_analyze.columns and "Risk $" in df_ai_logs_to_analyze.columns and \

Â  Â  Â  Â  Â  Â not df_ai_logs_to_analyze["Timestamp"].isnull().all() and not df_ai_logs_to_analyze.empty:

Â  Â  Â  Â  Â  Â  df_for_daily_pnl_planned = df_ai_logs_to_analyze.copy()

Â  Â  Â  Â  Â  Â  if not pd.api.types.is_datetime64_any_dtype(df_for_daily_pnl_planned["Timestamp"]):

Â  Â  Â  Â  Â  Â  Â  Â  df_for_daily_pnl_planned["Timestamp"] = pd.to_datetime(df_for_daily_pnl_planned["Timestamp"], errors='coerce')

Â  Â  Â  Â  Â  Â  df_for_daily_pnl_planned.dropna(subset=["Timestamp"], inplace=True)

Â  Â  Â  Â  Â  Â  if not df_for_daily_pnl_planned.empty:

Â  Â  Â  Â  Â  Â  Â  Â  df_for_daily_pnl_planned["Weekday"] = df_for_daily_pnl_planned["Timestamp"].dt.day_name()

Â  Â  Â  Â  Â  Â  Â  Â  daily_pnl_planned = df_for_daily_pnl_planned.groupby("Weekday")["Risk $"].sum()

Â  Â  Â  Â  Â  Â  Â  Â  if not daily_pnl_planned.empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  win_day_ai_planned = daily_pnl_planned.idxmax() if daily_pnl_planned.max() > 0 else "-"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  loss_day_ai_planned = daily_pnl_planned.idxmin() if daily_pnl_planned.min() < 0 else "-"



Â  Â  Â  Â  st.markdown(f"### ğŸ“ AI Intelligence Report {report_title_suffix_planned}")

Â  Â  Â  Â  st.write(f"- **à¸ˆà¸³à¸™à¸§à¸™à¹à¸œà¸™à¹€à¸—à¸£à¸”à¸—à¸µà¹ˆà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ:** {total_trades_ai_planned:,}")

Â  Â  Â  Â  st.write(f"- **Winrate (à¸•à¸²à¸¡à¹à¸œà¸™):** {winrate_ai_planned:.2f}%")

Â  Â  Â  Â  st.write(f"- **à¸à¸³à¹„à¸£/à¸‚à¸²à¸”à¸—à¸¸à¸™à¸ªà¸¸à¸—à¸˜à¸´ (à¸•à¸²à¸¡à¹à¸œà¸™):** {gross_profit_ai_planned:,.2f} USD")

Â  Â  Â  Â  st.write(f"- **RR à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ (à¸•à¸²à¸¡à¹à¸œà¸™):** {avg_rr_ai_planned:.2f}" if avg_rr_ai_planned is not None else "N/A")

Â  Â  Â  Â  st.write(f"- **Max Drawdown (à¸ˆà¸³à¸¥à¸­à¸‡à¸ˆà¸²à¸à¹à¸œà¸™):** {max_drawdown_ai_planned:,.2f} USD")

Â  Â  Â  Â  st.write(f"- **à¸§à¸±à¸™à¸—à¸µà¹ˆà¸—à¸³à¸à¸³à¹„à¸£à¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸” (à¸•à¸²à¸¡à¹à¸œà¸™):** {win_day_ai_planned}")

Â  Â  Â  Â  st.write(f"- **à¸§à¸±à¸™à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸—à¸¸à¸™à¸¡à¸²à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸” (à¸•à¸²à¸¡à¹à¸œà¸™):** {loss_day_ai_planned}")

Â  Â  Â  Â  st.markdown("#### ğŸ¤– AI Insight (à¸ˆà¸²à¸à¹à¸œà¸™à¹€à¸—à¸£à¸”)")

Â  Â  Â  Â  insight_messages_planned = []

Â  Â  Â  Â  if total_trades_ai_planned > 0 :Â 

Â  Â  Â  Â  Â  Â  if winrate_ai_planned >= 60: insight_messages_planned.append("âœ… Winrate (à¸•à¸²à¸¡à¹à¸œà¸™) à¸ªà¸¹à¸‡: à¸£à¸°à¸šà¸šà¸à¸²à¸£à¸§à¸²à¸‡à¹à¸œà¸™à¸¡à¸µà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸—à¸µà¹ˆà¸”à¸µ")

Â  Â  Â  Â  Â  Â  elif winrate_ai_planned < 40 and total_trades_ai_planned >=10 : insight_messages_planned.append("âš ï¸ Winrate (à¸•à¸²à¸¡à¹à¸œà¸™) à¸•à¹ˆà¸³: à¸„à¸§à¸£à¸—à¸šà¸—à¸§à¸™à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œà¸à¸²à¸£à¸§à¸²à¸‡à¹à¸œà¸™")

Â  Â  Â  Â  Â  Â  if avg_rr_ai_planned is not None and avg_rr_ai_planned < 1.5 and total_trades_ai_planned >=5 : insight_messages_planned.append("ğŸ“‰ RR à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ (à¸•à¸²à¸¡à¹à¸œà¸™) à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 1.5: à¸­à¸²à¸ˆà¸•à¹‰à¸­à¸‡à¸à¸´à¸ˆà¸²à¸£à¸“à¸²à¸à¸²à¸£à¸•à¸±à¹‰à¸‡ TP/SL à¹€à¸à¸·à¹ˆà¸­ Risk:Reward à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸‚à¸¶à¹‰à¸™")

Â  Â  Â  Â  Â  Â  if balance_for_ai_sim > 0 and max_drawdown_ai_planned > (balance_for_ai_sim * 0.10) : insight_messages_planned.append(f"ğŸš¨ Max Drawdown (à¸ˆà¸³à¸¥à¸­à¸‡à¸ˆà¸²à¸à¹à¸œà¸™) {max_drawdown_ai_planned:,.2f} USD à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸ªà¸¹à¸‡ ({ (max_drawdown_ai_planned/balance_for_ai_sim)*100:.1f}% à¸‚à¸­à¸‡ Balance): à¸„à¸§à¸£à¸£à¸°à¸¡à¸±à¸”à¸£à¸°à¸§à¸±à¸‡")

Â  Â  Â  Â  if not insight_messages_planned and total_trades_ai_planned > 0: insight_messages_planned = ["à¸”à¸¹à¹€à¸«à¸¡à¸·à¸­à¸™à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸œà¸™à¹€à¸—à¸£à¸”à¸—à¸µà¹ˆà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸™à¹ˆà¸²à¸à¸±à¸‡à¸§à¸¥à¹€à¸›à¹‡à¸™à¸à¸´à¹€à¸¨à¸©"]

Â  Â  Â  Â  for msg in insight_messages_planned:

Â  Â  Â  Â  Â  Â  if "âœ…" in msg: st.success(msg)

Â  Â  Â  Â  Â  Â  elif "âš ï¸" in msg or "ğŸ“‰" in msg: st.warning(msg)

Â  Â  Â  Â  Â  Â  elif "ğŸš¨" in msg: st.error(msg)

Â  Â  Â  Â  Â  Â  else: st.info(msg)



Â  Â  st.markdown("---")



Â  Â  df_actual_trades_all = load_actual_trades_from_gsheets()

Â  Â  df_actual_trades_to_analyze = pd.DataFrame()



Â  Â  if active_portfolio_id_ai and not df_actual_trades_all.empty:

Â  Â  Â  Â  if 'PortfolioID' in df_actual_trades_all.columns:

Â  Â  Â  Â  Â  Â  df_actual_trades_to_analyze = df_actual_trades_all[df_actual_trades_all['PortfolioID'] == str(active_portfolio_id_ai)].copy()

Â  Â  elif not df_actual_trades_all.empty:

Â  Â  Â  Â  df_actual_trades_to_analyze = df_actual_trades_all.copy()



Â  Â  st.markdown(f"### ğŸ“ˆ AI Intelligence Report {report_title_suffix_actual}")

Â  Â  if df_actual_trades_to_analyze.empty:

Â  Â  Â  Â  if df_actual_trades_all.empty :

Â  Â  Â  Â  Â  Â  Â st.info("à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡à¹ƒà¸™ Log (Google Sheets) à¸ªà¸³à¸«à¸£à¸±à¸šà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ")

Â  Â  Â  Â  elif active_portfolio_id_ai:

Â  Â  Â  Â  Â  Â  Â st.info(f"à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡à¹ƒà¸™ Log à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸• '{active_portfolio_name_ai}'.")

Â  Â  else:

Â  Â  Â  Â  if 'Profit_Deal' not in df_actual_trades_to_analyze.columns:

Â  Â  Â  Â  Â  Â  st.warning("à¹„à¸¡à¹ˆà¸à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'Profit_Deal' à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¸³à¸™à¸§à¸“à¸ªà¸–à¸´à¸•à¸´à¹„à¸”à¹‰")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  if 'Type_Deal' in df_actual_trades_to_analyze.columns:

Â  Â  Â  Â  Â  Â  Â  Â  df_trading_deals = df_actual_trades_to_analyze[

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ~df_actual_trades_to_analyze['Type_Deal'].astype(str).str.lower().isin(['balance', 'credit'])

Â  Â  Â  Â  Â  Â  Â  Â  ].copy()

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  df_trading_deals = df_actual_trades_to_analyze.copy()



Â  Â  Â  Â  Â  Â  if df_trading_deals.empty:

Â  Â  Â  Â  Â  Â  Â  Â  st.info("à¹„à¸¡à¹ˆà¸à¸šà¸£à¸²à¸¢à¸à¸²à¸£ Deals à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¸‚à¸²à¸¢à¸ˆà¸£à¸´à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  actual_total_deals = len(df_trading_deals)

Â  Â  Â  Â  Â  Â  Â  Â  actual_winning_deals_df = df_trading_deals[df_trading_deals['Profit_Deal'] > 0]

Â  Â  Â  Â  Â  Â  Â  Â  actual_losing_deals_df = df_trading_deals[df_trading_deals['Profit_Deal'] < 0]

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  actual_winning_deals_count = len(actual_winning_deals_df)

Â  Â  Â  Â  Â  Â  Â  Â  actual_losing_deals_count = len(actual_losing_deals_df)



Â  Â  Â  Â  Â  Â  Â  Â  actual_win_rate = (100 * actual_winning_deals_count / actual_total_deals) if actual_total_deals > 0 else 0

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  actual_gross_profit = actual_winning_deals_df['Profit_Deal'].sum()

Â  Â  Â  Â  Â  Â  Â  Â  actual_gross_loss = abs(actual_losing_deals_df['Profit_Deal'].sum())



Â  Â  Â  Â  Â  Â  Â  Â  actual_profit_factor = actual_gross_profit / actual_gross_loss if actual_gross_loss > 0 else float('inf') if actual_gross_profit > 0 else 0

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  actual_avg_profit_deal = actual_gross_profit / actual_winning_deals_count if actual_winning_deals_count > 0 else 0

Â  Â  Â  Â  Â  Â  Â  Â  actual_avg_loss_deal = actual_gross_loss / actual_losing_deals_count if actual_losing_deals_count > 0 else 0

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- **à¸ˆà¸³à¸™à¸§à¸™ Deals à¸—à¸µà¹ˆà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ (à¸œà¸¥à¸ˆà¸£à¸´à¸‡):** {actual_total_deals:,}")

Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- **Deal-Level Win Rate (à¸œà¸¥à¸ˆà¸£à¸´à¸‡):** {actual_win_rate:.2f}%")

Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- **à¸à¸³à¹„à¸£à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (Gross Profit - à¸œà¸¥à¸ˆà¸£à¸´à¸‡):** {actual_gross_profit:,.2f} USD")

Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- **à¸‚à¸²à¸”à¸—à¸¸à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (Gross Loss - à¸œà¸¥à¸ˆà¸£à¸´à¸‡):** {actual_gross_loss:,.2f} USD")

Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- **Profit Factor (Deal-Level - à¸œà¸¥à¸ˆà¸£à¸´à¸‡):** {actual_profit_factor:.2f}" if actual_profit_factor != float('inf') else "âˆ (No Losses)")

Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- **à¸à¸³à¹„à¸£à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¹ˆà¸­ Deal à¸—à¸µà¹ˆà¸Šà¸™à¸° (à¸œà¸¥à¸ˆà¸£à¸´à¸‡):** {actual_avg_profit_deal:,.2f} USD")

Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"- **à¸‚à¸²à¸”à¸—à¸¸à¸™à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸•à¹ˆà¸­ Deal à¸—à¸µà¹ˆà¹à¸à¹‰ (à¸œà¸¥à¸ˆà¸£à¸´à¸‡):** {actual_avg_loss_deal:,.2f} USD")



Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("#### ğŸ¤– AI Insight (à¸ˆà¸²à¸à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡)")

Â  Â  Â  Â  Â  Â  Â  Â  insight_messages_actual = []

Â  Â  Â  Â  Â  Â  Â  Â  if actual_total_deals > 0:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if actual_win_rate >= 50: insight_messages_actual.append("âœ… Win Rate (à¸œà¸¥à¸ˆà¸£à¸´à¸‡) à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¹€à¸à¸“à¸‘à¹Œà¸”à¸µ")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: insight_messages_actual.append("ğŸ“‰ Win Rate (à¸œà¸¥à¸ˆà¸£à¸´à¸‡) à¸„à¸§à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if actual_profit_factor > 1.5: insight_messages_actual.append("ğŸ“ˆ Profit Factor (à¸œà¸¥à¸ˆà¸£à¸´à¸‡) à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸°à¸”à¸±à¸šà¸—à¸µà¹ˆà¸”à¸µ")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif actual_profit_factor < 1 and actual_total_deals > 10: insight_messages_actual.append("âš ï¸ Profit Factor (à¸œà¸¥à¸ˆà¸£à¸´à¸‡) à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸² 1 à¸šà¹ˆà¸‡à¸Šà¸µà¹‰à¸§à¹ˆà¸²à¸‚à¸²à¸”à¸—à¸¸à¸™à¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸à¸³à¹„à¸£ à¸„à¸§à¸£à¸—à¸šà¸—à¸§à¸™à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œ")

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if not insight_messages_actual and actual_total_deals > 0 : insight_messages_actual = ["à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡à¸à¸³à¸¥à¸±à¸‡à¸–à¸¹à¸à¸£à¸§à¸šà¸£à¸§à¸¡ à¹‚à¸›à¸£à¸”à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Insights à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¹ƒà¸™à¸­à¸™à¸²à¸„à¸•"]

Â  Â  Â  Â  Â  Â  Â  Â  elif not actual_total_deals > 0 : insight_messages_actual = ["à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸œà¸¥à¸à¸²à¸£à¹€à¸—à¸£à¸”à¸ˆà¸£à¸´à¸‡à¹€à¸à¸µà¸¢à¸‡à¸à¸­à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡ Insight"]



Â  Â  Â  Â  Â  Â  Â  Â  for msg in insight_messages_actual:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if "âœ…" in msg or "ğŸ“ˆ" in msg : st.success(msg)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif "âš ï¸" in msg or "ğŸ“‰" in msg: st.warning(msg)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: st.info(msg)



# --- End of SEC 5 (formerly SEC 6) ---



# ===================== SEC 6: MAIN AREA - STATEMENT IMPORT & PROCESSING =======================

with st.expander("ğŸ“‚Â  Ultimate Chart Dashboard Import & Processing", expanded=True):

Â  Â  st.markdown("### ğŸ“Š à¸ˆà¸±à¸”à¸à¸²à¸£ Statement à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸”à¸´à¸š")



Â  Â  # --- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸¢à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹„à¸Ÿà¸¥à¹Œ Statement (CSV) ---

Â  Â  def extract_data_from_report_content(file_content_str_input):

Â  Â  Â  Â  extracted_data = {'deals': pd.DataFrame(), 'orders': pd.DataFrame(), 'positions': pd.DataFrame(), 'balance_summary': {}, 'results_summary': {}}



Â  Â  Â  Â  # Function to safely convert values to float (from mainà¹‚à¸«à¸¥à¸”à¹„à¸”à¹‰à¸«à¸¡à¸”.py's logic)

Â  Â  Â  Â  def safe_float_convert(value_str):

Â  Â  Â  Â  Â  Â  if isinstance(value_str, (int, float)):

Â  Â  Â  Â  Â  Â  Â  Â  return value_str

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  # Remove spaces, commas, and percentage signs

Â  Â  Â  Â  Â  Â  Â  Â  clean_value = str(value_str).strip().replace(" ", "").replace(",", "").replace("%", "")

Â  Â  Â  Â  Â  Â  Â  Â  if clean_value.count('.') > 1: # Handle cases like "1.234.56"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parts = clean_value.split('.'); integer_part = "".join(parts[:-1]); decimal_part = parts[-1]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  clean_value = integer_part + "." + decimal_part

Â  Â  Â  Â  Â  Â  Â  Â  if not clean_value:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return None

Â  Â  Â  Â  Â  Â  Â  Â  return float(clean_value)

Â  Â  Â  Â  Â  Â  except (ValueError, TypeError, AttributeError):

Â  Â  Â  Â  Â  Â  Â  Â  return None



Â  Â  Â  Â  lines = []

Â  Â  Â  Â  if isinstance(file_content_str_input, str):

Â  Â  Â  Â  Â  Â  lines = file_content_str_input.strip().split('\n')

Â  Â  Â  Â  elif isinstance(file_content_str_input, bytes):

Â  Â  Â  Â  Â  Â  lines = file_content_str_input.decode('utf-8', errors='replace').strip().split('\n')

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  print("Error: Invalid file_content type in extract_data_from_report_content.")

Â  Â  Â  Â  Â  Â  return extracted_data

Â  Â  Â  Â Â 

Â  Â  Â  Â  if not lines:

Â  Â  Â  Â  Â  Â  print("Warning: File content is empty in extract_data_from_report_content.")

Â  Â  Â  Â  Â  Â  return extracted_data



Â  Â  Â  Â  # Section keywords for identifying data blocks (from mainà¹‚à¸«à¸¥à¸”à¹„à¸”à¹‰à¸«à¸¡à¸”.py's logic)

Â  Â  Â  Â  section_keywords_for_structure = ["Positions", "Orders", "Deals", "History", "Results", "Balance"]

Â  Â  Â  Â  section_starts = {}



Â  Â  Â  Â  for i, line in enumerate(lines):

Â  Â  Â  Â  Â  Â  for keyword in section_keywords_for_structure:

Â  Â  Â  Â  Â  Â  Â  Â  if keyword not in section_starts and keyword in line:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Special handling for "Deals" section, as "History" might be its keyword in some reports

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  actual_key = "Deals" if keyword == "History" else keyword

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if actual_key not in section_starts: # Only record the first occurrence

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  section_starts[actual_key] = i

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break # Move to next line after finding a keyword



Â  Â  Â  Â  # Define raw headers and expected cleaned column names for table sections

Â  Â  Â  Â  section_raw_headers = {

Â  Â  Â  Â  Â  Â  "Positions": "Time,Position,Symbol,Type,Volume,Price,S / L,T / P,Time,Price,Commission,Swap,Profit",

Â  Â  Â  Â  Â  Â  "Orders": "Open Time,Order,Symbol,Type,Volume,Price,S / L,T / P,Time,State,,Comment",

Â  Â  Â  Â  Â  Â  "Deals": "Time,Deal,Symbol,Type,Direction,Volume,Price,Order,Commission,Fee,Swap,Profit,Balance,Comment",

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  expected_cleaned_columns = {

Â  Â  Â  Â  Â  Â  "Positions": ["Time_Pos", "Position_ID", "Symbol_Pos", "Type_Pos", "Volume_Pos", "Price_Open_Pos", "S_L_Pos", "T_P_Pos", "Time_Close_Pos", "Price_Close_Pos", "Commission_Pos", "Swap_Pos", "Profit_Pos"],

Â  Â  Â  Â  Â  Â  "Orders": ["Open_Time_Ord", "Order_ID_Ord", "Symbol_Ord", "Type_Ord", "Volume_Ord", "Price_Ord", "S_L_Ord", "T_P_Ord", "Close_Time_Ord", "State_Ord", "Filler_Ord","Comment_Ord"], # Keeping Filler for consistency with typical structure

Â  Â  Â  Â  Â  Â  "Deals": ["Time_Deal", "Deal_ID", "Symbol_Deal", "Type_Deal", "Direction_Deal", "Volume_Deal", "Price_Deal", "Order_ID_Deal", "Commission_Deal", "Fee_Deal", "Swap_Deal", "Profit_Deal", "Balance_Deal", "Comment_Deal"],

Â  Â  Â  Â  }

Â  Â  Â  Â Â 

Â  Â  Â  Â  section_order_for_tables = ["Positions", "Orders", "Deals"]



Â  Â  Â  Â  # 1. Parse each table section (Positions, Orders, Deals)

Â  Â  Â  Â  for table_idx, section_name in enumerate(section_order_for_tables):

Â  Â  Â  Â  Â  Â  section_key_lower = section_name.lower()

Â  Â  Â  Â  Â  Â  extracted_data[section_key_lower] = pd.DataFrame() # Initialize with empty DataFrame



Â  Â  Â  Â  Â  Â  if section_name in section_starts:

Â  Â  Â  Â  Â  Â  Â  Â  start_row_idx = section_starts[section_name]

Â  Â  Â  Â  Â  Â  Â  Â  header_row_idx = start_row_idx + 1 # Assuming header is always 1 line after section keyword



Â  Â  Â  Â  Â  Â  Â  Â  # Find actual header row (skip empty lines if any)

Â  Â  Â  Â  Â  Â  Â  Â  while header_row_idx < len(lines) and not lines[header_row_idx].strip():

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  header_row_idx += 1



Â  Â  Â  Â  Â  Â  Â  Â  if header_row_idx >= len(lines):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"DEBUG: Could not find header row for {section_name} after keyword.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue # Skip if no header found



Â  Â  Â  Â  Â  Â  Â  Â  headers_raw = lines[header_row_idx].strip().split(',')

Â  Â  Â  Â  Â  Â  Â  Â  # Clean headers by stripping and removing empty strings, and handle duplicates (e.g. from merged cells)

Â  Â  Â  Â  Â  Â  Â  Â  headers_cleaned = [h.strip() for h in headers_raw if h.strip()]

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  # Check for duplicates and make unique, e.g., by appending numbers

Â  Â  Â  Â  Â  Â  Â  Â  seen = {}

Â  Â  Â  Â  Â  Â  Â  Â  headers_final = []

Â  Â  Â  Â  Â  Â  Â  Â  for h in headers_cleaned:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if h in seen:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  seen[h] += 1

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  headers_final.append(f"{h}_{seen[h]}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  seen[h] = 1

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  headers_final.append(h)





Â  Â  Â  Â  Â  Â  Â  Â  data_start_row = header_row_idx + 1

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  # Determine where data for current table ends

Â  Â  Â  Â  Â  Â  Â  Â  data_end_row = len(lines)

Â  Â  Â  Â  Â  Â  Â  Â  for next_table_name_idx in range(table_idx + 1, len(section_order_for_tables)):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  next_section_name_candidate = section_order_for_tables[next_table_name_idx]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if next_section_name_candidate in section_starts:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data_end_row = section_starts[next_section_name_candidate]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  current_table_data_lines = []

Â  Â  Â  Â  Â  Â  Â  Â  for line_num in range(data_start_row, data_end_row):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  line_content = lines[line_num].strip()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not line_content: # Empty line, might be end of data

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if any(current_table_data_lines): # If we have collected data, this blank line marks end

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: # Skip leading blank lines after header

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Heuristic: If line starts looking like a summary or a different section header, stop.

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if line_content.startswith(("Balance:", "Credit Facility:", "Floating P/L:", "Equity:", "Results", "Total Net Profit:")):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  is_another_header = False

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for other_sec_name, other_raw_hdr_template in section_raw_headers.items():

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if other_sec_name != section_name and line_content.startswith(other_raw_hdr_template.split(',')[0].strip()) and other_raw_hdr_template in line_content:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  is_another_header = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if is_another_header:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Special handling for Deals/Balance/Credit rows that are part of the Deals table but are summary-like

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if section_name == "Deals":

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parts_of_line = [p.strip().lower() for p in line_content.split(',')]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(parts_of_line) > 3 and parts_of_line[3] in ['balance', 'credit', 'initial_deposit']:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"DEBUG [extract_data]: Skipping summary-like row in Deals: '{line_content}'")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue # Skip these lines as they are not actual trades



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_table_data_lines.append(line_content)



Â  Â  Â  Â  Â  Â  Â  Â  if current_table_data_lines:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  csv_data_str = "\n".join(current_table_data_lines)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_section = pd.read_csv(io.StringIO(csv_data_str),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â header=None,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â names=headers_final, # Use the dynamic headers

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â skipinitialspace=True,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â on_bad_lines='warn',

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â engine='python')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_section.dropna(how='all', inplace=True)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not df_section.empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extracted_data[section_key_lower] = df_section

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e_parse_df:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error parsing table data for {section_name}: {e_parse_df}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.text(f"Problematic CSV data for {section_name}:\n{csv_data_str[:500]}")





Â  Â  Â  Â  # --- Extract Balance Summary (Equity, Free Margin, etc.) ---

Â  Â  Â  Â  balance_summary_dict = {}

Â  Â  Â  Â  balance_section_start_line = -1



Â  Â  Â  Â  # Search for the "Balance:" keyword (more robustly)

Â  Â  Â  Â  for i, line in enumerate(lines):

Â  Â  Â  Â  Â  Â  if "Balance:" in line: # Use "in" for more flexibility

Â  Â  Â  Â  Â  Â  Â  Â  balance_section_start_line = i

Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â Â 

Â  Â  Â  Â  if balance_section_start_line != -1:

Â  Â  Â  Â  Â  Â  for i in range(balance_section_start_line, min(balance_section_start_line + 10, len(lines))): # Check next 10 lines

Â  Â  Â  Â  Â  Â  Â  Â  line_stripped = lines[i].strip()

Â  Â  Â  Â  Â  Â  Â  Â  if not line_stripped: continue

Â  Â  Â  Â  Â  Â  Â  Â  if line_stripped.startswith(("Results", "Total Net Profit:")): break # Stop if results section begins



Â  Â  Â  Â  Â  Â  Â  Â  # Specific parsing for Balance and Equity lines based on your format

Â  Â  Â  Â  Â  Â  Â  Â  # Example: "Balance:,,,4 708.36,,,Free Margin:,,,4 708.36,,,,"

Â  Â  Â  Â  Â  Â  Â  Â  # Example: "Equity:,,,4 708.36,,,,,,,,,"

Â  Â  Â  Â  Â  Â  Â  Â  if "Balance:" in line_stripped:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parts = line_stripped.split(',')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Find the first non-empty, convertable value after "Balance:"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for p in parts[1:]: # Start from the part after "Balance:"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val = safe_float_convert(p)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if val is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  balance_summary_dict['balance'] = val

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  elif "Equity:" in line_stripped:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parts = line_stripped.split(',')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Find the first non-empty, convertable value after "Equity:"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for p in parts[1:]:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val = safe_float_convert(p)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if val is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  balance_summary_dict['equity'] = val

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  # Generic parsing for other summary fields (Free Margin, Credit Facility etc.)

Â  Â  Â  Â  Â  Â  Â  Â  parts_with_colon = [p.strip() for p in line_stripped.split(',') if ':' in p]

Â  Â  Â  Â  Â  Â  Â  Â  for part in parts_with_colon:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key_part, val_part = part.split(':', 1)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key_clean = key_part.strip().lower().replace(" ", "_").replace(".", "")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val_clean = val_part.strip()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if val_clean:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  numeric_val = safe_float_convert(val_clean.split(' ')[0]) # Take first word before space

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if numeric_val is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  balance_summary_dict[key_clean] = numeric_val



Â  Â  Â  Â  # Ensure essential keys are present, defaulting to 0.0 if not found

Â  Â  Â  Â  essential_balance_keys = ["balance", "credit_facility", "floating_p_l", "equity", "free_margin", "margin", "margin_level"]

Â  Â  Â  Â  for k_b in essential_balance_keys:

Â  Â  Â  Â  Â  Â  if k_b not in balance_summary_dict:

Â  Â  Â  Â  Â  Â  Â  Â  balance_summary_dict[k_b] = 0.0 # Default to 0.0 if not found



Â  Â  Â  Â  extracted_data['balance_summary'] = balance_summary_dict

Â  Â  Â  Â Â 

Â  Â  Â  Â  # --- Extract Results Summary (Total Net Profit, Profit Factor, etc.) ---

Â  Â  Â  Â  results_summary_dict = {}

Â  Â  Â  Â  results_section_start_line = -1



Â  Â  Â  Â  for i_res, line_res in enumerate(lines):

Â  Â  Â  Â  Â  Â  if "Results" in line_res or "Total Net Profit:" in line_res:

Â  Â  Â  Â  Â  Â  Â  Â  results_section_start_line = i_res

Â  Â  Â  Â  Â  Â  Â  Â  break



Â  Â  Â  Â  if results_section_start_line != -1:

Â  Â  Â  Â  Â  Â  stat_definitions_map = { # Keeping this map as it was, it's robust

Â  Â  Â  Â  Â  Â  Â  Â  "Total Net Profit": "Total_Net_Profit", "Gross Profit": "Gross_Profit", "Gross Loss": "Gross_Loss",

Â  Â  Â  Â  Â  Â  Â  Â  "Profit Factor": "Profit_Factor", "Expected Payoff": "Expected_Payoff",

Â  Â  Â  Â  Â  Â  Â  Â  "Recovery Factor": "Recovery_Factor", "Sharpe Ratio": "Sharpe_Ratio",

Â  Â  Â  Â  Â  Â  Â  Â  "Balance Drawdown Absolute": "Balance_Drawdown_Absolute",

Â  Â  Â  Â  Â  Â  Â  Â  "Balance Drawdown Maximal": "Balance_Drawdown_Maximal",

Â  Â  Â  Â  Â  Â  Â  Â  "Balance Drawdown Relative": "Balance_Drawdown_Relative_Percent",

Â  Â  Â  Â  Â  Â  Â  Â  "Total Trades": "Total_Trades",

Â  Â  Â  Â  Â  Â  Â  Â  "Short Trades (won %)": "Short_Trades",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Long Trades (won %)": "Long_Trades",

Â  Â  Â  Â  Â  Â  Â  Â  "Profit Trades (% of total)": "Profit_Trades",

Â  Â  Â  Â  Â  Â  Â  Â  "Loss Trades (% of total)": "Loss_Trades",

Â  Â  Â  Â  Â  Â  Â  Â  "Largest profit trade": "Largest_profit_trade", "Largest loss trade": "Largest_loss_trade",

Â  Â  Â  Â  Â  Â  Â  Â  "Average profit trade": "Average_profit_trade", "Average loss trade": "Average_loss_trade",

Â  Â  Â  Â  Â  Â  Â  Â  "Maximum consecutive wins ($)": "Maximum_consecutive_wins_Count",

Â  Â  Â  Â  Â  Â  Â  Â  "Maximal consecutive profit (count)": "Maximal_consecutive_profit_Amount",

Â  Â  Â  Â  Â  Â  Â  Â  "Average consecutive wins": "Average_consecutive_wins",

Â  Â  Â  Â  Â  Â  Â  Â  "Maximum consecutive losses ($)": "Maximum_consecutive_losses_Count",

Â  Â  Â  Â  Â  Â  Â  Â  "Maximal consecutive loss (count)": "Maximal_consecutive_loss_Count",

Â  Â  Â  Â  Â  Â  Â  Â  "Average consecutive losses": "Average_consecutive_losses"

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  max_lines_to_read = 25 # Safety limit



Â  Â  Â  Â  Â  Â  for i_res_line in range(results_section_start_line, min(results_section_start_line + max_lines_to_read, len(lines))):

Â  Â  Â  Â  Â  Â  Â  Â  line_stripped_res = lines[i_res_line].strip()

Â  Â  Â  Â  Â  Â  Â  Â  if not line_stripped_res: continue



Â  Â  Â  Â  Â  Â  Â  Â  # Try to parse key-value pairs separated by comma for results

Â  Â  Â  Â  Â  Â  Â  Â  # This needs to be robust for varied formatting

Â  Â  Â  Â  Â  Â  Â  Â  parts = line_stripped_res.split(',')

Â  Â  Â  Â  Â  Â  Â  Â  for part_idx, part_content in enumerate(parts):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  content_clean = part_content.strip()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not content_clean: continue



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Check if it's a known label (e.g., "Total Net Profit:")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label_to_check = content_clean.replace(':', '')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if label_to_check in stat_definitions_map:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gsheet_key = stat_definitions_map[label_to_check]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Search for value in the next few parts of the same line

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for val_search_idx in range(1, 4): # Check next 1, 2, or 3 parts

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (part_idx + val_search_idx) < len(parts):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  raw_value_part = parts[part_idx + val_search_idx].strip()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if raw_value_part:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value_before_paren = raw_value_part.split('(')[0].strip()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  numeric_value = safe_float_convert(value_before_paren)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if numeric_value is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  results_summary_dict[gsheet_key] = numeric_value

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Handle parenthetical values (e.g. percentages, counts)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if '(' in raw_value_part and ')' in raw_value_part:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  paren_content = raw_value_part[raw_value_part.find('(')+1:raw_value_part.find(')')].strip().replace('%','')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  paren_numeric = safe_float_convert(paren_content)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if paren_numeric is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Assign composite keys (e.g., Balance_Drawdown_Maximal_Percent)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if label_to_check == "Balance Drawdown Maximal": results_summary_dict["Balance_Drawdown_Maximal_Percent"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Balance Drawdown Relative": results_summary_dict["Balance_Drawdown_Relative_Amount"] = paren_numeric # Amount for Relative DD

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Short Trades (won %)": results_summary_dict["Short_Trades_won_Percent"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Long Trades (won %)": results_summary_dict["Long_Trades_won_Percent"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Profit Trades (% of total)": results_summary_dict["Profit_Trades_Percent_of_total"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Loss Trades (% of total)": results_summary_dict["Loss_Trades_Percent_of_total"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Maximum consecutive wins ($)": results_summary_dict["Maximum_consecutive_wins_Profit"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Maximal consecutive profit (count)": results_summary_dict["Maximal_consecutive_profit_Count"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Maximum consecutive losses ($)": results_summary_dict["Maximum_consecutive_losses_Profit"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif label_to_check == "Maximal consecutive loss (count)": results_summary_dict["Maximal_consecutive_loss_Count"] = paren_numeric

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break # Value found for this label, move to next label

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  if line_stripped_res.startswith("Average consecutive losses"): break # Common end marker

Â  Â  Â  Â Â 

Â  Â  Â  Â  extracted_data['results_summary'] = results_summary_dict



Â  Â  Â  Â  # Debug print for parsed data

Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  st.subheader("DEBUG: Final Parsed Summaries (after extract_data_from_report_content)")

Â  Â  Â  Â  Â  Â  st.write("Balance Summary (Equity, Free Margin, etc.):")

Â  Â  Â  Â  Â  Â  st.json(balance_summary_dict if balance_summary_dict else "Balance summary not parsed or empty.")

Â  Â  Â  Â  Â  Â  st.write("Results Summary (Profit Factor, Trades, etc.):")

Â  Â  Â  Â  Â  Â  st.json(results_summary_dict if results_summary_dict else "Results summary not parsed or empty.")



Â  Â  Â  Â  return extracted_data



Â  Â  # --- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸šà¸±à¸™à¸—à¸¶à¸ Deals à¸¥à¸‡à¹ƒà¸™à¸Šà¸µà¸— ActualTrades ---

Â  Â  def save_deals_to_actual_trades(sh, df_deals, portfolio_id, portfolio_name, source_file_name="N/A", import_batch_id="N/A"):

Â  Â  Â  Â  if df_deals is None or df_deals.empty:

Â  Â  Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  Â  Â  st.info("DEBUG: No Deals data to save for this call.")

Â  Â  Â  Â  Â  Â  return True # Consider as success if no data to save

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  ws = sh.worksheet(WORKSHEET_ACTUAL_TRADES)

Â  Â  Â  Â  Â  Â  expected_headers = [

Â  Â  Â  Â  Â  Â  Â  Â  "Time", "Position", "Symbol", "Type", "Volume", "Price", "S_L", "T_P",

Â  Â  Â  Â  Â  Â  Â  Â  "Close_Time_Pos", "Close_Price_Pos", "Commission_Pos", "Swap_Pos", "Profit_Pos",

Â  Â  Â  Â  Â  Â  Â  Â  "PortfolioID", "PortfolioName", "SourceFile", "ImportBatchID"

Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # Auto-create/update headers if needed

Â  Â  Â  Â  Â  Â  current_headers = []

Â  Â  Â  Â  Â  Â  if ws.row_count > 0: current_headers = ws.row_values(1)

Â  Â  Â  Â  Â  Â  if not current_headers or all(h == "" for h in current_headers) or set(current_headers) != set(expected_headers): ws.update([expected_headers])



Â  Â  Â  Â  Â  Â  # Prepare DataFrame for saving, ensuring all expected headers are present

Â  Â  Â  Â  Â  Â  df_deals_to_save = pd.DataFrame(columns=expected_headers)

Â  Â  Â  Â  Â  Â  for col in expected_headers:

Â  Â  Â  Â  Â  Â  Â  Â  if col in df_deals.columns:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_deals_to_save[col] = df_deals[col]

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_deals_to_save[col] = None # Fill missing columns with None/NaN



Â  Â  Â  Â  Â  Â  # Add system-generated columns

Â  Â  Â  Â  Â  Â  df_deals_to_save["PortfolioID"] = str(portfolio_id)

Â  Â  Â  Â  Â  Â  df_deals_to_save["PortfolioName"] = str(portfolio_name)

Â  Â  Â  Â  Â  Â  df_deals_to_save["SourceFile"] = str(source_file_name)

Â  Â  Â  Â  Â  Â  df_deals_to_save["ImportBatchID"] = str(import_batch_id)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # Convert all data to string to avoid gspread type issues

Â  Â  Â  Â  Â  Â  list_of_lists = df_deals_to_save.astype(str).replace('nan', '').fillna('').values.tolist()

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if list_of_lists:

Â  Â  Â  Â  Â  Â  Â  Â  Â ws.append_rows(list_of_lists, value_input_option='USER_ENTERED')

Â  Â  Â  Â  Â  Â  Â  Â  Â return True

Â  Â  Â  Â  Â  Â  return False

Â  Â  Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š Worksheet '{WORKSHEET_ACTUAL_TRADES}'. à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¹ƒà¸ªà¹ˆ Headers: {', '.join(expected_headers)}")

Â  Â  Â  Â  Â  Â  return False

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸ Deals: {e}"); st.exception(e); return False



Â  Â  # --- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸šà¸±à¸™à¸—à¸¶à¸ Positions à¸¥à¸‡à¹ƒà¸™à¸Šà¸µà¸— ActualPositions ---

Â  Â  def save_positions_to_gsheets(sh, df_positions, portfolio_id, portfolio_name, source_file_name="N/A", import_batch_id="N/A"):

Â  Â  Â  Â  if df_positions is None or df_positions.empty:

Â  Â  Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  Â  Â  st.info("DEBUG: No Positions data to save for this call.")

Â  Â  Â  Â  Â  Â  return True

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  ws = sh.worksheet(WORKSHEET_ACTUAL_POSITIONS)

Â  Â  Â  Â  Â  Â  expected_headers = [

Â  Â  Â  Â  Â  Â  Â  Â  "Time", "Position", "Symbol", "Type", "Volume", "Price", "S_L", "T_P",

Â  Â  Â  Â  Â  Â  Â  Â  "Close_Time_Pos", "Close_Price_Pos", "Commission_Pos", "Swap_Pos", "Profit_Pos",

Â  Â  Â  Â  Â  Â  Â  Â  "PortfolioID", "PortfolioName", "SourceFile", "ImportBatchID"

Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  Â  Â  current_headers = []

Â  Â  Â  Â  Â  Â  if ws.row_count > 0: current_headers = ws.row_values(1)

Â  Â  Â  Â  Â  Â  if not current_headers or all(h == "" for h in current_headers) or set(current_headers) != set(expected_headers): ws.update([expected_headers])



Â  Â  Â  Â  Â  Â  df_positions_to_save = pd.DataFrame(columns=expected_headers)

Â  Â  Â  Â  Â  Â  for col in expected_headers:

Â  Â  Â  Â  Â  Â  Â  Â  if col in df_positions.columns:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_positions_to_save[col] = df_positions[col]

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_positions_to_save[col] = None



Â  Â  Â  Â  Â  Â  df_positions_to_save["PortfolioID"] = str(portfolio_id)

Â  Â  Â  Â  Â  Â  df_positions_to_save["PortfolioName"] = str(portfolio_name)

Â  Â  Â  Â  Â  Â  df_positions_to_save["SourceFile"] = str(source_file_name)

Â  Â  Â  Â  Â  Â  df_positions_to_save["ImportBatchID"] = str(import_batch_id)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  list_of_lists = df_positions_to_save.astype(str).replace('nan', '').fillna('').values.tolist()

Â  Â  Â  Â  Â  Â  if list_of_lists:

Â  Â  Â  Â  Â  Â  Â  Â  ws.append_rows(list_of_lists, value_input_option='USER_ENTERED')

Â  Â  Â  Â  Â  Â  Â  Â  return True

Â  Â  Â  Â  Â  Â  return False

Â  Â  Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š Worksheet '{WORKSHEET_ACTUAL_POSITIONS}'. à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¹ƒà¸ªà¹ˆ Headers: {', '.join(expected_headers)}")

Â  Â  Â  Â  Â  Â  return False

Â  Â  Â  Â  except Exception as e: st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸ Positions: {e}"); st.exception(e); return False



Â  Â  # --- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸šà¸±à¸™à¸—à¸¶à¸ Orders à¸¥à¸‡à¹ƒà¸™à¸Šà¸µà¸— ActualOrders ---

Â  Â  def save_orders_to_gsheets(sh, df_orders, portfolio_id, portfolio_name, source_file_name="N/A", import_batch_id="N/A"):

Â  Â  Â  Â  if df_orders is None or df_orders.empty:

Â  Â  Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  Â  Â  st.info("DEBUG: No Orders data to save for this call.")

Â  Â  Â  Â  Â  Â  return True

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  ws = sh.worksheet(WORKSHEET_ACTUAL_ORDERS)

Â  Â  Â  Â  Â  Â  expected_headers = [

Â  Â  Â  Â  Â  Â  Â  Â  "Open_Time_Ord", "Order_ID_Ord", "Symbol_Ord", "Type_Ord", "Volume_Ord", "Price_Ord", "S_L_Ord", "T_P_Ord",

Â  Â  Â  Â  Â  Â  Â  Â  "Close_Time_Ord", "State_Ord", "Comment_Ord", # Adjusted to match fewer columns in provided report

Â  Â  Â  Â  Â  Â  Â  Â  "PortfolioID", "PortfolioName", "SourceFile", "ImportBatchID"

Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  Â  Â  current_headers = []

Â  Â  Â  Â  Â  Â  if ws.row_count > 0: current_headers = ws.row_values(1)

Â  Â  Â  Â  Â  Â  if not current_headers or all(h == "" for h in current_headers) or set(current_headers) != set(expected_headers): ws.update([expected_headers])



Â  Â  Â  Â  Â  Â  df_orders_to_save = pd.DataFrame(columns=expected_headers)

Â  Â  Â  Â  Â  Â  for col in expected_headers:

Â  Â  Â  Â  Â  Â  Â  Â  if col in df_orders.columns:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_orders_to_save[col] = df_orders[col]

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_orders_to_save[col] = None

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  df_orders_to_save["PortfolioID"] = str(portfolio_id)

Â  Â  Â  Â  Â  Â  df_orders_to_save["PortfolioName"] = str(portfolio_name)

Â  Â  Â  Â  Â  Â  df_orders_to_save["SourceFile"] = str(source_file_name)

Â  Â  Â  Â  Â  Â  df_orders_to_save["ImportBatchID"] = str(import_batch_id)



Â  Â  Â  Â  Â  Â  list_of_lists = df_orders_to_save.astype(str).replace('nan', '').fillna('').values.tolist()

Â  Â  Â  Â  Â  Â  if list_of_lists:

Â  Â  Â  Â  Â  Â  Â  Â  ws.append_rows(list_of_lists, value_input_option='USER_ENTERED')

Â  Â  Â  Â  Â  Â  Â  Â  return True

Â  Â  Â  Â  Â  Â  return False

Â  Â  Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š Worksheet '{WORKSHEET_ACTUAL_ORDERS}'. à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¹ƒà¸ªà¹ˆ Headers: {', '.join(expected_headers)}")

Â  Â  Â  Â  Â  Â  return False

Â  Â  Â  Â  except Exception as e: st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸ Orders: {e}"); st.exception(e); return False

Â  Â  Â  Â Â 

Â  Â  # --- à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸šà¸±à¸™à¸—à¸¶à¸ Results Summary à¸¥à¸‡à¹ƒà¸™à¸Šà¸µà¸— StatementSummaries ---

Â  Â  def save_results_summary_to_gsheets(sh, balance_summary_data, results_summary_data, portfolio_id, portfolio_name, source_file_name="N/A", import_batch_id="N/A"):

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  ws = sh.worksheet(WORKSHEET_STATEMENT_SUMMARIES)

Â  Â  Â  Â  Â  Â  expected_headers = [

Â  Â  Â  Â  Â  Â  Â  Â  "Timestamp", "PortfolioID", "PortfolioName", "SourceFile", "ImportBatchID",

Â  Â  Â  Â  Â  Â  Â  Â  "Balance", "Equity", "Free_Margin", "Margin", "Floating_P_L", "Margin_Level", "Credit_Facility",

Â  Â  Â  Â  Â  Â  Â  Â  "Total_Net_Profit", "Gross_Profit", "Gross_Loss", "Profit_Factor",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Expected_Payoff", "Recovery_Factor", "Sharpe_Ratio",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Balance_Drawdown_Absolute", "Balance_Drawdown_Maximal", "Balance_Drawdown_Maximal_Percent",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Balance_Drawdown_Relative_Percent", "Balance_Drawdown_Relative_Amount",

Â  Â  Â  Â  Â  Â  Â  Â  "Total_Trades", "Short_Trades", "Short_Trades_won_Percent", "Long_Trades", "Long_Trades_won_Percent",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Profit_Trades", "Profit_Trades_Percent_of_total", "Loss_Trades", "Loss_Trades_Percent_of_total",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Largest_profit_trade", "Largest_loss_trade", "Average_profit_trade", "Average_loss_trade",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Maximum_consecutive_wins_Count", "Maximum_consecutive_wins_Profit",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Maximal_consecutive_profit_Amount", "Maximal_consecutive_profit_Count",

Â  Â  Â  Â  Â  Â  Â  Â  "Maximum_consecutive_losses_Count", "Maximum_consecutive_losses_Profit",Â 

Â  Â  Â  Â  Â  Â  Â  Â  "Maximal_consecutive_loss_Amount", "Maximal_consecutive_loss_Count",

Â  Â  Â  Â  Â  Â  Â  Â  "Average_consecutive_wins", "Average_consecutive_losses"

Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  current_headers_ws = []

Â  Â  Â  Â  Â  Â  if ws.row_count > 0: current_headers_ws = ws.row_values(1)

Â  Â  Â  Â  Â  Â  if not current_headers_ws or all(h == "" for h in current_headers_ws) or set(current_headers_ws) != set(expected_headers): ws.update([expected_headers])



Â  Â  Â  Â  Â  Â  row_data_to_save = {h: None for h in expected_headers} # Initialize with None

Â  Â  Â  Â  Â  Â  row_data_to_save.update({

Â  Â  Â  Â  Â  Â  Â  Â  "Timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),

Â  Â  Â  Â  Â  Â  Â  Â  "PortfolioID": str(portfolio_id),

Â  Â  Â  Â  Â  Â  Â  Â  "PortfolioName": str(portfolio_name),

Â  Â  Â  Â  Â  Â  Â  Â  "SourceFile": str(source_file_name),

Â  Â  Â  Â  Â  Â  Â  Â  "ImportBatchID": str(import_batch_id) # Add ImportBatchID for summaries too

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # Populate from balance_summary_data

Â  Â  Â  Â  Â  Â  if isinstance(balance_summary_data, dict):

Â  Â  Â  Â  Â  Â  Â  Â  for key, value in balance_summary_data.items():

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key_mapped = key.replace("_", " ").title().replace(" ", "_") # Try to map to original header

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if key == "balance": row_data_to_save["Balance"] = value

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif key == "equity": row_data_to_save["Equity"] = value

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif key == "free_margin": row_data_to_save["Free_Margin"] = value

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif key == "margin": row_data_to_save["Margin"] = value

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif key == "floating_p_l": row_data_to_save["Floating_P_L"] = value

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif key == "margin_level": row_data_to_save["Margin_Level"] = value

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif key == "credit_facility": row_data_to_save["Credit_Facility"] = value





Â  Â  Â  Â  Â  Â  # Populate from results_summary_data

Â  Â  Â  Â  Â  Â  if isinstance(results_summary_data, dict):

Â  Â  Â  Â  Â  Â  Â  Â  for gsheet_key, val_res in results_summary_data.items():

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if gsheet_key in expected_headers:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_data_to_save[gsheet_key] = val_res

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  final_row_values = [str(row_data_to_save.get(h, "")).strip() for h in expected_headers]

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  ws.append_rows([final_row_values], value_input_option='USER_ENTERED')

Â  Â  Â  Â  Â  Â  return True

Â  Â  Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹„à¸¡à¹ˆà¸à¸š Worksheet '{WORKSHEET_STATEMENT_SUMMARIES}'. à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¹ƒà¸ªà¹ˆ Headers: {', '.join(expected_headers)}")

Â  Â  Â  Â  Â  Â  return False

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸ Statement Summaries: {e}")

Â  Â  Â  Â  Â  Â  st.exception(e)

Â  Â  Â  Â  Â  Â  return False



Â  Â  st.markdown("---")

Â  Â  st.subheader("ğŸ“¤ à¸­à¸±à¸›à¹‚à¸«à¸¥à¸” Statement Report (CSV) à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¸°à¸šà¸±à¸™à¸—à¸¶à¸")

Â  Â Â 

Â  Â  uploaded_file_statement = st.file_uploader(Â 

Â  Â  Â  Â  "à¸¥à¸²à¸à¹à¸¥à¸°à¸§à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œ Statement Report (CSV) à¸—à¸µà¹ˆà¸™à¸µà¹ˆ à¸«à¸£à¸·à¸­à¸„à¸¥à¸´à¸à¹€à¸à¸·à¹ˆà¸­à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ",

Â  Â  Â  Â  type=["csv"],

Â  Â  Â  Â  key="full_stmt_uploader_final_v3" # Changed key to avoid conflict

Â  Â  )



Â  Â  st.checkbox("âš™ï¸ à¹€à¸›à¸´à¸”à¹‚à¸«à¸¡à¸” Debug (à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹à¸¢à¸à¹„à¸”à¹‰)", value=False, key="debug_statement_processing_v2")

Â  Â Â 

Â  Â  active_portfolio_id_for_actual = st.session_state.get('active_portfolio_id_gs', None)

Â  Â  active_portfolio_name_for_actual = st.session_state.get('active_portfolio_name_gs', None)



Â  Â  if uploaded_file_statement:

Â  Â  Â  Â  file_name_for_saving = uploaded_file_statement.name

Â  Â  Â  Â Â 

Â  Â  Â  Â  # --- NEW: Add FileHash for Deduplication ---

Â  Â  Â  Â  file_hash_for_saving = ""

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  uploaded_file_statement.seek(0) # Reset pointer

Â  Â  Â  Â  Â  Â  file_content_bytes_for_hash = uploaded_file_statement.read()

Â  Â  Â  Â  Â  Â  uploaded_file_statement.seek(0) # Reset pointer again

Â  Â  Â  Â  Â  Â  file_hash_for_saving = hashlib.md5(file_content_bytes_for_hash).hexdigest()

Â  Â  Â  Â  except Exception as e_hash:

Â  Â  Â  Â  Â  Â  file_hash_for_saving = f"hash_error_{random.randint(10000,99999)}"

Â  Â  Â  Â  Â  Â  print(f"Warning: Could not compute MD5 hash for file {file_name_for_saving}: {e_hash}")

Â  Â  Â  Â  # --- END NEW ---



Â  Â  Â  Â  # Check for previous successful uploads of the same file

Â  Â  Â  Â  previously_successfully_processed = False

Â  Â  Â  Â  if active_portfolio_id_for_actual: # Only check for duplicates if a portfolio is selected

Â  Â  Â  Â  Â  Â  gc_history = get_gspread_client()

Â  Â  Â  Â  Â  Â  if gc_history:

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sh_history = gc_history.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws_upload_history = sh_history.worksheet(WORKSHEET_UPLOAD_HISTORY)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  history_records = ws_upload_history.get_all_records(numericise_ignore=['all']) # Read all as string to compare hash/size

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for record in history_records:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  record_file_size_val = int(float(str(record.get("FileSize","0")).replace(",","")))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  record_file_size_val = 0 # Default to 0 if conversion fails



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if str(record.get("PortfolioID","")) == str(active_portfolio_id_for_actual) and \

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â record.get("FileName","") == file_name_for_saving and \

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â record_file_size_val == uploaded_file_statement.size and \

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â record.get("FileHash","") == file_hash_for_saving and \

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â str(record.get("Status","")).startswith("Success"):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  previously_successfully_processed = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  except gspread.exceptions.WorksheetNotFound:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Warning: Upload history worksheet '{WORKSHEET_UPLOAD_HISTORY}' not found. Cannot check for duplicates.")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e_hist_read:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Warning: Error reading upload history for duplicate check: {e_hist_read}")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  print("Warning: GSpread client not available for upload history check.")





Â  Â  Â  Â  if previously_successfully_processed:

Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ à¹„à¸Ÿà¸¥à¹Œ '{file_name_for_saving}' à¸™à¸µà¹‰ à¹€à¸„à¸¢à¸–à¸¹à¸à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸­à¸£à¹Œà¸• '{active_portfolio_name_for_actual}' à¹„à¸›à¹à¸¥à¹‰à¸§ à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸”à¹‰à¸–à¸¹à¸à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢ à¸ˆà¸°à¹„à¸¡à¹ˆà¸”à¸³à¹€à¸™à¸´à¸™à¸à¸²à¸£à¹ƒà¸”à¹† à¸‹à¹‰à¸³à¸­à¸µà¸")

Â  Â  Â  Â  else: # Proceed with processing only if not previously successful for this portfolio

Â  Â  Â  Â  Â  Â  import_batch_id = str(uuid.uuid4())

Â  Â  Â  Â  Â  Â  current_upload_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")



Â  Â  Â  Â  Â  Â  initial_log_success = False

Â  Â  Â  Â  Â  Â  gc_log_init = get_gspread_client()

Â  Â  Â  Â  Â  Â  if gc_log_init:

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sh_log_init = gc_log_init.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws_upload_history_init = sh_log_init.worksheet(WORKSHEET_UPLOAD_HISTORY)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ensure headers are correct for UploadHistory

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  expected_upload_history_headers = ["UploadTimestamp", "PortfolioID", "PortfolioName", "FileName", "FileSize", "FileHash", "Status", "ImportBatchID", "Notes"]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if ws_upload_history_init.row_count == 0 or set(ws_upload_history_init.row_values(1)) != set(expected_upload_history_headers):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws_upload_history_init.update([expected_upload_history_headers])



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws_upload_history_init.append_row([

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_upload_timestamp, str(active_portfolio_id_for_actual), str(active_portfolio_name_for_actual),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name_for_saving, uploaded_file_statement.size, file_hash_for_saving,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Processing", import_batch_id, "Attempting to process new/previously failed file."

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ])

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  initial_log_success = True

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e_log_init:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸šà¸±à¸™à¸—à¸¶à¸ Log à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹ƒà¸™ {WORKSHEET_UPLOAD_HISTORY}: {e_log_init}")



Â  Â  Â  Â  Â  Â  if initial_log_success:

Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"--- \n**Import Batch ID: `{import_batch_id}`**")

Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"à¸à¸³à¸¥à¸±à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸Ÿà¸¥à¹Œ (à¹ƒà¸«à¸¡à¹ˆ/à¹€à¸„à¸¢à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§): {file_name_for_saving}")



Â  Â  Â  Â  Â  Â  Â  Â  processing_had_errors = False

Â  Â  Â  Â  Â  Â  Â  Â  final_status_for_history = "Failed_Unknown"

Â  Â  Â  Â  Â  Â  Â  Â  final_processing_notes = []



Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  uploaded_file_statement.seek(0)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_content_bytes = uploaded_file_statement.getvalue()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_content_str = file_content_bytes.decode("utf-8", errors="replace")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner(f"à¸à¸³à¸¥à¸±à¸‡à¹à¸¢à¸à¸ªà¹ˆà¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ {file_name_for_saving}..."):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # THIS IS THE CORE CALL to the updated extraction function

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extracted_sections = extract_data_from_report_content(file_content_str)



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- DEBUG: Show extracted balance_summary before saving ---

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.markdown("---")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.info(f"DEBUG: Extracted Balance Summary (Pre-Save): {extracted_sections.get('balance_summary', {})}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"DEBUG Console: Extracted Balance Summary (Pre-Save): {extracted_sections.get('balance_summary', {})}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.markdown("---")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- END DEBUG ---



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.get("debug_statement_processing_v2", False):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("DEBUG: Extracted Sections (Details)")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if extracted_sections:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for section_name, data_item in extracted_sections.items():

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"#### {section_name.replace('_',' ').title()}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(data_item, pd.DataFrame):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not data_item.empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(data_item.head())

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"DataFrame for {section_name.replace('_',' ').title()} is empty.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif isinstance(data_item, dict):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.json(data_item if data_item else f"Dictionary for {section_name} is empty.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(data_item if data_item is not None else f"Data for {section_name} is None.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("No sections extracted from file.")





Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not active_portfolio_id_for_actual:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¸à¸£à¸¸à¸“à¸²à¹€à¸¥à¸·à¸­à¸à¸à¸­à¸£à¹Œà¸•à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ (Active Portfolio) à¹ƒà¸™ Sidebar à¸à¹ˆà¸­à¸™à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Statement.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif not extracted_sections:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ Statement à¹„à¸”à¹‰ à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œà¸«à¸£à¸·à¸­à¹‚à¸«à¸¡à¸” Debug")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: # If portfolio is selected and extraction succeeded

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("ğŸ’¾ à¸à¸³à¸¥à¸±à¸‡à¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸›à¸¢à¸±à¸‡ Google Sheets...")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gc_for_save_data = get_gspread_client()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if gc_for_save_data:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sh_for_save_data = gc_for_save_data.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Save Deals

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  deals_df = extracted_sections.get('deals')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if deals_df is not None and not deals_df.empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if save_deals_to_actual_trades(sh_for_save_data, deals_df, active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving, import_batch_id):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"à¸šà¸±à¸™à¸—à¸¶à¸ Deals ({len(deals_df)} à¸£à¸²à¸¢à¸à¸²à¸£) à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¸šà¸±à¸™à¸—à¸¶à¸ Deals à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ."); processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: st.info("à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Deals à¹ƒà¸™ Statement à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰.")



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Save Orders

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  orders_df = extracted_sections.get('orders')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if orders_df is not None and not orders_df.empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if save_orders_to_gsheets(sh_for_save_data, orders_df, active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving, import_batch_id):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"à¸šà¸±à¸™à¸—à¸¶à¸ Orders ({len(orders_df)} à¸£à¸²à¸¢à¸à¸²à¸£) à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¸šà¸±à¸™à¸—à¸¶à¸ Orders à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ."); processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: st.info("à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Orders à¹ƒà¸™ Statement à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Save Positions

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  positions_df = extracted_sections.get('positions')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if positions_df is not None and not positions_df.empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if save_positions_to_gsheets(sh_for_save_data, positions_df, active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving, import_batch_id):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"à¸šà¸±à¸™à¸—à¸¶à¸ Positions ({len(positions_df)} à¸£à¸²à¸¢à¸à¸²à¸£) à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¸šà¸±à¸™à¸—à¸¶à¸ Positions à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ."); processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: st.info("à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Positions à¹ƒà¸™ Statement à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰.")



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Save Summaries (Balance & Results)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  balance_summary_data = extracted_sections.get('balance_summary', {})

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  results_summary_data = extracted_sections.get('results_summary', {})



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if balance_summary_data or results_summary_data:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if save_results_summary_to_gsheets(sh_for_save_data, balance_summary_data, results_summary_data, active_portfolio_id_for_actual, active_portfolio_name_for_actual, file_name_for_saving, import_batch_id):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("à¸šà¸±à¸™à¸—à¸¶à¸ Summary Data (Balance & Results) à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¸šà¸±à¸™à¸—à¸¶à¸ Summary Data à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ."); processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: st.info("à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Summary (Balance à¸«à¸£à¸·à¸­ Results) à¹ƒà¸™ Statement.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- Update session_state.latest_statement_equity AND current_account_balance ---

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # This is the crucial step to update the balance used for calculations

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if 'equity' in balance_summary_data and balance_summary_data['equity'] is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  latest_equity_from_stmt = float(balance_summary_data['equity'])

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.latest_statement_equity = latest_equity_from_stmt

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_account_balance = latest_equity_from_stmt

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"âœ”ï¸ à¸­à¸±à¸›à¹€à¸”à¸• Balance à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸™à¸§à¸“à¸ˆà¸²à¸ Statement Equity à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {latest_equity_from_stmt:,.2f} USD")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_processing_notes.append(f"Updated_Equity={latest_equity_from_stmt}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("âš ï¸ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸² Equity à¸ˆà¸²à¸ Statement à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚à¹„à¸”à¹‰")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_processing_notes.append("Warning: Failed to convert Equity from Statement.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("âš ï¸ à¹„à¸¡à¹ˆà¸à¸šà¸„à¹ˆà¸² 'Equity' à¹ƒà¸™ Statement à¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸”. à¸ˆà¸°à¹ƒà¸Šà¹‰ Balance à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡à¹„à¸§à¹‰")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_processing_notes.append("Warning: 'Equity' not found in Statement.")



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e_save_data:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‚à¹‰à¸² Google Sheets: {e_save_data}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.exception(e_save_data)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Google Sheets Client à¹€à¸à¸·à¹ˆà¸­à¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸”à¹‰."); processing_had_errors = True

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not processing_had_errors:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_status_for_history = "Success"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.balloons()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¸°à¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œ '{file_name_for_saving}' à¸ªà¸³à¸«à¸£à¸±à¸š Batch ID '{import_batch_id}' à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_status_for_history = "Failed_PartialSave"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸Ÿà¸¥à¹Œ '{file_name_for_saving}' (Batch ID '{import_batch_id}') à¸¡à¸µà¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§ à¹‚à¸›à¸£à¸”à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸”à¹‰à¸²à¸™à¸šà¸™à¹à¸¥à¸° Log")

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  except UnicodeDecodeError as e_decode_main:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£ Decode à¹„à¸Ÿà¸¥à¹Œ: {e_decode_main}. à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Encoding (à¸„à¸§à¸£à¹€à¸›à¹‡à¸™ UTF-8).")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_status_for_history = "Failed_UnicodeDecode"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_processing_notes.append(f"UnicodeDecodeError: {e_decode_main}")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e_main:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸«à¸¥à¸±à¸: {type(e_main).__name__} - {str(e_main)[:200]}...")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_status_for_history = f"Failed_MainProcessing_{type(e_main).__name__}"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_processing_notes.append(f"MainError: {type(e_main).__name__} - {str(e_main)[:100]}")



Â  Â  Â  Â  Â  Â  Â  Â  # Update UploadHistory with the final status and notes

Â  Â  Â  Â  Â  Â  Â  Â  gc_log_update = get_gspread_client()

Â  Â  Â  Â  Â  Â  Â  Â  if gc_log_update and initial_log_success: # Only attempt to update if initial log was written

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sh_log_update = gc_log_update.open(GOOGLE_SHEET_NAME)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws_upload_history_update = sh_log_update.worksheet(WORKSHEET_UPLOAD_HISTORY)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  history_rows = ws_upload_history_update.get_all_values()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_to_update_idx = None

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for idx_update, row_val_update in reversed(list(enumerate(history_rows))):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(row_val_update) > 7 and row_val_update[7] == import_batch_id:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_to_update_idx = idx_update + 1

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if row_to_update_idx:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  notes_to_save_str = " | ".join(filter(None, final_processing_notes))[:49999] # Truncate if too long

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws_upload_history_update.batch_update([

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {'range': f'G{row_to_update_idx}', 'values': [[final_status_for_history]]},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {'range': f'I{row_to_update_idx}', 'values': [[notes_to_save_str]]}

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ], value_input_option='USER_ENTERED')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Info: Updated UploadHistory for ImportBatchID '{import_batch_id}' to '{final_status_for_history}'.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Warning: Could not find ImportBatchID '{import_batch_id}' in {WORKSHEET_UPLOAD_HISTORY} to update final status.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e_update_hist_final:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Warning: Could not update final status in {WORKSHEET_UPLOAD_HISTORY} for batch {import_batch_id}: {e_update_hist_final}")

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Warning: Could not update upload history (no client or initial log failed) for batch {import_batch_id}.")



Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.uploader_key_version += 1 # Increment key to reset uploader widget

Â  Â  Â  Â  Â  Â  Â  Â  st.rerun() # Rerun to reflect changes immediately

Â  Â  else: # No file uploaded

Â  Â  Â  Â  st.info("à¹‚à¸›à¸£à¸”à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Statement Report (CSV) à¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥.")



Â  Â  st.markdown("---")



# --- End of SEC 7 ---

# ===================== SEC 7: MAIN AREA - TRADE LOG VIEWER =======================

@st.cache_data(ttl=120) # Cache à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸‚à¸­à¸‡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸™à¸µà¹‰ (à¸‹à¸¶à¹ˆà¸‡à¸£à¸§à¸¡à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¹‰à¸§) à¹„à¸§à¹‰ 2 à¸™à¸²à¸—à¸µ

def load_planned_trades_from_gsheets_for_viewer():

Â  Â  # à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸à¸¥à¸²à¸‡à¹€à¸à¸·à¹ˆà¸­à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ PlannedTradeLogs (à¸‹à¸¶à¹ˆà¸‡à¸¡à¸µ cache à¸‚à¸­à¸‡à¸•à¸±à¸§à¹€à¸­à¸‡)

Â  Â  df_logs_viewer = load_all_planned_trade_logs_from_gsheets()Â 

Â  Â Â 

Â  Â  if df_logs_viewer.empty:

Â  Â  Â  Â  return pd.DataFrame()



Â  Â  # à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸°à¸—à¸³à¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ cache à¸à¸¥à¸²à¸‡à¹à¸¥à¹‰à¸§

Â  Â  # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ 'Timestamp' à¸¡à¸µà¸­à¸¢à¸¹à¹ˆ à¹à¸¥à¸°à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¸„à¹ˆà¸²à¸§à¹ˆà¸²à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸à¹ˆà¸­à¸™à¹€à¸£à¸µà¸¢à¸‡

Â  Â  if 'Timestamp' in df_logs_viewer.columns and not df_logs_viewer['Timestamp'].isnull().all():

Â  Â  Â  Â  return df_logs_viewer.sort_values(by="Timestamp", ascending=False)

Â  Â  return df_logs_viewer # à¸„à¸·à¸™à¸„à¹ˆà¸² df à¹€à¸”à¸´à¸¡à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸£à¸µà¸¢à¸‡à¹„à¸”à¹‰



with st.expander("ğŸ“š Trade Log Viewer (à¹à¸œà¸™à¹€à¸—à¸£à¸”à¸ˆà¸²à¸ Google Sheets)", expanded=False):

Â  Â  df_log_viewer_gs = load_planned_trades_from_gsheets_for_viewer()



Â  Â  if df_log_viewer_gs.empty:

Â  Â  Â  Â  st.info("à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸œà¸™à¸—à¸µà¹ˆà¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸§à¹‰à¹ƒà¸™ Google Sheets à¸«à¸£à¸·à¸­ Worksheet 'PlannedTradeLogs' à¸§à¹ˆà¸²à¸‡à¹€à¸›à¸¥à¹ˆà¸²/à¹‚à¸«à¸¥à¸”à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ.")

Â  Â  else:

Â  Â  Â  Â  df_show_log_viewer = df_log_viewer_gs.copy() # à¸—à¸³à¸‡à¸²à¸™à¸šà¸™à¸ªà¸³à¹€à¸™à¸²à¹€à¸à¸·à¹ˆà¸­à¸à¸²à¸£à¸à¸£à¸­à¸‡



Â  Â  Â  Â  # --- Filters UI ---

Â  Â  Â  Â  log_filter_cols = st.columns(4)

Â  Â  Â  Â  with log_filter_cols[0]:

Â  Â  Â  Â  Â  Â  portfolios_in_log = ["à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"]

Â  Â  Â  Â  Â  Â  if "PortfolioName" in df_show_log_viewer.columns:

Â  Â  Â  Â  Â  Â  Â  Â  Â portfolios_in_log.extend(sorted(df_show_log_viewer["PortfolioName"].dropna().unique().tolist()))

Â  Â  Â  Â  Â  Â  portfolio_filter_log = st.selectbox("Portfolio", portfolios_in_log, key="log_viewer_portfolio_filter")

Â  Â  Â  Â Â 

Â  Â  Â  Â  with log_filter_cols[1]:

Â  Â  Â  Â  Â  Â  modes_in_log = ["à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"]

Â  Â  Â  Â  Â  Â  if "Mode" in df_show_log_viewer.columns:

Â  Â  Â  Â  Â  Â  Â  Â  modes_in_log.extend(sorted(df_show_log_viewer["Mode"].dropna().unique().tolist()))

Â  Â  Â  Â  Â  Â  mode_filter_log = st.selectbox("Mode", modes_in_log, key="log_viewer_mode_filter")



Â  Â  Â  Â  with log_filter_cols[2]:

Â  Â  Â  Â  Â  Â  assets_in_log = ["à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”"]

Â  Â  Â  Â  Â  Â  if "Asset" in df_show_log_viewer.columns:

Â  Â  Â  Â  Â  Â  Â  Â  assets_in_log.extend(sorted(df_show_log_viewer["Asset"].dropna().unique().tolist()))

Â  Â  Â  Â  Â  Â  asset_filter_log = st.selectbox("Asset", assets_in_log, key="log_viewer_asset_filter")



Â  Â  Â  Â  with log_filter_cols[3]:

Â  Â  Â  Â  Â  Â  date_filter_log = None

Â  Â  Â  Â  Â  Â  # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ Timestamp à¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹à¸¥à¸°à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¹ˆà¸­à¸™à¹à¸ªà¸”à¸‡ date_input

Â  Â  Â  Â  Â  Â  if 'Timestamp' in df_show_log_viewer.columns and not df_show_log_viewer['Timestamp'].isnull().all():

Â  Â  Â  Â  Â  Â  Â  Â  Â date_filter_log = st.date_input("à¸„à¹‰à¸™à¸«à¸²à¸§à¸±à¸™à¸—à¸µà¹ˆ (Log)", value=None, key="log_viewer_date_filter", help="à¹€à¸¥à¸·à¸­à¸à¸§à¸±à¸™à¸—à¸µà¹ˆà¹€à¸à¸·à¹ˆà¸­à¸à¸£à¸­à¸‡ Log")





Â  Â  Â  Â  # --- Apply Filters ---

Â  Â  Â  Â  if portfolio_filter_log != "à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”" and "PortfolioName" in df_show_log_viewer:

Â  Â  Â  Â  Â  Â  df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["PortfolioName"] == portfolio_filter_log]

Â  Â  Â  Â  if mode_filter_log != "à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”" and "Mode" in df_show_log_viewer:

Â  Â  Â  Â  Â  Â  df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["Mode"] == mode_filter_log]

Â  Â  Â  Â  if asset_filter_log != "à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”" and "Asset" in df_show_log_viewer:

Â  Â  Â  Â  Â  Â  df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["Asset"] == asset_filter_log]

Â  Â  Â  Â Â 

Â  Â  Â  Â  # Filter by date (ensure Timestamp is datetime)

Â  Â  Â  Â  if date_filter_log and 'Timestamp' in df_show_log_viewer.columns:

Â  Â  Â  Â  Â  Â  # Ensure 'Timestamp' is datetime64 for comparison with date_filter_log (which is datetime.date)

Â  Â  Â  Â  Â  Â  if not pd.api.types.is_datetime64_any_dtype(df_show_log_viewer['Timestamp']):

Â  Â  Â  Â  Â  Â  Â  Â  df_show_log_viewer['Timestamp'] = pd.to_datetime(df_show_log_viewer['Timestamp'], errors='coerce')

Â  Â  Â  Â  Â  Â  df_show_log_viewer = df_show_log_viewer[df_show_log_viewer["Timestamp"].dt.date == date_filter_log]

Â  Â  Â  Â Â 

Â  Â  Â  Â  st.markdown("---")

Â  Â  Â  Â  st.markdown("**Log Details & Actions:**")

Â  Â  Â  Â Â 

Â  Â  Â  Â  # --- Display Logic (Iterative rows - Original user's style) ---

Â  Â  Â  Â  # Define columns to display and their headers

Â  Â  Â  Â  cols_to_display_log_viewer = {

Â  Â  Â  Â  Â  Â  "Timestamp": "Timestamp", "PortfolioName": "Portfolio", "Asset": "Asset",

Â  Â  Â  Â  Â  Â  "Mode": "Mode", "Direction": "Direction", "Entry": "Entry", "SL": "SL", "TP": "TP",

Â  Â  Â  Â  Â  Â  "Lot": "Lot", "Risk $": "Risk $" , "RR": "RR"

Â  Â  Â  Â  Â  Â  # "LogID": "LogID" # Optional: for debugging or unique keying if needed

Â  Â  Â  Â  }

Â  Â  Â  Â  # Filter out columns not present in the DataFrame to prevent KeyErrors

Â  Â  Â  Â  actual_cols_to_display_keys = [k for k in cols_to_display_log_viewer.keys() if k in df_show_log_viewer.columns]

Â  Â  Â  Â Â 

Â  Â  Â  Â  num_display_cols = len(actual_cols_to_display_keys)

Â  Â  Â  Â Â 

Â  Â  Â  Â  if not df_show_log_viewer.empty:

Â  Â  Â  Â  Â  Â  # Create header row

Â  Â  Â  Â  Â  Â  header_cols = st.columns(num_display_cols + 1) # +1 for Action button

Â  Â  Â  Â  Â  Â  for i, col_key in enumerate(actual_cols_to_display_keys):

Â  Â  Â  Â  Â  Â  Â  Â  header_cols[i].markdown(f"**{cols_to_display_log_viewer[col_key]}**")

Â  Â  Â  Â  Â  Â  header_cols[num_display_cols].markdown(f"**Action**")



Â  Â  Â  Â  Â  Â  # Iterate through filtered DataFrame to display rows

Â  Â  Â  Â  Â  Â  for index_log, row_log in df_show_log_viewer.iterrows():

Â  Â  Â  Â  Â  Â  Â  Â  row_display_cols = st.columns(num_display_cols + 1)

Â  Â  Â  Â  Â  Â  Â  Â  for i, col_key in enumerate(actual_cols_to_display_keys):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val = row_log.get(col_key, "-") # Default to "-" if value is missing

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.isna(val): # Check for pd.NA or np.nan

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val_display = "-"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif isinstance(val, float):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Format floats (e.g., Entry, SL, TP, Lot, Risk $, RR)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if col_key in ['Entry', 'SL', 'TP']:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val_display = f"{val:.5f}" if val != 0 else "0.00000" # More precision for prices

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif col_key in ['Lot', 'Risk $', 'RR', 'Risk %']:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â val_display = f"{val:.2f}"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â val_display = str(val)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif isinstance(val, pd.Timestamp):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val_display = val.strftime("%Y-%m-%d %H:%M")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  val_display = str(val)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_display_cols[i].write(val_display)



Â  Â  Â  Â  Â  Â  Â  Â  # Action button for each row

Â  Â  Â  Â  Â  Â  Â  Â  log_id_for_key = row_log.get('LogID', index_log) # Use LogID if available, else index

Â  Â  Â  Â  Â  Â  Â  Â  if row_display_cols[num_display_cols].button(f"ğŸ“ˆ Plot", key=f"plot_log_{log_id_for_key}"):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state['plot_data'] = row_log.to_dict()

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"à¹€à¸¥à¸·à¸­à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸—à¸£à¸” '{row_log.get('Asset', '-')}' @ Entry '{row_log.get('Entry', '-')}' à¹€à¸•à¸£à¸µà¸¢à¸¡à¸à¸£à¹‰à¸­à¸¡à¸ªà¸³à¸«à¸£à¸±à¸š Plot à¸šà¸™ Chart Visualizer!")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Consider if rerun is needed or if Chart Visualizer updates reactively

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun() # Rerun to make chart visualizer pick up the new plot_data

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  st.info("à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Log à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²")

Â  Â  Â  Â Â 

Â  Â  Â  Â  # Display plot_data in sidebar if it exists (from original code)

Â  Â  Â  Â  if 'plot_data' in st.session_state and st.session_state['plot_data']:

Â  Â  Â  Â  Â  Â  st.sidebar.success(f"à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸£à¹‰à¸­à¸¡ Plot: {st.session_state['plot_data'].get('Asset')} @ {st.session_state['plot_data'].get('Entry')}")

Â  Â  Â  Â  Â  Â  # Limit the display if plot_data is too large

Â  Â  Â  Â  Â  Â  # For instance, convert to string and truncate, or select specific keys

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  plot_data_str = str(st.session_state['plot_data'])

Â  Â  Â  Â  Â  Â  Â  Â  if len(plot_data_str) > 300: # Limit length for display

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  plot_data_display = plot_data_str[:300] + "..."

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  plot_data_display = plot_data_str

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.json(plot_data_display, expanded=False) # Display as JSON string

Â  Â  Â  Â  Â  Â  except:

Â  Â  Â  Â  Â  Â  Â  Â  st.sidebar.text("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸ªà¸”à¸‡ plot_data (à¸­à¸²à¸ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¸à¸²à¸£à¹à¸›à¸¥à¸‡)")





# --- End of SEC 7 (formerly SEC 9) ---

